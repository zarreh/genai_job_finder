OPENAI_API_KEY=sk-proj-
GOOGLE_API_KEY=xxxx
ANTHROPIC_API_KEY=xxxx
HF_TOKEN=xxxx
LANGSMITH_TRACING="true"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="lsv2_xxxxxx"
LANGSMITH_PROJECT="genai_job_finder"
USER_AGENT = "xxxxx"

# Chat Configuration
# Options: "default" (all Ollama), "mixed" (Ollama chat + OpenAI resume), "openai" (all OpenAI), "env" (from variables below)
CHAT_CONFIG_MODE=default

# Chat LLM Configuration (for conversation)
CHAT_LLM_PROVIDER=ollama
CHAT_LLM_MODEL=llama3.2
CHAT_LLM_TEMPERATURE=0.7
CHAT_LLM_MAX_TOKENS=1500

# Resume Analysis LLM Configuration (for resume processing)
RESUME_LLM_PROVIDER=openai
RESUME_LLM_MODEL=gpt-3.5-turbo
RESUME_LLM_TEMPERATURE=0.1
RESUME_LLM_MAX_TOKENS=1000

# Chat Behavior Settings
CHAT_MAX_HISTORY=2000
CHAT_TOPIC_FILTERING=true

# Hugging Face Configuration
HF_HUB_OFFLINE=1
TRANSFORMERS_OFFLINE=1
HF_DATASETS_OFFLINE=1
HF_HUB_DISABLE_TELEMETRY=1

# Local cache directories
TRANSFORMERS_CACHE=./models/transformers_cache
HF_HOME=./models/hf_cache

# Optional: If you have a Hugging Face token (uncomment and add your token)
HUGGINGFACE_HUB_TOKEN=hf_xxxxxx

# Force CPU usage (uncomment if you want to disable CUDA)
# CUDA_VISIBLE_DEVICES=""

SKIP_SENTENCE_TRANSFORMERS=true


# LinkedIn Parser Configuration
# Copy this file to .env and modify as needed

# NOTE: Search parameters (query, location, etc.) are now configured 
# in genai_job_finder/linkedin_parser/config.py in the LINKEDIN_JOB_SEARCH_PARAMS list
# Edit that file to change your default search criteria

# Database and export paths
JOB_DB_PATH="data/jobs.db"
EXPORT_CSV_PATH="data/jobs_export.csv"

# Scraping settings
HEADLESS_BROWSER=true
PAGE_TIMEOUT=10
MAX_PAGES=5
REQUEST_DELAY=2.0

# Logging
LOG_LEVEL="INFO"
# LOG_FILE="parser.log"  # Uncomment to log to file

# Vector store (legacy compatibility)
PERSIST_PATH="data/job_data/vectorstore_faiss"
