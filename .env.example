OPENAI_API_KEY=sk-proj-
GOOGLE_API_KEY=xxxx
ANTHROPIC_API_KEY=xxxx
HF_TOKEN=xxxx
LANGSMITH_TRACING="true"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="lsv2_xxxxxx"
LANGSMITH_PROJECT="genai_job_finder"
USER_AGENT = "xxxxx"

# Hugging Face Configuration
HF_HUB_OFFLINE=1
TRANSFORMERS_OFFLINE=1
HF_DATASETS_OFFLINE=1
HF_HUB_DISABLE_TELEMETRY=1

# Local cache directories
TRANSFORMERS_CACHE=./models/transformers_cache
HF_HOME=./models/hf_cache

# Optional: If you have a Hugging Face token (uncomment and add your token)
HUGGINGFACE_HUB_TOKEN=hf_xxxxxx

# Force CPU usage (uncomment if you want to disable CUDA)
# CUDA_VISIBLE_DEVICES=""

SKIP_SENTENCE_TRANSFORMERS=true


# LinkedIn Parser Configuration
# Copy this file to .env and modify as needed

# NOTE: Search parameters (query, location, etc.) are now configured 
# in genai_job_finder/linkedin_parser/config.py in the LINKEDIN_JOB_SEARCH_PARAMS list
# Edit that file to change your default search criteria

# Database and export paths
JOB_DB_PATH="data/jobs.db"
EXPORT_CSV_PATH="data/jobs_export.csv"

# Scraping settings
HEADLESS_BROWSER=true
PAGE_TIMEOUT=10
MAX_PAGES=5
REQUEST_DELAY=2.0

# Logging
LOG_LEVEL="INFO"
# LOG_FILE="parser.log"  # Uncomment to log to file

# Vector store (legacy compatibility)
PERSIST_PATH="data/job_data/vectorstore_faiss"
