{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be7e499",
   "metadata": {},
   "source": [
    "# Enhanced LinkedIn Job Database Analysis\n",
    "\n",
    "This notebook analyzes the LinkedIn job database with the new enhanced parser that includes:\n",
    "\n",
    "- **20-column output structure** (with integrated company information)\n",
    "- **Company intelligence** with automatic extraction of company size, followers, and industry\n",
    "- **Location intelligence** with automatic extraction\n",
    "- **Work type classification** (Remote/Hybrid/On-site)\n",
    "- **Enhanced data model** with comprehensive job and company information\n",
    "\n",
    "Run `make run-parser` first to collect fresh job data with location and company intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "741025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = (\n",
    "    Path(__file__).parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    ")\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from genai_job_finder.linkedin_parser.database import DatabaseManager\n",
    "from genai_job_finder.linkedin_parser.models import Job, JobRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f1daf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/alireza/projects/genai_job_finder')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef5a736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /home/alireza/projects/genai_job_finder/data/jobs.db\n",
      "Database exists: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db_path = project_root / \"data\" / \"jobs.db\"\n",
    "# db_path = project_root / \"test_jobs.db\"\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")\n",
    "\n",
    "# Create database manager\n",
    "db = DatabaseManager(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16b1a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in database: 256\n",
      "Total job runs: 23\n",
      "\n",
      "Recent job runs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "search_query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location_filter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "15ab7df5-c3d8-47ea-9d00-2dea9f87e0d0",
       "rows": [
        [
         "0",
         "23",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-09-01 04:32:27"
        ],
        [
         "1",
         "22",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-09-01 04:22:58"
        ],
        [
         "2",
         "21",
         "data scientist",
         "San Antonio",
         "completed",
         "8",
         "2025-08-31 23:18:11"
        ],
        [
         "3",
         "20",
         "data scientist",
         "San Antonio",
         "pending",
         "0",
         "2025-08-31 23:13:38"
        ],
        [
         "4",
         "19",
         "data scientist",
         "San Antonio",
         "completed",
         "8",
         "2025-08-31 23:07:50"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>location_filter</th>\n",
       "      <th>status</th>\n",
       "      <th>job_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-01 04:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-01 04:22:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-08-31 23:18:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>pending</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-31 23:13:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-08-31 23:07:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    search_query location_filter     status  job_count  \\\n",
       "0  23  data scientist     San Antonio  completed          9   \n",
       "1  22  data scientist     San Antonio  completed          9   \n",
       "2  21  data scientist     San Antonio  completed          8   \n",
       "3  20  data scientist     San Antonio    pending          0   \n",
       "4  19  data scientist     San Antonio  completed          8   \n",
       "\n",
       "            created_at  \n",
       "0  2025-09-01 04:32:27  \n",
       "1  2025-09-01 04:22:58  \n",
       "2  2025-08-31 23:18:11  \n",
       "3  2025-08-31 23:13:38  \n",
       "4  2025-08-31 23:07:50  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check database contents - get basic stats\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Count total jobs\n",
    "    total_jobs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\n",
    "        \"count\"\n",
    "    ]\n",
    "    print(f\"Total jobs in database: {total_jobs}\")\n",
    "\n",
    "    # Count job runs\n",
    "    total_runs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM job_runs\", conn).iloc[\n",
    "        0\n",
    "    ][\"count\"]\n",
    "    print(f\"Total job runs: {total_runs}\")\n",
    "\n",
    "    # Show recent runs\n",
    "    if total_runs > 0:\n",
    "        recent_runs = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT id, search_query, location_filter, status, job_count, created_at \n",
    "            FROM job_runs \n",
    "            ORDER BY created_at DESC \n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "            conn,\n",
    "        )\n",
    "        print(\"\\nRecent job runs:\")\n",
    "recent_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20c5edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Enhanced Job Data Analysis with Company Intelligence\n",
      "Database contains: 20 recent jobs\n",
      "Columns: 20 (20-column structure with company info)\n",
      "\n",
      "Column names: ['id', 'company', 'company_size', 'company_followers', 'company_industry', 'title', 'location', 'work_location_type', 'level', 'salary_range', 'employment_type', 'job_function', 'industries', 'posted_time', 'applicants', 'job_id', 'date', 'parsing_link', 'job_posting_link', 'created_at']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_followers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_industry",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "work_location_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_range",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industries",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "posted_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicants",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parsing_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_posting_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0d6873c7-90b1-40f3-82b1-0f2ef6f3df2d",
       "rows": [
        [
         "0",
         "5c3aec75-f58d-45a1-af1f-9eb7901f2281",
         "Jobs via Dice",
         "1 employees",
         "173 followers",
         null,
         "Lead",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         "$45.00/hr - $60.00/hr",
         "Full-time",
         "Management",
         "Business Consulting and Services",
         "4 hours ago",
         "N/A",
         "4293521357",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293521357",
         "https://www.linkedin.com/jobs/view/lead-at-jobs-via-dice-4293521357?trk=public_jobs_topcard-title",
         "2025-09-01 04:34:04"
        ],
        [
         "1",
         "d95f8708-f301-4e45-a27e-3abc2e782dcc",
         "Amazon Web Services (AWS)",
         "492 employees",
         "363 followers",
         null,
         "Cleared Data Center Mechanical Field Engineer, ADC Field Engineering",
         "San Antonio, TX",
         "On-site",
         "Not Applicable",
         null,
         "Full-time",
         "Information Technology, Consulting, and Engineering",
         "IT Services and IT Consulting",
         "15 hours ago",
         "37 applicants",
         "4259080606",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4259080606",
         "https://www.linkedin.com/jobs/view/cleared-data-center-mechanical-field-engineer-adc-field-engineering-at-amazon-web-services-aws-4259080606?trk=public_jobs_topcard-title",
         "2025-09-01 04:33:56"
        ],
        [
         "2",
         "38454989-183a-47d4-8fb8-7d7dea095fdf",
         "Aha!",
         null,
         null,
         null,
         "Sr. Platform Engineer",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "22 hours ago",
         "N/A",
         "4293451536",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293451536",
         "https://www.linkedin.com/jobs/view/sr-platform-engineer-at-aha%21-4293451536?trk=public_jobs_topcard-title",
         "2025-09-01 04:33:47"
        ],
        [
         "3",
         "a1f79df7-e2f3-4eca-8e0a-b42b889d2937",
         "Jobs via Dice",
         "1 employees",
         "173 followers",
         null,
         "Web Developer",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "22 hours ago",
         "N/A",
         "4293366035",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293366035",
         "https://www.linkedin.com/jobs/view/web-developer-at-jobs-via-dice-4293366035?trk=public_jobs_topcard-title",
         "2025-09-01 04:33:36"
        ],
        [
         "4",
         "63c3f731-bb47-45fc-b5fb-4085c19f2b6e",
         "CyrusOne",
         "501-1,000 employees",
         "52,863 followers",
         "IT Services and IT Consulting",
         "Senior Data Center Capacity Engineer",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "18 hours ago",
         "N/A",
         "4267490741",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267490741",
         "https://www.linkedin.com/jobs/view/senior-data-center-capacity-engineer-at-cyrusone-4267490741?trk=public_jobs_topcard-title",
         "2025-09-01 04:33:25"
        ],
        [
         "5",
         "07586e9e-7e8a-4244-b986-1d414f5dec28",
         "Lensa",
         null,
         null,
         null,
         "Internships in Data Science, Math, Statistics or Operations Research",
         "San Antonio, TX",
         "Remote",
         "Internship",
         null,
         "Internship",
         "Engineering and Information Technology",
         "Internet Publishing",
         "22 hours ago",
         "N/A",
         "4293448846",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293448846",
         "https://www.linkedin.com/jobs/view/internships-in-data-science-math-statistics-or-operations-research-at-lensa-4293448846?trk=public_jobs_topcard-title",
         "2025-09-01 04:33:15"
        ],
        [
         "6",
         "459f6ae9-18df-450f-96fa-fd265d00ca61",
         "Jobs via Dice",
         "1 employees",
         "173 followers",
         null,
         "Senior Back-End Developer",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         "$145,000.00/yr - $170,000.00/yr",
         "Full-time",
         "Information Technology",
         "Software Development",
         "12 hours ago",
         "N/A",
         "4291579961",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291579961",
         "https://www.linkedin.com/jobs/view/senior-back-end-developer-at-jobs-via-dice-4291579961?trk=public_jobs_topcard-title",
         "2025-09-01 04:33:03"
        ],
        [
         "7",
         "f2fc0d6d-7f62-4e1d-bf91-55185c6b71d3",
         "Aha!",
         null,
         null,
         null,
         "Sr. Security Engineer (Ruby on Rails experience required)",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "22 hours ago",
         "N/A",
         "4293443790",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293443790",
         "https://www.linkedin.com/jobs/view/sr-security-engineer-ruby-on-rails-experience-required-at-aha%21-4293443790?trk=public_jobs_topcard-title",
         "2025-09-01 04:32:52"
        ],
        [
         "8",
         "78b052e8-f1a9-4d76-ba20-e37c9206f328",
         "Jobot",
         "501-1,000 employees",
         "3,308,869 followers",
         "Staffing and Recruiting",
         "REMOTE Sr. Java Backend Developer (Recent healthtech exp. req'd)",
         "San Antonio, TX",
         "Remote",
         "Not Applicable",
         "$160,000.00/yr - $200,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Software Development, Technology, Information and Internet, and Technology, Information and Media",
         "13 hours ago",
         "N/A",
         "4291714459",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291714459",
         "https://www.linkedin.com/jobs/view/remote-sr-java-backend-developer-recent-healthtech-exp-req-d-at-jobot-4291714459?trk=public_jobs_topcard-title",
         "2025-09-01 04:32:40"
        ],
        [
         "9",
         "b8f23846-f582-4a3f-ae8b-c468cf5f575c",
         "Lensa",
         null,
         null,
         null,
         "Internships in Data Science, Math, Statistics or Operations Research",
         "San Antonio, TX",
         "Remote",
         "Internship",
         null,
         "Internship",
         "Engineering and Information Technology",
         "Internet Publishing",
         "22 hours ago",
         "N/A",
         "4293448846",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293448846",
         "https://www.linkedin.com/jobs/view/internships-in-data-science-math-statistics-or-operations-research-at-lensa-4293448846?trk=public_jobs_topcard-title",
         "2025-09-01 04:24:28"
        ],
        [
         "10",
         "31fe003d-6503-414d-8759-f21e7a799125",
         "Amazon Web Services (AWS)",
         "492 employees",
         "363 followers",
         null,
         "Cleared Data Center Mechanical Field Engineer, ADC Field Engineering",
         "San Antonio, TX",
         "On-site",
         "Not Applicable",
         null,
         "Full-time",
         "Information Technology, Consulting, and Engineering",
         "IT Services and IT Consulting",
         "15 hours ago",
         "37 applicants",
         "4259080606",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4259080606",
         "https://www.linkedin.com/jobs/view/cleared-data-center-mechanical-field-engineer-adc-field-engineering-at-amazon-web-services-aws-4259080606?trk=public_jobs_topcard-title",
         "2025-09-01 04:24:20"
        ],
        [
         "11",
         "0913309a-dbed-4661-86e0-2c95dacc6926",
         "Jobs via Dice",
         "1 employees",
         "173 followers",
         null,
         "Web Developer",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "22 hours ago",
         "N/A",
         "4293366035",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293366035",
         "https://www.linkedin.com/jobs/view/web-developer-at-jobs-via-dice-4293366035?trk=public_jobs_topcard-title",
         "2025-09-01 04:24:13"
        ],
        [
         "12",
         "929d4150-110b-40a0-8cd7-0724da13486a",
         "Jobs via Dice",
         "1 employees",
         "173 followers",
         null,
         "Lead",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         "$45.00/hr - $60.00/hr",
         "Full-time",
         "Management",
         "Business Consulting and Services",
         "4 hours ago",
         "N/A",
         "4293521357",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293521357",
         "https://www.linkedin.com/jobs/view/lead-at-jobs-via-dice-4293521357?trk=public_jobs_topcard-title",
         "2025-09-01 04:24:03"
        ],
        [
         "13",
         "3ae09381-3543-4db2-a693-e79c29302d83",
         "Jobot",
         null,
         null,
         null,
         "REMOTE Sr. Java Backend Developer (Recent healthtech exp. req'd)",
         "San Antonio, TX",
         "Remote",
         "Not Applicable",
         "$160,000.00/yr - $200,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Software Development, Technology, Information and Internet, and Technology, Information and Media",
         "13 hours ago",
         "N/A",
         "4291714459",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291714459",
         "https://www.linkedin.com/jobs/view/remote-sr-java-backend-developer-recent-healthtech-exp-req-d-at-jobot-4291714459?trk=public_jobs_topcard-title",
         "2025-09-01 04:23:52"
        ],
        [
         "14",
         "5c91f651-9fa3-4d26-9cca-f068d10b7d5a",
         "Aha!",
         null,
         null,
         null,
         "Sr. Platform Engineer",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "22 hours ago",
         "N/A",
         "4293451536",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293451536",
         "https://www.linkedin.com/jobs/view/sr-platform-engineer-at-aha%21-4293451536?trk=public_jobs_topcard-title",
         "2025-09-01 04:23:41"
        ],
        [
         "15",
         "47d32ed3-8442-4dc7-aac3-a12d765318a3",
         "Jobs via Dice",
         "1 employees",
         "173 followers",
         null,
         "Senior Back-End Developer",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         "$145,000.00/yr - $170,000.00/yr",
         "Full-time",
         "Information Technology",
         "Software Development",
         "12 hours ago",
         "N/A",
         "4291579961",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291579961",
         "https://www.linkedin.com/jobs/view/senior-back-end-developer-at-jobs-via-dice-4291579961?trk=public_jobs_topcard-title",
         "2025-09-01 04:23:31"
        ],
        [
         "16",
         "2e448993-c855-4bf3-91f4-a7be365ff13d",
         "Aha!",
         null,
         null,
         null,
         "Sr. Security Engineer (Ruby on Rails experience required)",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "22 hours ago",
         "N/A",
         "4293443790",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293443790",
         "https://www.linkedin.com/jobs/view/sr-security-engineer-ruby-on-rails-experience-required-at-aha%21-4293443790?trk=public_jobs_topcard-title",
         "2025-09-01 04:23:21"
        ],
        [
         "17",
         "7829f15d-5d8e-4e3d-b497-2742efc3df6d",
         "CyrusOne",
         "501-1,000 employees",
         "52,863 followers",
         "IT Services and IT Consulting",
         "Senior Data Center Capacity Engineer",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "18 hours ago",
         "N/A",
         "4267490741",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267490741",
         "https://www.linkedin.com/jobs/view/senior-data-center-capacity-engineer-at-cyrusone-4267490741?trk=public_jobs_topcard-title",
         "2025-09-01 04:23:10"
        ],
        [
         "18",
         "81323107-f4ec-4a77-a443-736010ad0069",
         "CyrusOne",
         "822 employees",
         "52,862 followers",
         "CyrusOne",
         "Senior Data Center Capacity Engineer",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "13 hours ago",
         "N/A",
         "4267490741",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267490741",
         "https://www.linkedin.com/jobs/view/senior-data-center-capacity-engineer-at-cyrusone-4267490741?trk=public_jobs_topcard-title",
         "2025-08-31 23:18:59"
        ],
        [
         "19",
         "cdeb7242-b6b1-4938-8ca3-c185503550ae",
         "Amazon Web Services (AWS)",
         "10,001+ employees",
         "10,274,592 followers",
         "IT Services and IT Consulting",
         "Cleared Data Center Mechanical Field Engineer, ADC Field Engineering",
         "San Antonio, TX",
         "On-site",
         "Not Applicable",
         null,
         "Full-time",
         "Information Technology, Consulting, and Engineering",
         "IT Services and IT Consulting",
         "9 hours ago",
         "37 applicants",
         "4259080606",
         "2025-08-31",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4259080606",
         "https://www.linkedin.com/jobs/view/cleared-data-center-mechanical-field-engineer-adc-field-engineering-at-amazon-web-services-aws-4259080606?trk=public_jobs_topcard-title",
         "2025-08-31 23:18:55"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_followers</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>work_location_type</th>\n",
       "      <th>level</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>posted_time</th>\n",
       "      <th>applicants</th>\n",
       "      <th>job_id</th>\n",
       "      <th>date</th>\n",
       "      <th>parsing_link</th>\n",
       "      <th>job_posting_link</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c3aec75-f58d-45a1-af1f-9eb7901f2281</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>1 employees</td>\n",
       "      <td>173 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Lead</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$45.00/hr - $60.00/hr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Management</td>\n",
       "      <td>Business Consulting and Services</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293521357</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-at-job...</td>\n",
       "      <td>2025-09-01 04:34:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d95f8708-f301-4e45-a27e-3abc2e782dcc</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>492 employees</td>\n",
       "      <td>363 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Cleared Data Center Mechanical Field Engineer,...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology, Consulting, and Engine...</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>37 applicants</td>\n",
       "      <td>4259080606</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/cleared-dat...</td>\n",
       "      <td>2025-09-01 04:33:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38454989-183a-47d4-8fb8-7d7dea095fdf</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr. Platform Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293451536</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-platform...</td>\n",
       "      <td>2025-09-01 04:33:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1f79df7-e2f3-4eca-8e0a-b42b889d2937</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>1 employees</td>\n",
       "      <td>173 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293366035</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/web-develop...</td>\n",
       "      <td>2025-09-01 04:33:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63c3f731-bb47-45fc-b5fb-4085c19f2b6e</td>\n",
       "      <td>CyrusOne</td>\n",
       "      <td>501-1,000 employees</td>\n",
       "      <td>52,863 followers</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Senior Data Center Capacity Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>18 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4267490741</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>2025-09-01 04:33:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07586e9e-7e8a-4244-b986-1d414f5dec28</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Internships in Data Science, Math, Statistics ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Internship</td>\n",
       "      <td>None</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Internet Publishing</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293448846</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/internships...</td>\n",
       "      <td>2025-09-01 04:33:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>459f6ae9-18df-450f-96fa-fd265d00ca61</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>1 employees</td>\n",
       "      <td>173 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Back-End Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$145,000.00/yr - $170,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4291579961</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-back...</td>\n",
       "      <td>2025-09-01 04:33:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f2fc0d6d-7f62-4e1d-bf91-55185c6b71d3</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr. Security Engineer (Ruby on Rails experienc...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293443790</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-security...</td>\n",
       "      <td>2025-09-01 04:32:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78b052e8-f1a9-4d76-ba20-e37c9206f328</td>\n",
       "      <td>Jobot</td>\n",
       "      <td>501-1,000 employees</td>\n",
       "      <td>3,308,869 followers</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>REMOTE Sr. Java Backend Developer (Recent heal...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>$160,000.00/yr - $200,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development, Technology, Information ...</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4291714459</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/remote-sr-j...</td>\n",
       "      <td>2025-09-01 04:32:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b8f23846-f582-4a3f-ae8b-c468cf5f575c</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Internships in Data Science, Math, Statistics ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Internship</td>\n",
       "      <td>None</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Internet Publishing</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293448846</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/internships...</td>\n",
       "      <td>2025-09-01 04:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31fe003d-6503-414d-8759-f21e7a799125</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>492 employees</td>\n",
       "      <td>363 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Cleared Data Center Mechanical Field Engineer,...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology, Consulting, and Engine...</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>37 applicants</td>\n",
       "      <td>4259080606</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/cleared-dat...</td>\n",
       "      <td>2025-09-01 04:24:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0913309a-dbed-4661-86e0-2c95dacc6926</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>1 employees</td>\n",
       "      <td>173 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293366035</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/web-develop...</td>\n",
       "      <td>2025-09-01 04:24:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>929d4150-110b-40a0-8cd7-0724da13486a</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>1 employees</td>\n",
       "      <td>173 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Lead</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$45.00/hr - $60.00/hr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Management</td>\n",
       "      <td>Business Consulting and Services</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293521357</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-at-job...</td>\n",
       "      <td>2025-09-01 04:24:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3ae09381-3543-4db2-a693-e79c29302d83</td>\n",
       "      <td>Jobot</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>REMOTE Sr. Java Backend Developer (Recent heal...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>$160,000.00/yr - $200,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development, Technology, Information ...</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4291714459</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/remote-sr-j...</td>\n",
       "      <td>2025-09-01 04:23:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5c91f651-9fa3-4d26-9cca-f068d10b7d5a</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr. Platform Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293451536</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-platform...</td>\n",
       "      <td>2025-09-01 04:23:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47d32ed3-8442-4dc7-aac3-a12d765318a3</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>1 employees</td>\n",
       "      <td>173 followers</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Back-End Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$145,000.00/yr - $170,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4291579961</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-back...</td>\n",
       "      <td>2025-09-01 04:23:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2e448993-c855-4bf3-91f4-a7be365ff13d</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr. Security Engineer (Ruby on Rails experienc...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293443790</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-security...</td>\n",
       "      <td>2025-09-01 04:23:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7829f15d-5d8e-4e3d-b497-2742efc3df6d</td>\n",
       "      <td>CyrusOne</td>\n",
       "      <td>501-1,000 employees</td>\n",
       "      <td>52,863 followers</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Senior Data Center Capacity Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>18 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4267490741</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>2025-09-01 04:23:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>81323107-f4ec-4a77-a443-736010ad0069</td>\n",
       "      <td>CyrusOne</td>\n",
       "      <td>822 employees</td>\n",
       "      <td>52,862 followers</td>\n",
       "      <td>CyrusOne</td>\n",
       "      <td>Senior Data Center Capacity Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4267490741</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>2025-08-31 23:18:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cdeb7242-b6b1-4938-8ca3-c185503550ae</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>10,274,592 followers</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Cleared Data Center Mechanical Field Engineer,...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology, Consulting, and Engine...</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>37 applicants</td>\n",
       "      <td>4259080606</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/cleared-dat...</td>\n",
       "      <td>2025-08-31 23:18:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id                    company  \\\n",
       "0   5c3aec75-f58d-45a1-af1f-9eb7901f2281              Jobs via Dice   \n",
       "1   d95f8708-f301-4e45-a27e-3abc2e782dcc  Amazon Web Services (AWS)   \n",
       "2   38454989-183a-47d4-8fb8-7d7dea095fdf                       Aha!   \n",
       "3   a1f79df7-e2f3-4eca-8e0a-b42b889d2937              Jobs via Dice   \n",
       "4   63c3f731-bb47-45fc-b5fb-4085c19f2b6e                   CyrusOne   \n",
       "5   07586e9e-7e8a-4244-b986-1d414f5dec28                      Lensa   \n",
       "6   459f6ae9-18df-450f-96fa-fd265d00ca61              Jobs via Dice   \n",
       "7   f2fc0d6d-7f62-4e1d-bf91-55185c6b71d3                       Aha!   \n",
       "8   78b052e8-f1a9-4d76-ba20-e37c9206f328                      Jobot   \n",
       "9   b8f23846-f582-4a3f-ae8b-c468cf5f575c                      Lensa   \n",
       "10  31fe003d-6503-414d-8759-f21e7a799125  Amazon Web Services (AWS)   \n",
       "11  0913309a-dbed-4661-86e0-2c95dacc6926              Jobs via Dice   \n",
       "12  929d4150-110b-40a0-8cd7-0724da13486a              Jobs via Dice   \n",
       "13  3ae09381-3543-4db2-a693-e79c29302d83                      Jobot   \n",
       "14  5c91f651-9fa3-4d26-9cca-f068d10b7d5a                       Aha!   \n",
       "15  47d32ed3-8442-4dc7-aac3-a12d765318a3              Jobs via Dice   \n",
       "16  2e448993-c855-4bf3-91f4-a7be365ff13d                       Aha!   \n",
       "17  7829f15d-5d8e-4e3d-b497-2742efc3df6d                   CyrusOne   \n",
       "18  81323107-f4ec-4a77-a443-736010ad0069                   CyrusOne   \n",
       "19  cdeb7242-b6b1-4938-8ca3-c185503550ae  Amazon Web Services (AWS)   \n",
       "\n",
       "           company_size     company_followers               company_industry  \\\n",
       "0           1 employees         173 followers                           None   \n",
       "1         492 employees         363 followers                           None   \n",
       "2                  None                  None                           None   \n",
       "3           1 employees         173 followers                           None   \n",
       "4   501-1,000 employees      52,863 followers  IT Services and IT Consulting   \n",
       "5                  None                  None                           None   \n",
       "6           1 employees         173 followers                           None   \n",
       "7                  None                  None                           None   \n",
       "8   501-1,000 employees   3,308,869 followers        Staffing and Recruiting   \n",
       "9                  None                  None                           None   \n",
       "10        492 employees         363 followers                           None   \n",
       "11          1 employees         173 followers                           None   \n",
       "12          1 employees         173 followers                           None   \n",
       "13                 None                  None                           None   \n",
       "14                 None                  None                           None   \n",
       "15          1 employees         173 followers                           None   \n",
       "16                 None                  None                           None   \n",
       "17  501-1,000 employees      52,863 followers  IT Services and IT Consulting   \n",
       "18        822 employees      52,862 followers                       CyrusOne   \n",
       "19    10,001+ employees  10,274,592 followers  IT Services and IT Consulting   \n",
       "\n",
       "                                                title         location  \\\n",
       "0                                                Lead  San Antonio, TX   \n",
       "1   Cleared Data Center Mechanical Field Engineer,...  San Antonio, TX   \n",
       "2                               Sr. Platform Engineer  San Antonio, TX   \n",
       "3                                       Web Developer  San Antonio, TX   \n",
       "4                Senior Data Center Capacity Engineer  San Antonio, TX   \n",
       "5   Internships in Data Science, Math, Statistics ...  San Antonio, TX   \n",
       "6                           Senior Back-End Developer  San Antonio, TX   \n",
       "7   Sr. Security Engineer (Ruby on Rails experienc...  San Antonio, TX   \n",
       "8   REMOTE Sr. Java Backend Developer (Recent heal...  San Antonio, TX   \n",
       "9   Internships in Data Science, Math, Statistics ...  San Antonio, TX   \n",
       "10  Cleared Data Center Mechanical Field Engineer,...  San Antonio, TX   \n",
       "11                                      Web Developer  San Antonio, TX   \n",
       "12                                               Lead  San Antonio, TX   \n",
       "13  REMOTE Sr. Java Backend Developer (Recent heal...  San Antonio, TX   \n",
       "14                              Sr. Platform Engineer  San Antonio, TX   \n",
       "15                          Senior Back-End Developer  San Antonio, TX   \n",
       "16  Sr. Security Engineer (Ruby on Rails experienc...  San Antonio, TX   \n",
       "17               Senior Data Center Capacity Engineer  San Antonio, TX   \n",
       "18               Senior Data Center Capacity Engineer  San Antonio, TX   \n",
       "19  Cleared Data Center Mechanical Field Engineer,...  San Antonio, TX   \n",
       "\n",
       "   work_location_type             level                     salary_range  \\\n",
       "0             On-site  Mid-Senior level            $45.00/hr - $60.00/hr   \n",
       "1             On-site    Not Applicable                             None   \n",
       "2              Remote  Mid-Senior level                             None   \n",
       "3             On-site       Entry level                             None   \n",
       "4              Hybrid  Mid-Senior level                             None   \n",
       "5              Remote        Internship                             None   \n",
       "6             On-site  Mid-Senior level  $145,000.00/yr - $170,000.00/yr   \n",
       "7              Remote  Mid-Senior level                             None   \n",
       "8              Remote    Not Applicable  $160,000.00/yr - $200,000.00/yr   \n",
       "9              Remote        Internship                             None   \n",
       "10            On-site    Not Applicable                             None   \n",
       "11            On-site       Entry level                             None   \n",
       "12            On-site  Mid-Senior level            $45.00/hr - $60.00/hr   \n",
       "13             Remote    Not Applicable  $160,000.00/yr - $200,000.00/yr   \n",
       "14             Remote  Mid-Senior level                             None   \n",
       "15            On-site  Mid-Senior level  $145,000.00/yr - $170,000.00/yr   \n",
       "16             Remote  Mid-Senior level                             None   \n",
       "17             Hybrid  Mid-Senior level                             None   \n",
       "18             Hybrid  Mid-Senior level                             None   \n",
       "19            On-site    Not Applicable                             None   \n",
       "\n",
       "   employment_type                                       job_function  \\\n",
       "0        Full-time                                         Management   \n",
       "1        Full-time  Information Technology, Consulting, and Engine...   \n",
       "2        Full-time             Engineering and Information Technology   \n",
       "3        Full-time                             Information Technology   \n",
       "4        Full-time                             Information Technology   \n",
       "5       Internship             Engineering and Information Technology   \n",
       "6        Full-time                             Information Technology   \n",
       "7        Full-time                             Information Technology   \n",
       "8        Full-time             Engineering and Information Technology   \n",
       "9       Internship             Engineering and Information Technology   \n",
       "10       Full-time  Information Technology, Consulting, and Engine...   \n",
       "11       Full-time                             Information Technology   \n",
       "12       Full-time                                         Management   \n",
       "13       Full-time             Engineering and Information Technology   \n",
       "14       Full-time             Engineering and Information Technology   \n",
       "15       Full-time                             Information Technology   \n",
       "16       Full-time                             Information Technology   \n",
       "17       Full-time                             Information Technology   \n",
       "18       Full-time                             Information Technology   \n",
       "19       Full-time  Information Technology, Consulting, and Engine...   \n",
       "\n",
       "                                           industries   posted_time  \\\n",
       "0                    Business Consulting and Services   4 hours ago   \n",
       "1                       IT Services and IT Consulting  15 hours ago   \n",
       "2                                Software Development  22 hours ago   \n",
       "3                                Software Development  22 hours ago   \n",
       "4                       IT Services and IT Consulting  18 hours ago   \n",
       "5                                 Internet Publishing  22 hours ago   \n",
       "6                                Software Development  12 hours ago   \n",
       "7                                Software Development  22 hours ago   \n",
       "8   Software Development, Technology, Information ...  13 hours ago   \n",
       "9                                 Internet Publishing  22 hours ago   \n",
       "10                      IT Services and IT Consulting  15 hours ago   \n",
       "11                               Software Development  22 hours ago   \n",
       "12                   Business Consulting and Services   4 hours ago   \n",
       "13  Software Development, Technology, Information ...  13 hours ago   \n",
       "14                               Software Development  22 hours ago   \n",
       "15                               Software Development  12 hours ago   \n",
       "16                               Software Development  22 hours ago   \n",
       "17                      IT Services and IT Consulting  18 hours ago   \n",
       "18                      IT Services and IT Consulting  13 hours ago   \n",
       "19                      IT Services and IT Consulting   9 hours ago   \n",
       "\n",
       "       applicants      job_id        date  \\\n",
       "0             N/A  4293521357  2025-08-31   \n",
       "1   37 applicants  4259080606  2025-08-31   \n",
       "2             N/A  4293451536  2025-08-31   \n",
       "3             N/A  4293366035  2025-08-31   \n",
       "4             N/A  4267490741  2025-08-31   \n",
       "5             N/A  4293448846  2025-08-31   \n",
       "6             N/A  4291579961  2025-08-31   \n",
       "7             N/A  4293443790  2025-08-31   \n",
       "8             N/A  4291714459  2025-08-31   \n",
       "9             N/A  4293448846  2025-08-31   \n",
       "10  37 applicants  4259080606  2025-08-31   \n",
       "11            N/A  4293366035  2025-08-31   \n",
       "12            N/A  4293521357  2025-08-31   \n",
       "13            N/A  4291714459  2025-08-31   \n",
       "14            N/A  4293451536  2025-08-31   \n",
       "15            N/A  4291579961  2025-08-31   \n",
       "16            N/A  4293443790  2025-08-31   \n",
       "17            N/A  4267490741  2025-08-31   \n",
       "18            N/A  4267490741  2025-08-31   \n",
       "19  37 applicants  4259080606  2025-08-31   \n",
       "\n",
       "                                         parsing_link  \\\n",
       "0   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "1   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "2   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "3   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "4   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "5   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "6   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "7   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "8   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "9   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "10  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "11  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "12  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "13  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "14  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "15  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "16  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "17  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "18  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "19  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "\n",
       "                                     job_posting_link           created_at  \n",
       "0   https://www.linkedin.com/jobs/view/lead-at-job...  2025-09-01 04:34:04  \n",
       "1   https://www.linkedin.com/jobs/view/cleared-dat...  2025-09-01 04:33:56  \n",
       "2   https://www.linkedin.com/jobs/view/sr-platform...  2025-09-01 04:33:47  \n",
       "3   https://www.linkedin.com/jobs/view/web-develop...  2025-09-01 04:33:36  \n",
       "4   https://www.linkedin.com/jobs/view/senior-data...  2025-09-01 04:33:25  \n",
       "5   https://www.linkedin.com/jobs/view/internships...  2025-09-01 04:33:15  \n",
       "6   https://www.linkedin.com/jobs/view/senior-back...  2025-09-01 04:33:03  \n",
       "7   https://www.linkedin.com/jobs/view/sr-security...  2025-09-01 04:32:52  \n",
       "8   https://www.linkedin.com/jobs/view/remote-sr-j...  2025-09-01 04:32:40  \n",
       "9   https://www.linkedin.com/jobs/view/internships...  2025-09-01 04:24:28  \n",
       "10  https://www.linkedin.com/jobs/view/cleared-dat...  2025-09-01 04:24:20  \n",
       "11  https://www.linkedin.com/jobs/view/web-develop...  2025-09-01 04:24:13  \n",
       "12  https://www.linkedin.com/jobs/view/lead-at-job...  2025-09-01 04:24:03  \n",
       "13  https://www.linkedin.com/jobs/view/remote-sr-j...  2025-09-01 04:23:52  \n",
       "14  https://www.linkedin.com/jobs/view/sr-platform...  2025-09-01 04:23:41  \n",
       "15  https://www.linkedin.com/jobs/view/senior-back...  2025-09-01 04:23:31  \n",
       "16  https://www.linkedin.com/jobs/view/sr-security...  2025-09-01 04:23:21  \n",
       "17  https://www.linkedin.com/jobs/view/senior-data...  2025-09-01 04:23:10  \n",
       "18  https://www.linkedin.com/jobs/view/senior-data...  2025-08-31 23:18:59  \n",
       "19  https://www.linkedin.com/jobs/view/cleared-dat...  2025-08-31 23:18:55  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 20 most recent jobs with enhanced data structure including company information\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        company,\n",
    "        company_size,\n",
    "        company_followers,\n",
    "        company_industry,\n",
    "        title,\n",
    "        location,\n",
    "        work_location_type,\n",
    "        level,\n",
    "        salary_range,\n",
    "        employment_type,\n",
    "        job_function,\n",
    "        industries,\n",
    "        posted_time,\n",
    "        applicants,\n",
    "        job_id,\n",
    "        date,\n",
    "        parsing_link,\n",
    "        job_posting_link,\n",
    "        created_at\n",
    "    FROM jobs \n",
    "    ORDER BY created_at DESC \n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "\n",
    "    top_jobs_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(f\"ðŸ“Š Enhanced Job Data Analysis with Company Intelligence\")\n",
    "print(f\"Database contains: {len(top_jobs_df)} recent jobs\")\n",
    "print(f\"Columns: {top_jobs_df.shape[1]} (20-column structure with company info)\")\n",
    "print(f\"\\nColumn names: {list(top_jobs_df.columns)}\")\n",
    "top_jobs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f84df63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENHANCED JOB LISTINGS WITH LOCATION & COMPANY INTELLIGENCE\n",
      "================================================================================\n",
      "Showing first 5 of 20 jobs:\n",
      "\n",
      "ðŸ“‹ JOB #1\n",
      "Title: Senior Data Center Capacity Engineer\n",
      "Company: CyrusOne\n",
      "ðŸ¢ Company Info: ðŸ‘¥ Size: 822 employees | ðŸ“Š Followers: 52,862 followers | ðŸ­ Industry: CyrusOne\n",
      "ðŸ“ Location: San Antonio, TX\n",
      "ðŸ”„ Work Type: Hybrid\n",
      "ðŸŽ¯ Level: Mid-Senior level\n",
      "ðŸ“ Employment: Full-time\n",
      "âš™ï¸ Function: Information Technology\n",
      "ðŸ­ Industries: IT Services and IT Consulting\n",
      "ðŸ‘¥ Applicants: N/A\n",
      "ðŸ“… Posted: 13 hours ago\n",
      "ðŸ”— LinkedIn URL: https://www.linkedin.com/jobs/view/senior-data-center-capacity-engineer-at-cyrusone-4267490741?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ JOB #2\n",
      "Title: Cleared Data Center Mechanical Field Engineer, ADC Field Engineering\n",
      "Company: Amazon Web Services (AWS)\n",
      "ðŸ¢ Company Info: ðŸ‘¥ Size: 492 employees | ðŸ“Š Followers: 363 followers\n",
      "ðŸ“ Location: San Antonio, TX\n",
      "ðŸ¢ Work Type: On-site\n",
      "ðŸŽ¯ Level: Not Applicable\n",
      "ðŸ“ Employment: Full-time\n",
      "âš™ï¸ Function: Information Technology, Consulting, and Engineering\n",
      "ðŸ­ Industries: IT Services and IT Consulting\n",
      "ðŸ‘¥ Applicants: 37 applicants\n",
      "ðŸ“… Posted: 9 hours ago\n",
      "ðŸ”— LinkedIn URL: https://www.linkedin.com/jobs/view/cleared-data-center-mechanical-field-engineer-adc-field-engineering-at-amazon-web-services-aws-4259080606?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ JOB #3\n",
      "Title: Sr. Security Engineer (Ruby on Rails experience required)\n",
      "Company: Aha!\n",
      "ðŸ“ Location: San Antonio, TX\n",
      "ðŸ  Work Type: Remote\n",
      "ðŸŽ¯ Level: Mid-Senior level\n",
      "ðŸ“ Employment: Full-time\n",
      "âš™ï¸ Function: Information Technology\n",
      "ðŸ­ Industries: Software Development\n",
      "ðŸ‘¥ Applicants: N/A\n",
      "ðŸ“… Posted: 17 hours ago\n",
      "ðŸ”— LinkedIn URL: https://www.linkedin.com/jobs/view/sr-security-engineer-ruby-on-rails-experience-required-at-aha%21-4293443790?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ JOB #4\n",
      "Title: Sr. Platform Engineer\n",
      "Company: Aha!\n",
      "ðŸ“ Location: San Antonio, TX\n",
      "ðŸ  Work Type: Remote\n",
      "ðŸŽ¯ Level: Mid-Senior level\n",
      "ðŸ“ Employment: Full-time\n",
      "âš™ï¸ Function: Engineering and Information Technology\n",
      "ðŸ­ Industries: Software Development\n",
      "ðŸ‘¥ Applicants: N/A\n",
      "ðŸ“… Posted: 17 hours ago\n",
      "ðŸ”— LinkedIn URL: https://www.linkedin.com/jobs/view/sr-platform-engineer-at-aha%21-4293451536?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ JOB #5\n",
      "Title: Senior Back-End Developer\n",
      "Company: Jobs via Dice\n",
      "ðŸ¢ Company Info: ðŸ‘¥ Size: 1 employees | ðŸ“Š Followers: 173 followers\n",
      "ðŸ“ Location: San Antonio, TX\n",
      "ðŸ¢ Work Type: On-site\n",
      "ðŸŽ¯ Level: Mid-Senior level\n",
      "ðŸ’° Salary: $145,000.00/yr - $170,000.00/yr\n",
      "ðŸ“ Employment: Full-time\n",
      "âš™ï¸ Function: Information Technology\n",
      "ðŸ­ Industries: Software Development\n",
      "ðŸ‘¥ Applicants: N/A\n",
      "ðŸ“… Posted: 7 hours ago\n",
      "ðŸ”— LinkedIn URL: https://www.linkedin.com/jobs/view/senior-back-end-developer-at-jobs-via-dice-4291579961?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "\n",
      "... and 15 more jobs in the database\n",
      "ðŸ’¡ Tip: Run the statistics cell below for a summary of all jobs\n"
     ]
    }
   ],
   "source": [
    "# Display detailed information for each job with enhanced data including company info (limited output)\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED JOB LISTINGS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Limit to first 5 jobs to prevent excessive output\n",
    "    display_limit = min(5, len(top_jobs_df))\n",
    "    print(f\"Showing first {display_limit} of {len(top_jobs_df)} jobs:\\n\")\n",
    "\n",
    "    for idx in range(display_limit):\n",
    "        job = top_jobs_df.iloc[idx]\n",
    "        print(f\"ðŸ“‹ JOB #{idx + 1}\")\n",
    "        print(f\"Title: {job['title']}\")\n",
    "        print(f\"Company: {job['company']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_info = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_info.append(f\"ðŸ‘¥ Size: {job['company_size']}\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_info.append(f\"ðŸ“Š Followers: {job['company_followers']}\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_info.append(f\"ðŸ­ Industry: {job['company_industry']}\")\n",
    "\n",
    "        if company_info:\n",
    "            print(f\"ðŸ¢ Company Info: {' | '.join(company_info)}\")\n",
    "\n",
    "        # Enhanced location information\n",
    "        if pd.notna(job[\"location\"]) and job[\"location\"]:\n",
    "            print(f\"ðŸ“ Location: {job['location']}\")\n",
    "\n",
    "        if pd.notna(job[\"work_location_type\"]) and job[\"work_location_type\"]:\n",
    "            # Use emoji for work type\n",
    "            work_type_emoji = {\"Remote\": \"ðŸ \", \"Hybrid\": \"ðŸ”„\", \"On-site\": \"ðŸ¢\"}\n",
    "            emoji = work_type_emoji.get(job[\"work_location_type\"], \"ðŸ“\")\n",
    "            print(f\"{emoji} Work Type: {job['work_location_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"level\"]) and job[\"level\"]:\n",
    "            print(f\"ðŸŽ¯ Level: {job['level']}\")\n",
    "\n",
    "        if pd.notna(job[\"salary_range\"]) and job[\"salary_range\"]:\n",
    "            print(f\"ðŸ’° Salary: {job['salary_range']}\")\n",
    "\n",
    "        if pd.notna(job[\"employment_type\"]) and job[\"employment_type\"]:\n",
    "            print(f\"ðŸ“ Employment: {job['employment_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_function\"]) and job[\"job_function\"]:\n",
    "            print(f\"âš™ï¸ Function: {job['job_function']}\")\n",
    "\n",
    "        if pd.notna(job[\"industries\"]) and job[\"industries\"]:\n",
    "            print(f\"ðŸ­ Industries: {job['industries']}\")\n",
    "\n",
    "        if pd.notna(job[\"applicants\"]) and job[\"applicants\"]:\n",
    "            print(f\"ðŸ‘¥ Applicants: {job['applicants']}\")\n",
    "\n",
    "        if pd.notna(job[\"posted_time\"]) and job[\"posted_time\"]:\n",
    "            print(f\"ðŸ“… Posted: {job['posted_time']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_posting_link\"]) and job[\"job_posting_link\"]:\n",
    "            print(f\"ðŸ”— LinkedIn URL: {job['job_posting_link']}\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    if len(top_jobs_df) > display_limit:\n",
    "        print(f\"\\n... and {len(top_jobs_df) - display_limit} more jobs in the database\")\n",
    "        print(\"ðŸ’¡ Tip: Run the statistics cell below for a summary of all jobs\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs found in database. Run 'make run-parser' first to collect job data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05cc1bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š ENHANCED JOB STATISTICS WITH LOCATION & COMPANY INTELLIGENCE\n",
      "======================================================================\n",
      "\n",
      "ðŸ¢ Top Companies:\n",
      "  â€¢ Jobs via Dice: 5 job(s)\n",
      "  â€¢ Aha!: 5 job(s)\n",
      "  â€¢ Amazon Web Services (AWS): 3 job(s)\n",
      "  â€¢ CyrusOne: 3 job(s)\n",
      "  â€¢ Lensa: 3 job(s)\n",
      "\n",
      "ðŸ¢ COMPANY INTELLIGENCE ANALYSIS:\n",
      "  ðŸ‘¥ Company Size Info Available: 11/20 jobs (55.0%)\n",
      "     Sample sizes: 822 employees, 492 employees, 1 employees\n",
      "  ðŸ“Š Company Followers Info: 11/20 jobs (55.0%)\n",
      "     Sample followers: 52,862 followers, 363 followers, 173 followers\n",
      "  ðŸ­ Company Industry Info: 3/20 jobs (15.0%)\n",
      "     Top industries: CyrusOne, Lensa, Amazon Web Services (AWS)\n",
      "\n",
      "ðŸ“ Top Locations:\n",
      "  â€¢ San Antonio, TX: 20 job(s)\n",
      "\n",
      "ðŸ  Work Location Types (Location Intelligence):\n",
      "  ðŸ¢ On-site: 9 job(s) (45.0%)\n",
      "  ðŸ  Remote: 8 job(s) (40.0%)\n",
      "  ðŸ”„ Hybrid: 3 job(s) (15.0%)\n",
      "\n",
      "ðŸŽ¯ Experience Levels:\n",
      "  â€¢ Mid-Senior level: 12 job(s)\n",
      "  â€¢ Not Applicable: 3 job(s)\n",
      "  â€¢ Internship: 3 job(s)\n",
      "  â€¢ Entry level: 2 job(s)\n",
      "\n",
      "ðŸ’¼ Employment Types:\n",
      "  â€¢ Full-time: 17 job(s)\n",
      "  â€¢ Internship: 3 job(s)\n",
      "\n",
      "âš™ï¸ Top Job Functions:\n",
      "  â€¢ Information Technology: 12 job(s)\n",
      "  â€¢ Engineering and Information Technology: 5 job(s)\n",
      "  â€¢ Information Technology, Consulting, and Engineering: 3 job(s)\n",
      "\n",
      "ðŸ’° Salary Information: 4 out of 20 jobs (20.0%)\n",
      "ðŸ‘¥ Applicant Count Available: 20 out of 20 jobs (100.0%)\n",
      "\n",
      "ðŸ“ˆ Data Quality Summary:\n",
      "  âœ… All jobs have location intelligence classification\n",
      "  âœ… Enhanced 20-column data structure with company info\n",
      "  âœ… Company intelligence extraction available\n",
      "  âœ… Comprehensive job metadata available\n"
     ]
    }
   ],
   "source": [
    "# Enhanced job statistics with location and company intelligence\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"ðŸ“Š ENHANCED JOB STATISTICS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Company distribution\n",
    "    company_counts = top_jobs_df[\"company\"].value_counts()\n",
    "    print(f\"\\nðŸ¢ Top Companies:\")\n",
    "    for company, count in company_counts.head().items():\n",
    "        print(f\"  â€¢ {company}: {count} job(s)\")\n",
    "\n",
    "    # NEW: Company intelligence analysis\n",
    "    print(f\"\\nðŸ¢ COMPANY INTELLIGENCE ANALYSIS:\")\n",
    "\n",
    "    # Company size analysis\n",
    "    company_size_data = top_jobs_df[\"company_size\"].dropna()\n",
    "    if not company_size_data.empty:\n",
    "        print(\n",
    "            f\"  ðŸ‘¥ Company Size Info Available: {len(company_size_data)}/{len(top_jobs_df)} jobs ({len(company_size_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(f\"     Sample sizes: {', '.join(company_size_data.head(3).astype(str))}\")\n",
    "    else:\n",
    "        print(f\"  ðŸ‘¥ Company Size Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company followers analysis\n",
    "    company_followers_data = top_jobs_df[\"company_followers\"].dropna()\n",
    "    if not company_followers_data.empty:\n",
    "        print(\n",
    "            f\"  ðŸ“Š Company Followers Info: {len(company_followers_data)}/{len(top_jobs_df)} jobs ({len(company_followers_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"     Sample followers: {', '.join(company_followers_data.head(3).astype(str))}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"  ðŸ“Š Company Followers Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company industry analysis\n",
    "    company_industry_data = top_jobs_df[\"company_industry\"].dropna()\n",
    "    if not company_industry_data.empty:\n",
    "        print(\n",
    "            f\"  ðŸ­ Company Industry Info: {len(company_industry_data)}/{len(top_jobs_df)} jobs ({len(company_industry_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        industry_counts = company_industry_data.value_counts().head(3)\n",
    "        print(f\"     Top industries: {', '.join(industry_counts.index)}\")\n",
    "    else:\n",
    "        print(f\"  ðŸ­ Company Industry Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Location distribution (enhanced)\n",
    "    location_counts = top_jobs_df[\"location\"].value_counts()\n",
    "    print(f\"\\nðŸ“ Top Locations:\")\n",
    "    for location, count in location_counts.head().items():\n",
    "        print(f\"  â€¢ {location}: {count} job(s)\")\n",
    "\n",
    "    # Work location type analysis\n",
    "    if \"work_location_type\" in top_jobs_df.columns:\n",
    "        work_type_counts = top_jobs_df[\"work_location_type\"].value_counts(dropna=True)\n",
    "        print(f\"\\nðŸ  Work Location Types (Location Intelligence):\")\n",
    "        for work_type, count in work_type_counts.items():\n",
    "            emoji = {\"Remote\": \"ðŸ \", \"Hybrid\": \"ðŸ”„\", \"On-site\": \"ðŸ¢\"}.get(\n",
    "                work_type, \"ðŸ“\"\n",
    "            )\n",
    "            percentage = count / len(top_jobs_df) * 100\n",
    "            print(f\"  {emoji} {work_type}: {count} job(s) ({percentage:.1f}%)\")\n",
    "\n",
    "    # Experience level distribution\n",
    "    if \"level\" in top_jobs_df.columns:\n",
    "        level_counts = top_jobs_df[\"level\"].value_counts(dropna=True)\n",
    "        if not level_counts.empty:\n",
    "            print(f\"\\nðŸŽ¯ Experience Levels:\")\n",
    "            for level, count in level_counts.items():\n",
    "                print(f\"  â€¢ {level}: {count} job(s)\")\n",
    "\n",
    "    # Employment type distribution\n",
    "    if \"employment_type\" in top_jobs_df.columns:\n",
    "        employment_counts = top_jobs_df[\"employment_type\"].value_counts(dropna=True)\n",
    "        if not employment_counts.empty:\n",
    "            print(f\"\\nðŸ’¼ Employment Types:\")\n",
    "            for emp_type, count in employment_counts.items():\n",
    "                print(f\"  â€¢ {emp_type}: {count} job(s)\")\n",
    "\n",
    "    # Job function analysis\n",
    "    if \"job_function\" in top_jobs_df.columns:\n",
    "        function_counts = top_jobs_df[\"job_function\"].value_counts(dropna=True)\n",
    "        if not function_counts.empty:\n",
    "            print(f\"\\nâš™ï¸ Top Job Functions:\")\n",
    "            for function, count in function_counts.head().items():\n",
    "                print(f\"  â€¢ {function}: {count} job(s)\")\n",
    "\n",
    "    # Salary information availability\n",
    "    salary_jobs = top_jobs_df[\"salary_range\"].notna().sum()\n",
    "    print(\n",
    "        f\"\\nðŸ’° Salary Information: {salary_jobs} out of {len(top_jobs_df)} jobs ({salary_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Applicant information\n",
    "    applicant_jobs = top_jobs_df[\"applicants\"].notna().sum()\n",
    "    print(\n",
    "        f\"ðŸ‘¥ Applicant Count Available: {applicant_jobs} out of {len(top_jobs_df)} jobs ({applicant_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸ“ˆ Data Quality Summary:\")\n",
    "    print(f\"  âœ… All jobs have location intelligence classification\")\n",
    "    print(f\"  âœ… Enhanced 20-column data structure with company info\")\n",
    "    print(f\"  âœ… Company intelligence extraction available\")\n",
    "    print(f\"  âœ… Comprehensive job metadata available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7613ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’° JOBS WITH SALARY INFORMATION + LOCATION & COMPANY INTELLIGENCE\n",
      "===========================================================================\n",
      " 1. Senior Back-End Developer at Jobs via Dice\n",
      "    ðŸ’° $145,000.00/yr - $170,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ¢ On-site\n",
      "    ðŸ¢ ðŸ‘¥ 1 employees employees | ðŸ“Š 173 followers followers\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 2. BI Developer/Reporting Analyst at Piper Companies\n",
      "    ðŸ’° $75,000.00/yr - $90,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ¢ On-site\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 3. Senior Back-End Developer at Jobs via Dice\n",
      "    ðŸ’° $145,000.00/yr - $170,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ¢ On-site\n",
      "    ðŸ¢ ðŸ‘¥ 1 employees employees | ðŸ“Š 173 followers followers\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 4. Senior Back-End Developer at Jobs via Dice\n",
      "    ðŸ’° $145,000.00/yr - $170,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ¢ On-site\n",
      "    ðŸ¢ ðŸ‘¥ 1 employees employees | ðŸ“Š 173 followers followers\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 5. BI Developer/Reporting Analyst at Piper Companies\n",
      "    ðŸ’° $75,000.00/yr - $90,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ¢ On-site\n",
      "    ðŸ¢ ðŸ‘¥ 140 employees employees | ðŸ“Š 62,419 followers followers | ðŸ­ Piper Companies\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 6. Senior Back-End Developer at Jobs via Dice\n",
      "    ðŸ’° $145,000.00/yr - $170,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ¢ On-site\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 7. BI Developer/Reporting Analyst at Piper Companies\n",
      "    ðŸ’° $75,000.00/yr - $90,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ¢ On-site\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 8. TeamCenter Developer at Tata Consultancy Services\n",
      "    ðŸ’° $110,000.00/yr - $150,000.00/yr\n",
      "    ðŸ“ Universal City, TX | ðŸ¢ On-site\n",
      "    ðŸ¢ ðŸ‘¥ 680104 employees employees | ðŸ“Š 17,773,812 followers followers | ðŸ­ Tata Consultancy Services\n",
      "    ðŸŽ¯ Entry level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      " 9. Platform Engineer (Hybrid) - 23372 at Enlighten\n",
      "    ðŸ’° $97,097.00/yr - $135,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ”„ Hybrid\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      "10. Senior Full Stack Developer at Jobs via Dice\n",
      "    ðŸ’° $92,000.00/yr - $153,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ  Remote\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      "11. Platform Engineer (Hybrid) - 23372 at Enlighten\n",
      "    ðŸ’° $97,097.00/yr - $135,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ”„ Hybrid\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      "12. TeamCenter Developer at Tata Consultancy Services\n",
      "    ðŸ’° $110,000.00/yr - $150,000.00/yr\n",
      "    ðŸ“ Universal City, TX | ðŸ¢ On-site\n",
      "    ðŸŽ¯ Entry level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      "13. Senior Full Stack Developer at Jobs via Dice\n",
      "    ðŸ’° $92,000.00/yr - $153,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ  Remote\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      "14. DevOps Engineer - 23884 at Enlighten\n",
      "    ðŸ’° $97,097.00/yr - $130,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ”„ Hybrid\n",
      "    ðŸŽ¯ Mid-Senior level\n",
      "    ðŸ“ Full-time\n",
      "\n",
      "15. Systems Engineer at Booz Allen Hamilton\n",
      "    ðŸ’° $52,900.00/yr - $108,000.00/yr\n",
      "    ðŸ“ San Antonio, TX | ðŸ  Remote\n",
      "    ðŸŽ¯ Not Applicable\n",
      "    ðŸ“ Full-time\n",
      "\n",
      "ðŸ“ˆ SALARY ANALYSIS BY WORK TYPE\n",
      "========================================\n",
      "ðŸ”„ Hybrid: 3 jobs with salary info\n",
      "ðŸ¢ On-site: 9 jobs with salary info\n",
      "ðŸ  Remote: 3 jobs with salary info\n",
      "\n",
      "ðŸ¢ COMPANY SIZE ANALYSIS FOR SALARY JOBS\n",
      "=============================================\n",
      "ðŸ’¼ Jobs with both salary and company size data: 5\n",
      "  â€¢ Jobs via Dice: 1 employees employees | $145,000.00/yr - $170,000.00/yr\n",
      "  â€¢ Jobs via Dice: 1 employees employees | $145,000.00/yr - $170,000.00/yr\n",
      "  â€¢ Jobs via Dice: 1 employees employees | $145,000.00/yr - $170,000.00/yr\n",
      "  â€¢ Piper Companies: 140 employees employees | $75,000.00/yr - $90,000.00/yr\n",
      "  â€¢ Tata Consultancy Services: 680104 employees employees | $110,000.00/yr - $150,000.00/yr\n"
     ]
    }
   ],
   "source": [
    "# Enhanced salary analysis with location and company intelligence\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    salary_query = \"\"\"\n",
    "    SELECT title, company, company_size, company_followers, company_industry,\n",
    "           salary_range, location, work_location_type, level, employment_type\n",
    "    FROM jobs \n",
    "    WHERE salary_range IS NOT NULL AND salary_range != ''\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 15\n",
    "    \"\"\"\n",
    "\n",
    "    salary_jobs = pd.read_sql_query(salary_query, conn)\n",
    "\n",
    "if not salary_jobs.empty:\n",
    "    print(\"ðŸ’° JOBS WITH SALARY INFORMATION + LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 75)\n",
    "    for idx, job in salary_jobs.iterrows():\n",
    "        # Work type emoji\n",
    "        work_emoji = {\"Remote\": \"ðŸ \", \"Hybrid\": \"ðŸ”„\", \"On-site\": \"ðŸ¢\"}.get(\n",
    "            job[\"work_location_type\"], \"ðŸ“\"\n",
    "        )\n",
    "\n",
    "        print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "        print(f\"    ðŸ’° {job['salary_range']}\")\n",
    "        print(f\"    ðŸ“ {job['location']} | {work_emoji} {job['work_location_type']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_details = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_details.append(f\"ðŸ‘¥ {job['company_size']} employees\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_details.append(f\"ðŸ“Š {job['company_followers']} followers\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_details.append(f\"ðŸ­ {job['company_industry']}\")\n",
    "\n",
    "        if company_details:\n",
    "            print(f\"    ðŸ¢ {' | '.join(company_details)}\")\n",
    "\n",
    "        if job[\"level\"]:\n",
    "            print(f\"    ðŸŽ¯ {job['level']}\")\n",
    "        if job[\"employment_type\"]:\n",
    "            print(f\"    ðŸ“ {job['employment_type']}\")\n",
    "        print()\n",
    "\n",
    "    # Salary analysis by work type\n",
    "    if \"work_location_type\" in salary_jobs.columns:\n",
    "        print(\"ðŸ“ˆ SALARY ANALYSIS BY WORK TYPE\")\n",
    "        print(\"=\" * 40)\n",
    "        work_type_salary = salary_jobs.groupby(\"work_location_type\").size()\n",
    "        for work_type, count in work_type_salary.items():\n",
    "            emoji = {\"Remote\": \"ðŸ \", \"Hybrid\": \"ðŸ”„\", \"On-site\": \"ðŸ¢\"}.get(\n",
    "                work_type, \"ðŸ“\"\n",
    "            )\n",
    "            print(f\"{emoji} {work_type}: {count} jobs with salary info\")\n",
    "\n",
    "    # NEW: Company size analysis for salary jobs\n",
    "    print(f\"\\nðŸ¢ COMPANY SIZE ANALYSIS FOR SALARY JOBS\")\n",
    "    print(\"=\" * 45)\n",
    "    company_size_salary = salary_jobs[salary_jobs[\"company_size\"].notna()]\n",
    "    if not company_size_salary.empty:\n",
    "        print(\n",
    "            f\"ðŸ’¼ Jobs with both salary and company size data: {len(company_size_salary)}\"\n",
    "        )\n",
    "        for idx, job in company_size_salary.head(5).iterrows():\n",
    "            print(\n",
    "                f\"  â€¢ {job['company']}: {job['company_size']} employees | {job['salary_range']}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"ðŸ“Š No jobs found with both salary and company size information\")\n",
    "        print(\n",
    "            \"ðŸ’¡ Run 'make run-parser' to collect fresh data with company intelligence\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(\"No jobs with salary information found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9879302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ LOCATION & COMPANY INTELLIGENCE ANALYSIS\n",
      "============================================================\n",
      "ðŸ“Š Location + Work Type + Company Intelligence Distribution:\n",
      "ðŸ¢ San Antonio, TX - On-site: 81 jobs\n",
      "    Companies: VETROMAC, Inherent Technologies, SwRI Structural Geology & Geomechanics... (+12 more)\n",
      "    Company Intel: ðŸ‘¥ 9 with size data | ðŸ­ 3 with industry data\n",
      "\n",
      "ðŸ  San Antonio, TX - Remote: 65 jobs\n",
      "    Companies: Raft, Mindrift, Lensa... (+8 more)\n",
      "    Company Intel: ðŸ‘¥ 3 with size data | ðŸ­ 6 with industry data\n",
      "\n",
      "ðŸ”„ San Antonio, TX - Hybrid: 61 jobs\n",
      "    Companies: GovCIO, USAA, Modern Technology Solutions... (+10 more)\n",
      "    Company Intel: ðŸ‘¥ 3 with size data | ðŸ­ 1 with industry data\n",
      "\n",
      "ðŸ¢ San Antonio, Texas Metropolitan Area - On-site: 11 jobs\n",
      "    Companies: Oteemo Inc., Mission Technologies,  a division of HII\n",
      "\n",
      "ðŸ  San Antonio, Texas Metropolitan Area - Remote: 4 jobs\n",
      "    Companies: Compri Consulting, Mission Technologies,  a division of HII\n",
      "\n",
      "ðŸ¢ Lackland Air Force Base, TX - On-site: 3 jobs\n",
      "    Companies: Knowesis Inc.\n",
      "\n",
      "ðŸ¢ Universal City, TX - On-site: 2 jobs\n",
      "    Companies: Tata Consultancy Services\n",
      "    Company Intel: ðŸ‘¥ 1 with size data | ðŸ­ 1 with industry data\n",
      "\n",
      "ðŸ¢ Texas, United States - On-site: 1 jobs\n",
      "    Companies: Frost\n",
      "\n",
      "ðŸŽ¯ WORK TYPE INTELLIGENCE SUMMARY:\n",
      "----------------------------------------\n",
      "ðŸ¢ On-site :  98 jobs ( 41.2%)\n",
      "ðŸ  Remote  :  69 jobs ( 29.0%)\n",
      "ðŸ”„ Hybrid  :  61 jobs ( 25.6%)\n",
      "\n",
      "ðŸ¢ COMPANY INTELLIGENCE SUMMARY:\n",
      "----------------------------------------\n",
      "ðŸ‘¥ Company Size Data:      16/238 jobs (  6.7%)\n",
      "ðŸ“Š Company Followers:      16/238 jobs (  6.7%)\n",
      "ðŸ­ Company Industry:       11/238 jobs (  4.6%)\n",
      "ðŸŽ¯ Complete Company Data:  16/238 jobs (  6.7%)\n",
      "\n",
      "âœ¨ Enhanced Intelligence Features:\n",
      "   ðŸŽ¯ Automatic location extraction from job postings\n",
      "   ðŸ¤– AI-powered work type classification\n",
      "   ðŸ¢ Company size, followers, and industry extraction\n",
      "   ðŸ“Š Enhanced analytics with location and company data\n",
      "   ðŸ’¾ 20-column output with integrated company information\n"
     ]
    }
   ],
   "source": [
    "# ðŸŽ¯ LOCATION & COMPANY INTELLIGENCE SHOWCASE\n",
    "print(\"ðŸŒ LOCATION & COMPANY INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get location intelligence statistics\n",
    "    location_intel_query = \"\"\"\n",
    "    SELECT \n",
    "        location,\n",
    "        work_location_type,\n",
    "        COUNT(*) as job_count,\n",
    "        GROUP_CONCAT(DISTINCT company) as companies,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as companies_with_size,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as companies_with_industry\n",
    "    FROM jobs \n",
    "    WHERE location IS NOT NULL\n",
    "    GROUP BY location, work_location_type\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    location_intel_df = pd.read_sql_query(location_intel_query, conn)\n",
    "\n",
    "if not location_intel_df.empty:\n",
    "    print(\"ðŸ“Š Location + Work Type + Company Intelligence Distribution:\")\n",
    "    for idx, row in location_intel_df.iterrows():\n",
    "        emoji = {\"Remote\": \"ðŸ \", \"Hybrid\": \"ðŸ”„\", \"On-site\": \"ðŸ¢\"}.get(\n",
    "            row[\"work_location_type\"], \"ðŸ“\"\n",
    "        )\n",
    "        companies = row[\"companies\"].split(\",\") if row[\"companies\"] else []\n",
    "\n",
    "        print(\n",
    "            f\"{emoji} {row['location']} - {row['work_location_type']}: {row['job_count']} jobs\"\n",
    "        )\n",
    "        if len(companies) <= 3:\n",
    "            print(f\"    Companies: {', '.join(companies)}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"    Companies: {', '.join(companies[:3])}... (+{len(companies)-3} more)\"\n",
    "            )\n",
    "\n",
    "        # NEW: Company intelligence stats\n",
    "        company_intel_info = []\n",
    "        if row[\"companies_with_size\"] > 0:\n",
    "            company_intel_info.append(f\"ðŸ‘¥ {row['companies_with_size']} with size data\")\n",
    "        if row[\"companies_with_industry\"] > 0:\n",
    "            company_intel_info.append(\n",
    "                f\"ðŸ­ {row['companies_with_industry']} with industry data\"\n",
    "            )\n",
    "\n",
    "        if company_intel_info:\n",
    "            print(f\"    Company Intel: {' | '.join(company_intel_info)}\")\n",
    "        print()\n",
    "\n",
    "    # Overall location intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        summary_query = \"\"\"\n",
    "        SELECT \n",
    "            work_location_type,\n",
    "            COUNT(*) as count,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM jobs), 1) as percentage\n",
    "        FROM jobs \n",
    "        WHERE work_location_type IS NOT NULL\n",
    "        GROUP BY work_location_type\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        summary_df = pd.read_sql_query(summary_query, conn)\n",
    "\n",
    "    print(\"ðŸŽ¯ WORK TYPE INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        emoji = {\"Remote\": \"ðŸ \", \"Hybrid\": \"ðŸ”„\", \"On-site\": \"ðŸ¢\"}.get(\n",
    "            row[\"work_location_type\"], \"ðŸ“\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{emoji} {row['work_location_type']:8s}: {row['count']:3d} jobs ({row['percentage']:5.1f}%)\"\n",
    "        )\n",
    "\n",
    "    # NEW: Company intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        company_intel_summary = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_jobs,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as jobs_with_size,\n",
    "            COUNT(CASE WHEN company_followers IS NOT NULL THEN 1 END) as jobs_with_followers,\n",
    "            COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as jobs_with_industry,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL AND company_followers IS NOT NULL THEN 1 END) as jobs_with_both\n",
    "        FROM jobs\n",
    "        \"\"\"\n",
    "        company_stats = pd.read_sql_query(company_intel_summary, conn).iloc[0]\n",
    "\n",
    "    print(f\"\\nðŸ¢ COMPANY INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    total = company_stats[\"total_jobs\"]\n",
    "    print(\n",
    "        f\"ðŸ‘¥ Company Size Data:     {company_stats['jobs_with_size']:3d}/{total} jobs ({company_stats['jobs_with_size']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ðŸ“Š Company Followers:     {company_stats['jobs_with_followers']:3d}/{total} jobs ({company_stats['jobs_with_followers']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ðŸ­ Company Industry:      {company_stats['jobs_with_industry']:3d}/{total} jobs ({company_stats['jobs_with_industry']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ðŸŽ¯ Complete Company Data: {company_stats['jobs_with_both']:3d}/{total} jobs ({company_stats['jobs_with_both']/total*100:5.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ¨ Enhanced Intelligence Features:\")\n",
    "    print(f\"   ðŸŽ¯ Automatic location extraction from job postings\")\n",
    "    print(f\"   ðŸ¤– AI-powered work type classification\")\n",
    "    print(f\"   ðŸ¢ Company size, followers, and industry extraction\")\n",
    "    print(f\"   ðŸ“Š Enhanced analytics with location and company data\")\n",
    "    print(f\"   ðŸ’¾ 20-column output with integrated company information\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"No location data found. Run 'make run-parser' to collect jobs with location & company intelligence.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79ac9006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” CURRENT COMPANY INTELLIGENCE COVERAGE\n",
      "==================================================\n",
      "ðŸ“Š Database-wide Company Intelligence:\n",
      "   Total jobs: 238\n",
      "   ðŸ‘¥ Company Size: 21 jobs (8.8%)\n",
      "   ðŸ“Š Company Followers: 21 jobs (8.8%)\n",
      "   ðŸ­ Company Industry: 19 jobs (8.0%)\n",
      "\n",
      "ðŸ¢ Examples of Company Intelligence:\n",
      "   1. CyrusOne\n",
      "      ðŸ‘¥ Size: 822 employees\n",
      "      ðŸ“Š Followers: 52,862 followers\n",
      "      ðŸ­ Industry: CyrusOne\n",
      "      Job: Senior Data Center Capacity Engineer\n",
      "\n",
      "   2. Amazon Web Services (AWS)\n",
      "      ðŸ‘¥ Size: 10,001+ employees\n",
      "      ðŸ“Š Followers: 10,274,592 followers\n",
      "      ðŸ­ Industry: IT Services and IT Consulting\n",
      "      Job: Cleared Data Center Mechanical Field Engineer, ADC Field Engineering\n",
      "\n",
      "   3. Aha!\n",
      "      ðŸ‘¥ Size: 51-200 employees\n",
      "      ðŸ“Š Followers: 116,162 followers\n",
      "      ðŸ­ Industry: Software Development\n",
      "      Job: Sr. Security Engineer (Ruby on Rails experience required)\n",
      "\n",
      "   4. Aha!\n",
      "      ðŸ‘¥ Size: 51-200 employees\n",
      "      ðŸ“Š Followers: 116,162 followers\n",
      "      ðŸ­ Industry: Software Development\n",
      "      Job: Sr. Platform Engineer\n",
      "\n",
      "   5. Jobs via Dice\n",
      "      ðŸ‘¥ Size: 1 employee\n",
      "      ðŸ“Š Followers: 274,169 followers\n",
      "      ðŸ­ Industry: Software Development\n",
      "      Job: Senior Back-End Developer\n",
      "\n",
      "   6. Lensa\n",
      "      ðŸ‘¥ Size: 419 employees\n",
      "      ðŸ“Š Followers: 140,099 followers\n",
      "      ðŸ­ Industry: Lensa\n",
      "      Job: Internships in Data Science, Math, Statistics or Operations Research\n",
      "\n",
      "   7. Piper Companies\n",
      "      ðŸ‘¥ Size: 501-1,000 employees\n",
      "      ðŸ“Š Followers: 62,421 followers\n",
      "      ðŸ­ Industry: Business Consulting and Services\n",
      "      Job: BI Developer/Reporting Analyst\n",
      "\n",
      "   8. Jobs via Dice\n",
      "      ðŸ‘¥ Size: 1 employee\n",
      "      ðŸ“Š Followers: 274,172 followers\n",
      "      ðŸ­ Industry: Software Development\n",
      "      Job: Web Developer\n",
      "\n",
      "   9. Jobs via Dice\n",
      "      ðŸ‘¥ Size: 1 employees\n",
      "      ðŸ“Š Followers: 173 followers\n",
      "      Job: Senior Back-End Developer\n",
      "\n",
      "   10. Amazon Web Services (AWS)\n",
      "      ðŸ‘¥ Size: 142495 employees\n",
      "      ðŸ“Š Followers: 10,274,566 followers\n",
      "      ðŸ­ Industry: Amazon Web Services (AWS)\n",
      "      Job: Cleared Data Center Mechanical Field Engineer, ADC Field Engineering\n",
      "\n",
      "âœ¨ The enhanced company parser successfully extracted information!\n",
      "ðŸ’¡ To improve coverage further, run: make fix-company-info\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” QUICK COMPANY INTELLIGENCE CHECK\n",
    "print(\"ðŸ” CURRENT COMPANY INTELLIGENCE COVERAGE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get current state of company fields\n",
    "    coverage_query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_jobs,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL AND company_size != '' THEN 1 END) as jobs_with_size,\n",
    "        COUNT(CASE WHEN company_followers IS NOT NULL AND company_followers != '' THEN 1 END) as jobs_with_followers,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL AND company_industry != '' THEN 1 END) as jobs_with_industry\n",
    "    FROM jobs\n",
    "    \"\"\"\n",
    "    coverage_stats = pd.read_sql_query(coverage_query, conn).iloc[0]\n",
    "    \n",
    "    print(f\"ðŸ“Š Database-wide Company Intelligence:\")\n",
    "    total = coverage_stats[\"total_jobs\"]\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(f\"   ðŸ‘¥ Company Size: {coverage_stats['jobs_with_size']} jobs ({coverage_stats['jobs_with_size']/total*100:.1f}%)\")\n",
    "    print(f\"   ðŸ“Š Company Followers: {coverage_stats['jobs_with_followers']} jobs ({coverage_stats['jobs_with_followers']/total*100:.1f}%)\")\n",
    "    print(f\"   ðŸ­ Company Industry: {coverage_stats['jobs_with_industry']} jobs ({coverage_stats['jobs_with_industry']/total*100:.1f}%)\")\n",
    "    \n",
    "    # Show some examples of extracted company info\n",
    "    sample_query = \"\"\"\n",
    "    SELECT company, company_size, company_followers, company_industry, title\n",
    "    FROM jobs \n",
    "    WHERE (company_size IS NOT NULL AND company_size != '') \n",
    "       OR (company_followers IS NOT NULL AND company_followers != '')\n",
    "       OR (company_industry IS NOT NULL AND company_industry != '')\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    \n",
    "    sample_companies = pd.read_sql_query(sample_query, conn)\n",
    "    \n",
    "    print(f\"\\nðŸ¢ Examples of Company Intelligence:\")\n",
    "    for idx, row in sample_companies.iterrows():\n",
    "        print(f\"   {idx+1}. {row['company']}\")\n",
    "        if row['company_size']:\n",
    "            print(f\"      ðŸ‘¥ Size: {row['company_size']}\")\n",
    "        if row['company_followers']:\n",
    "            print(f\"      ðŸ“Š Followers: {row['company_followers']}\")\n",
    "        if row['company_industry']:\n",
    "            print(f\"      ðŸ­ Industry: {row['company_industry']}\")\n",
    "        print(f\"      Job: {row['title']}\")\n",
    "        print()\n",
    "\n",
    "print(f\"âœ¨ The enhanced company parser successfully extracted information!\")\n",
    "print(f\"ðŸ’¡ To improve coverage further, run: make fix-company-info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27363121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¤ CSV EXPORT WITH ENHANCED DATA + COMPANY INTELLIGENCE\n",
      "=======================================================\n",
      "âœ… Jobs exported to: ../data/notebook_analysis_export.csv\n",
      "\n",
      "ðŸ“‹ Export Validation:\n",
      "   Shape: (230, 20)\n",
      "   Columns: 20 (should be 20)\n",
      "\n",
      "âœ… Column Validation:\n",
      "   ðŸŽ¯ Perfect! All 20 expected columns present\n",
      "\n",
      "ðŸ“Š Data Quality Check:\n",
      "   Location data: 220/230 jobs (95.7%)\n",
      "   Work type data: 220/230 jobs (95.7%)\n",
      "   Company data: 230/230 jobs\n",
      "   Company size: 6/230 jobs (2.6%)\n",
      "   Company followers: 6/230 jobs (2.6%)\n",
      "   Company industry: 0/230 jobs (0.0%)\n",
      "   Title data: 230/230 jobs\n",
      "\n",
      "ðŸŽ‰ SUCCESS: Enhanced LinkedIn parser with location & company intelligence is working perfectly!\n",
      "   ðŸ’¾ Database: data/jobs.db\n",
      "   ðŸ“¤ Export: ../data/notebook_analysis_export.csv\n",
      "   ðŸŽ¯ Use: make run-parser (to collect more jobs with company info)\n",
      "\n",
      "============================================================\n",
      "ðŸš€ ANALYSIS COMPLETE - Enhanced LinkedIn Parser with Company Intelligence Ready!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š EXPORT & DATA VALIDATION\n",
    "print(\"ðŸ“¤ CSV EXPORT WITH ENHANCED DATA + COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Export current job data to CSV in the main data folder\n",
    "csv_filename = db.export_jobs_to_csv(\"../data/notebook_analysis_export.csv\")\n",
    "print(f\"âœ… Jobs exported to: {csv_filename}\")\n",
    "\n",
    "# Validate the exported CSV structure\n",
    "if csv_filename:\n",
    "    import pandas as pd\n",
    "\n",
    "    exported_df = pd.read_csv(csv_filename)\n",
    "\n",
    "    print(f\"\\nðŸ“‹ Export Validation:\")\n",
    "    print(f\"   Shape: {exported_df.shape}\")\n",
    "    print(f\"   Columns: {exported_df.shape[1]} (should be 20)\")\n",
    "\n",
    "    expected_columns = [\n",
    "        \"id\",\n",
    "        \"company\",\n",
    "        \"company_size\",\n",
    "        \"company_followers\",\n",
    "        \"company_industry\",\n",
    "        \"title\",\n",
    "        \"location\",\n",
    "        \"work_location_type\",\n",
    "        \"level\",\n",
    "        \"salary_range\",\n",
    "        \"content\",\n",
    "        \"employment_type\",\n",
    "        \"job_function\",\n",
    "        \"industries\",\n",
    "        \"posted_time\",\n",
    "        \"applicants\",\n",
    "        \"job_id\",\n",
    "        \"date\",\n",
    "        \"parsing_link\",\n",
    "        \"job_posting_link\",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nâœ… Column Validation:\")\n",
    "    missing_cols = set(expected_columns) - set(exported_df.columns)\n",
    "    extra_cols = set(exported_df.columns) - set(expected_columns)\n",
    "\n",
    "    if not missing_cols and not extra_cols:\n",
    "        print(\"   ðŸŽ¯ Perfect! All 20 expected columns present\")\n",
    "    else:\n",
    "        if missing_cols:\n",
    "            print(f\"   âš ï¸  Missing columns: {missing_cols}\")\n",
    "        if extra_cols:\n",
    "            print(f\"   âž• Extra columns: {extra_cols}\")\n",
    "\n",
    "    print(f\"\\nðŸ“Š Data Quality Check:\")\n",
    "    print(\n",
    "        f\"   Location data: {exported_df['location'].notna().sum()}/{len(exported_df)} jobs ({exported_df['location'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Work type data: {exported_df['work_location_type'].notna().sum()}/{len(exported_df)} jobs ({exported_df['work_location_type'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company data: {exported_df['company'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company size: {exported_df['company_size'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_size'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company followers: {exported_df['company_followers'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_followers'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company industry: {exported_df['company_industry'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_industry'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Title data: {exported_df['title'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\nðŸŽ‰ SUCCESS: Enhanced LinkedIn parser with location & company intelligence is working perfectly!\"\n",
    "    )\n",
    "    print(f\"   ðŸ’¾ Database: data/jobs.db\")\n",
    "    print(f\"   ðŸ“¤ Export: {csv_filename}\")\n",
    "    print(f\"   ðŸŽ¯ Use: make run-parser (to collect more jobs with company info)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\n",
    "    \"ðŸš€ ANALYSIS COMPLETE - Enhanced LinkedIn Parser with Company Intelligence Ready!\"\n",
    ")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1107ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ RUNNING PARSER + DATA CLEANER PIPELINE\n",
      "==================================================\n",
      "ðŸ“¥ Step 1: Running LinkedIn Parser...\n",
      "Command: make run-parser\n",
      "âœ… Parser completed successfully!\n",
      "   âœ… Successfully parsed 8 jobs\n",
      "   ðŸ“Š Jobs exported to: data/jobs_export.csv\n",
      "\n",
      "ðŸ§¹ Step 2: Running Data Cleaner...\n",
      "Command: python -m genai_job_finder.data_cleaner.run_graph\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCommand: python -m genai_job_finder.data_cleaner.run_graph\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     cleaner_result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/alireza/.cache/pypoetry/virtualenvs/genai-job-finder-Y_k-9c-5-py3.12/bin/python\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenai_job_finder.data_cleaner.run_graph\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--db-path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/jobs.db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--verbose\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 10 minute timeout for AI processing\u001b[39;49;00m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cleaner_result.returncode == \u001b[32m0\u001b[39m:\n\u001b[32m     65\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Data cleaner completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:1209\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1206\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1211\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/subprocess.py:2115\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2108\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2109\u001b[39m                         stdout, stderr,\n\u001b[32m   2110\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2111\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2112\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2113\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2115\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2118\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2119\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ðŸ”„ RUN PARSER + CLEANER BACK TO BACK\n",
    "print(\"ðŸš€ RUNNING PARSER + DATA CLEANER PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Step 1: Run the parser to collect fresh job data\n",
    "print(\"ðŸ“¥ Step 1: Running LinkedIn Parser...\")\n",
    "print(\"Command: make run-parser\")\n",
    "try:\n",
    "    parser_result = subprocess.run(\n",
    "        [\"make\", \"run-parser\"],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300,  # 5 minute timeout\n",
    "    )\n",
    "\n",
    "    if parser_result.returncode == 0:\n",
    "        print(\"âœ… Parser completed successfully!\")\n",
    "        # Extract some stats from output if available\n",
    "        lines = parser_result.stdout.split(\"\\n\")\n",
    "        for line in lines[-10:]:  # Show last 10 lines\n",
    "            if line.strip() and (\n",
    "                \"saved\" in line.lower()\n",
    "                or \"exported\" in line.lower()\n",
    "                or \"jobs\" in line.lower()\n",
    "            ):\n",
    "                print(f\"   {line.strip()}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Parser completed with warnings:\")\n",
    "        print(f\"   Return code: {parser_result.returncode}\")\n",
    "        if parser_result.stderr:\n",
    "            print(f\"   Error: {parser_result.stderr[-500:]}\")  # Last 500 chars\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"â° Parser timeout after 5 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Parser error: {e}\")\n",
    "\n",
    "# Small delay between operations\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 2: Run the data cleaner on the fresh data\n",
    "print(f\"\\nðŸ§¹ Step 2: Running Data Cleaner...\")\n",
    "print(\"Command: python -m genai_job_finder.data_cleaner.run_graph\")\n",
    "try:\n",
    "    cleaner_result = subprocess.run(\n",
    "        [\n",
    "            \"/home/alireza/.cache/pypoetry/virtualenvs/genai-job-finder-Y_k-9c-5-py3.12/bin/python\",\n",
    "            \"-m\",\n",
    "            \"genai_job_finder.data_cleaner.run_graph\",\n",
    "            \"--db-path\",\n",
    "            \"data/jobs.db\",\n",
    "            \"--verbose\",\n",
    "        ],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=600,  # 10 minute timeout for AI processing\n",
    "    )\n",
    "\n",
    "    if cleaner_result.returncode == 0:\n",
    "        print(\"âœ… Data cleaner completed successfully!\")\n",
    "        # Extract processing summary\n",
    "        lines = cleaner_result.stdout.split(\"\\n\")\n",
    "        in_summary = False\n",
    "        for line in lines:\n",
    "            if \"PROCESSING SUMMARY\" in line:\n",
    "                in_summary = True\n",
    "                print(f\"\\nðŸ“Š {line}\")\n",
    "            elif in_summary and (\"=\" in line or line.strip() == \"\"):\n",
    "                if \"=\" in line:\n",
    "                    print(line)\n",
    "                    in_summary = False\n",
    "            elif in_summary:\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Data cleaner completed with issues:\")\n",
    "        print(f\"   Return code: {cleaner_result.returncode}\")\n",
    "        if cleaner_result.stderr:\n",
    "            print(f\"   Error: {cleaner_result.stderr[-500:]}\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"â° Data cleaner timeout after 10 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Data cleaner error: {e}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Pipeline Complete!\")\n",
    "print(\"   ðŸ“¥ Fresh job data collected\")\n",
    "print(\"   ðŸ§¹ AI-powered data cleaning applied\")\n",
    "print(\"   ðŸ’¾ Results available in cleaned_jobs table\")\n",
    "print(\"   ðŸ“Š Ready for enhanced analysis below â¬‡ï¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc70e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§¹ CLEANED JOBS TABLE ANALYSIS\n",
    "print(\"âœ¨ ANALYZING AI-CLEANED JOB DATA WITH COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if cleaned_jobs table exists\n",
    "    tables_query = (\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\"\n",
    "    )\n",
    "    table_exists = pd.read_sql_query(tables_query, conn)\n",
    "\n",
    "    if table_exists.empty:\n",
    "        print(\"âŒ No cleaned_jobs table found.\")\n",
    "        print(\"ðŸ’¡ Run the cell above to execute the parser + cleaner pipeline first.\")\n",
    "    else:\n",
    "        print(\"âœ… Cleaned jobs table found!\")\n",
    "\n",
    "        # Get basic stats\n",
    "        total_cleaned = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "        print(f\"ðŸ“Š Total cleaned jobs: {total_cleaned}\")\n",
    "\n",
    "        if total_cleaned > 0:\n",
    "            # Get the schema of cleaned table\n",
    "            schema_query = \"PRAGMA table_info(cleaned_jobs)\"\n",
    "            schema_df = pd.read_sql_query(schema_query, conn)\n",
    "            print(f\"ðŸ—ï¸ Table structure: {len(schema_df)} columns\")\n",
    "\n",
    "            # Sample of cleaned data with company information\n",
    "            sample_query = \"\"\"\n",
    "            SELECT \n",
    "                id, company, company_size, company_followers, company_industry,\n",
    "                title, location, \n",
    "                min_years_experience, experience_level_label,\n",
    "                work_location_type, employment_type,\n",
    "                min_salary, max_salary, mid_salary, content\n",
    "            FROM cleaned_jobs \n",
    "            ORDER BY id DESC \n",
    "            LIMIT 10\n",
    "            \"\"\"\n",
    "\n",
    "            cleaned_sample = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "            print(f\"\\nðŸ“‹ SAMPLE CLEANED JOBS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 70)\n",
    "            for idx, job in cleaned_sample.iterrows():\n",
    "                print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "                print(f\"    ðŸ“ {job['location']}\")\n",
    "\n",
    "                # NEW: Company information display\n",
    "                company_details = []\n",
    "                if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "                    company_details.append(f\"ðŸ‘¥ {job['company_size']} employees\")\n",
    "                if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "                    company_details.append(f\"ðŸ“Š {job['company_followers']} followers\")\n",
    "                if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "                    company_details.append(f\"ðŸ­ {job['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"    ðŸ¢ {' | '.join(company_details)}\")\n",
    "\n",
    "                # Experience info\n",
    "                if pd.notna(job[\"min_years_experience\"]) and pd.notna(\n",
    "                    job[\"experience_level_label\"]\n",
    "                ):\n",
    "                    print(\n",
    "                        f\"    ðŸŽ¯ Experience: {job['min_years_experience']} years â†’ {job['experience_level_label']}\"\n",
    "                    )\n",
    "\n",
    "                # Salary info\n",
    "                if pd.notna(job[\"min_salary\"]) and pd.notna(job[\"max_salary\"]):\n",
    "                    print(\n",
    "                        f\"    ðŸ’° Salary: ${job['min_salary']:,.0f} - ${job['max_salary']:,.0f} (Mid: ${job['mid_salary']:,.0f})\"\n",
    "                    )\n",
    "\n",
    "                # Work details\n",
    "                work_details = []\n",
    "                if pd.notna(job[\"work_location_type\"]):\n",
    "                    work_emoji = {\"Remote\": \"ðŸ \", \"Hybrid\": \"ðŸ”„\", \"On-site\": \"ðŸ¢\"}.get(\n",
    "                        job[\"work_location_type\"], \"ðŸ“\"\n",
    "                    )\n",
    "                    work_details.append(f\"{work_emoji} {job['work_location_type']}\")\n",
    "                if pd.notna(job[\"employment_type\"]):\n",
    "                    work_details.append(job[\"employment_type\"])\n",
    "                if work_details:\n",
    "                    print(f\"    ðŸ“ {' | '.join(work_details)}\")\n",
    "                print()\n",
    "\n",
    "cleaned_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ŠðŸ”„ BEFORE vs AFTER: Data Transformation Analysis with Company Intelligence\n",
    "print(\"ðŸ”„ ORIGINAL vs AI-CLEANED DATA COMPARISON (WITH COMPANY INTELLIGENCE)\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if both tables exist\n",
    "    original_exists = (\n",
    "        pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\"count\"]\n",
    "        > 0\n",
    "    )\n",
    "    cleaned_exists = (\n",
    "        len(\n",
    "            pd.read_sql_query(\n",
    "                \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\",\n",
    "                conn,\n",
    "            )\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "\n",
    "    if not cleaned_exists:\n",
    "        print(\"âŒ Need cleaned data for comparison\")\n",
    "        print(\"ðŸ’¡ Run: make run-pipeline\")\n",
    "    elif not original_exists:\n",
    "        print(\"âŒ No original data found\")\n",
    "    else:\n",
    "        cleaned_count = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "\n",
    "        if cleaned_count == 0:\n",
    "            print(\"ðŸ“­ Cleaned table is empty\")\n",
    "            print(\"ðŸ’¡ Run: make run-cleaner\")\n",
    "        else:\n",
    "            print(\"ðŸ“Š DATA TRANSFORMATION PIPELINE RESULTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            # Side-by-side comparison of same jobs including company info\n",
    "            comparison_query = \"\"\"\n",
    "            SELECT \n",
    "                o.id,\n",
    "                o.company,\n",
    "                o.company_size,\n",
    "                o.company_followers,\n",
    "                o.company_industry,\n",
    "                o.title,\n",
    "                o.location,\n",
    "                o.level as original_level,\n",
    "                o.salary_range as original_salary,\n",
    "                o.employment_type as original_employment,\n",
    "                c.min_years_experience as ai_years,\n",
    "                c.experience_level_label as ai_level,\n",
    "                CASE \n",
    "                    WHEN c.min_salary IS NOT NULL THEN c.min_salary || ' - ' || c.max_salary || ' (Mid: ' || c.mid_salary || ')'\n",
    "                    ELSE 'Not extracted'\n",
    "                END as ai_salary,\n",
    "                c.work_location_type as ai_work_type,\n",
    "                c.employment_type as ai_employment\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            ORDER BY o.id DESC\n",
    "            LIMIT 5\n",
    "            \"\"\"\n",
    "\n",
    "            comparison_df = pd.read_sql_query(comparison_query, conn)\n",
    "\n",
    "            print(\"ðŸ” DETAILED TRANSFORMATION EXAMPLES WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"(Showing how AI enhanced the original data)\")\n",
    "            print()\n",
    "\n",
    "            for idx, row in comparison_df.iterrows():\n",
    "                print(f\"ðŸ“‹ JOB {idx+1}: {row['title']} at {row['company']}\")\n",
    "                print(f\"   ðŸ“ Location: {row['location']}\")\n",
    "\n",
    "                # NEW: Company intelligence display\n",
    "                company_details = []\n",
    "                if pd.notna(row[\"company_size\"]) and row[\"company_size\"]:\n",
    "                    company_details.append(f\"ðŸ‘¥ {row['company_size']} employees\")\n",
    "                if pd.notna(row[\"company_followers\"]) and row[\"company_followers\"]:\n",
    "                    company_details.append(f\"ðŸ“Š {row['company_followers']} followers\")\n",
    "                if pd.notna(row[\"company_industry\"]) and row[\"company_industry\"]:\n",
    "                    company_details.append(f\"ðŸ­ {row['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"   ðŸ¢ Company Intel: {' | '.join(company_details)}\")\n",
    "                print()\n",
    "\n",
    "                # Experience comparison\n",
    "                print(\"   ðŸŽ¯ EXPERIENCE ANALYSIS:\")\n",
    "                print(f\"      Original: '{row['original_level'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_years']} years â†’ {row['ai_level']}\")\n",
    "                print()\n",
    "\n",
    "                # Salary comparison\n",
    "                print(\"   ðŸ’° SALARY INTELLIGENCE:\")\n",
    "                print(f\"      Original: '{row['original_salary'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_salary']}\")\n",
    "                print()\n",
    "\n",
    "                # Employment type comparison\n",
    "                print(\"   ðŸ“ EMPLOYMENT TYPE:\")\n",
    "                print(\n",
    "                    f\"      Original: '{row['original_employment'] or 'Not specified'}'\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"      AI Result: {row['ai_employment']} | Work Type: {row['ai_work_type']}\"\n",
    "                )\n",
    "                print()\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "            # Statistical improvements including company intelligence\n",
    "            print(\"ðŸ“ˆ STATISTICAL IMPROVEMENTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Count improvements\n",
    "            improvements_query = \"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_jobs,\n",
    "                -- Experience data\n",
    "                COUNT(CASE WHEN o.level IS NOT NULL AND o.level != '' THEN 1 END) as original_exp_data,\n",
    "                COUNT(CASE WHEN c.experience_level_label IS NOT NULL THEN 1 END) as ai_exp_data,\n",
    "                -- Salary data  \n",
    "                COUNT(CASE WHEN o.salary_range IS NOT NULL AND o.salary_range != '' THEN 1 END) as original_salary_data,\n",
    "                COUNT(CASE WHEN c.min_salary IS NOT NULL THEN 1 END) as ai_salary_data,\n",
    "                -- Work location data\n",
    "                COUNT(CASE WHEN c.work_location_type IS NOT NULL THEN 1 END) as ai_work_type_data,\n",
    "                -- Company intelligence data (already in original)\n",
    "                COUNT(CASE WHEN o.company_size IS NOT NULL THEN 1 END) as company_size_data,\n",
    "                COUNT(CASE WHEN o.company_followers IS NOT NULL THEN 1 END) as company_followers_data,\n",
    "                COUNT(CASE WHEN o.company_industry IS NOT NULL THEN 1 END) as company_industry_data\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "            improvements_stats = pd.read_sql_query(improvements_query, conn).iloc[0]\n",
    "            total = improvements_stats[\"total_jobs\"]\n",
    "\n",
    "            print(f\"ðŸŽ¯ Experience Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_exp_data']}/{total} jobs ({improvements_stats['original_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_exp_data']}/{total} jobs ({improvements_stats['ai_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            exp_improvement = (\n",
    "                improvements_stats[\"ai_exp_data\"]\n",
    "                - improvements_stats[\"original_exp_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{exp_improvement} jobs (+{exp_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"ðŸ’° Salary Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_salary_data']}/{total} jobs ({improvements_stats['original_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_salary_data']}/{total} jobs ({improvements_stats['ai_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            salary_improvement = (\n",
    "                improvements_stats[\"ai_salary_data\"]\n",
    "                - improvements_stats[\"original_salary_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{salary_improvement} jobs (+{salary_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"ðŸ  Work Location Type (New):\")\n",
    "            print(f\"   Before: 0/{total} jobs (0.0%) - Not available in original\")\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_work_type_data']}/{total} jobs ({improvements_stats['ai_work_type_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{improvements_stats['ai_work_type_data']} jobs (NEW FEATURE)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            # NEW: Company intelligence summary\n",
    "            print(f\"ðŸ¢ Company Intelligence (Integrated in Parser):\")\n",
    "            print(\n",
    "                f\"   Company Size:     {improvements_stats['company_size_data']}/{total} jobs ({improvements_stats['company_size_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Followers: {improvements_stats['company_followers_data']}/{total} jobs ({improvements_stats['company_followers_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Industry:  {improvements_stats['company_industry_data']}/{total} jobs ({improvements_stats['company_industry_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                \"   ðŸ’¡ Company data extracted during parsing phase, available in both tables\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-job-finder-Y_k-9c-5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
