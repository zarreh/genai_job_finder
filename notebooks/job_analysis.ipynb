{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be7e499",
   "metadata": {},
   "source": [
    "# Enhanced LinkedIn Job Database Analysis\n",
    "\n",
    "This notebook analyzes the LinkedIn job database with the new enhanced parser that includes:\n",
    "\n",
    "- **17-column output structure** (matching legacy format)\n",
    "- **Location intelligence** with automatic extraction\n",
    "- **Work type classification** (Remote/Hybrid/On-site)\n",
    "- **Enhanced data model** with comprehensive job information\n",
    "\n",
    "Run `make run-parser` first to collect fresh job data with location intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "741025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = (\n",
    "    Path(__file__).parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    ")\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from genai_job_finder.linkedin_parser.database import DatabaseManager\n",
    "from genai_job_finder.linkedin_parser.models import Job, JobRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1daf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/alireza/projects/genai_job_finder')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5a736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /home/alireza/projects/genai_job_finder/data/jobs.db\n",
      "Database exists: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db_path = project_root / \"data\" / \"jobs.db\"\n",
    "# db_path = project_root / \"test_jobs.db\"\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")\n",
    "\n",
    "# Create database manager\n",
    "db = DatabaseManager(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b1a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in database: 190\n",
      "Total job runs: 15\n",
      "\n",
      "Recent job runs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "search_query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location_filter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ba3184ba-2966-4f42-855c-6576eb08db3f",
       "rows": [
        [
         "0",
         "15",
         "data scientist",
         "San Antonio",
         "completed",
         "10",
         "2025-08-24 05:20:24"
        ],
        [
         "1",
         "14",
         "data scientist",
         "San Antonio",
         "pending",
         "0",
         "2025-08-22 20:53:14"
        ],
        [
         "2",
         "13",
         "data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-08-22 20:43:51"
        ],
        [
         "3",
         "12",
         "data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-08-22 02:51:16"
        ],
        [
         "4",
         "11",
         "data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-08-22 02:50:10"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>location_filter</th>\n",
       "      <th>status</th>\n",
       "      <th>job_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-08-24 05:20:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>pending</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-22 20:53:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-08-22 20:43:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-08-22 02:51:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-08-22 02:50:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    search_query location_filter     status  job_count  \\\n",
       "0  15  data scientist     San Antonio  completed         10   \n",
       "1  14  data scientist     San Antonio    pending          0   \n",
       "2  13  data scientist     San Antonio  completed         20   \n",
       "3  12  data scientist     San Antonio  completed         20   \n",
       "4  11  data scientist     San Antonio  completed         20   \n",
       "\n",
       "            created_at  \n",
       "0  2025-08-24 05:20:24  \n",
       "1  2025-08-22 20:53:14  \n",
       "2  2025-08-22 20:43:51  \n",
       "3  2025-08-22 02:51:16  \n",
       "4  2025-08-22 02:50:10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check database contents - get basic stats\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Count total jobs\n",
    "    total_jobs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\n",
    "        \"count\"\n",
    "    ]\n",
    "    print(f\"Total jobs in database: {total_jobs}\")\n",
    "\n",
    "    # Count job runs\n",
    "    total_runs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM job_runs\", conn).iloc[\n",
    "        0\n",
    "    ][\"count\"]\n",
    "    print(f\"Total job runs: {total_runs}\")\n",
    "\n",
    "    # Show recent runs\n",
    "    if total_runs > 0:\n",
    "        recent_runs = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT id, search_query, location_filter, status, job_count, created_at \n",
    "            FROM job_runs \n",
    "            ORDER BY created_at DESC \n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "            conn,\n",
    "        )\n",
    "        print(\"\\nRecent job runs:\")\n",
    "recent_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20c5edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Enhanced Job Data Analysis\n",
      "Database contains: 10 recent jobs\n",
      "Columns: 18 (17-column structure)\n",
      "\n",
      "Column names: ['id', 'company', 'title', 'location', 'work_location_type', 'level', 'salary_range', 'employment_type', 'job_function', 'industries', 'posted_time', 'applicants', 'job_id', 'date', 'parsing_link', 'job_posting_link', 'created_at', 'content']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "work_location_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_range",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industries",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "posted_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicants",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parsing_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_posting_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "665ea329-8ad5-4758-b3b0-08cc49994096",
       "rows": [
        [
         "0",
         "e2763d13-9861-4da5-881e-618a3bb9d022",
         "Enlighten",
         "DevOps Engineer - 23884",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         "$97,097.00/yr - $130,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "15 hours ago",
         "110 applicants",
         "4265158800",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4265158800",
         "https://www.linkedin.com/jobs/view/devops-engineer-23884-at-enlighten-4265158800?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:48",
         "Enlighten, honored as a Top Workplace from USA Today, is a leader in big data solution development and deployment, with expertise in cloud-based services, software and systems engineering, cyber capabilities, and data science. Enlighten provides continued innovation and proactivity in meeting our customers’ greatest challenges.\n\nWhy Enlighten?\n\nBenefits\n\nAt Enlighten, our team’s unwavering work ethic, top talent and celebration of innovative ideas have helped us thrive. We know that our employees are essential to our company’s success, so we seek to take care of you as much as you take care of us. Here are a few highlights of our benefits package:\n\n• 100% paid employee premium for healthcare, vision and dental plans.\n• 10% 401k benefit.\n• Generous PTO + 10 paid holidays.\n• Education/training allowances.\n\nAnticipated Salary Range: $97,097.00 - $130,000.00. The salary range for this role is intended as a good faith estimate based on the role's location, expectations, and responsibilities. When extending an offer, Enlighten takes a variety of factors into consideration which include, but are not limited to, the role's function, internal equity and a candidate's education or training, work experience, certifications and key skills. Occasionally positions/roles may include additional non-recurrent compensation and will be addressed by the recruiter during the interview process.\n\nJob Description\n\nEnlighten is seeking a highly motivated and experienced DevOps Engineer to join our fast-paced development team. The ideal candidate will have strong working knowledge in Linux systems administration, and a background in Big Data solutions, configuration management, automation, scripting, and AWS. The DevOps Engineer will be responsible for implementing infrastructure, automating deployment processes, and ensuring the reliability and scalability of our services. Work is performed on a San Antonio, TX customer site 5 days/week some weeks and some weeks it will be hybrid with the ability to be working from home. This will change as needed, so flexibility is key.\n\nIf you have a passion for DevOps and are interested in working with a dynamic and innovative team, we encourage you to apply for this exciting opportunity.\n\n#Mid-Senior Level\n\nEssential Job Responsibilities\n\n• Support development and deployment of infrastructure in AWS\n• Automate deployment processes and ensure reliability and scalability of services\n• Manage and maintain cloud infrastructure on AWS\n• Collaborate with development teams to integrate their applications into the infrastructure\n• Monitor and troubleshoot production systems and resolve issues as necessary\n• Continuously improve processes and tools to ensure high availability and performance\n• Stay current with new technologies and industry trends, continuously exploring new ways to improve our infrastructure\n• Other duties as assigned\n\nMinimum Qualifications\n\n• Security Clearance - A current TS/SCI U.S. Government Security clearance is required; U.S. citizenship required.\n• 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience.\n• Strong Knowledge of AWS services (EKS, EC2, EBS, S3, Lambda) and their application to deployment and management of infrastructure.\n• Proficient knowledge of Linux, including system administration and troubleshooting.\n• Proficient in configuration management tools such as Terraform and Ansible\n• Experience with application, container, and OS deployment, scaling, and management.\n• Ability to develop in multiple programming languages such as Python, Bash, or Go.\n• Familiarity with Git, Flux, and other development and deployment tools.\n• Excellent problem-solving skills and the ability to identify and troubleshoot complex issues\n• Excellent oral and written communication skills.\n• Understanding of AGILE software development methodologies and use of standard software development tool suites\n• Must be able to obtain Security+ certification within 60 days of hire.\n• Must be able to work daily on customer site in San Antonio, TX. Will work some days from home in a hybrid schedule as well. Flexibility is key to accommodate any schedules changes per the customer and team in place.\n\nPreferred Requirements\n\n• Security+ certification is highly desired.\n• Experience with big data technologies like: Hadoop, Accumulo, Ceph, Spark, NiFi, Kafka, PostgreSQL, ElasticSearch, Hive, Drill, Impala, Trino, Presto, etc.\n• Experience with containers, EKS, Diode, CI/CD, and Terraform are a plus.\n• Work could possibly require some on-call work.\n\nWe have many more additional great benefits/perks that you can find on our website at www.eitccorp.com [eitccorp.com].\n\n Show more\n\n Show less"
        ],
        [
         "1",
         "b1f485fb-9741-450f-9278-72301675ce8f",
         "Shrive Technologies",
         "Snowflake Developer with SQL, Python, DBT",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "9 hours ago",
         "N/A",
         "4290423063",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290423063",
         "https://www.linkedin.com/jobs/view/snowflake-developer-with-sql-python-dbt-at-shrive-technologies-4290423063?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:46",
         "Job Summary\n\nThe Senior Technical Lead will be responsible for leading technical teams and projects related to Snowflake, DBT, SQL, and Python. The role involves overseeing the design, development, and implementation of data solutions leveraging these technologies to meet business requirements. (1.) Key Responsibilities\n\n• Lead and manage technical teams in the development and implementation of snowflake data solutions.\n• Design, build, and optimize data models using snowflake and dbt for efficient data processing.\n• Develop and optimize sql queries for data extraction, transformation, and loading processes.\n• Utilize python for scripting and automation of data processes and workflows.\n• Collaborate with cross functional teams to understand data requirements and ensure the successful delivery of technical solutions.\n• Conduct code reviews, provide technical guidance, and mentor team members to enhance overall technical capabilities.\n• Troubleshoot technical issues and provide resolutions in a timely manner to ensure smooth project execution.\n\nSkill Requirements\n\n• Proficiency in snowflake for data warehousing and cloud data platform.\n• Experience with dbt (data build tool) for data transformation and modeling.\n• Strong command of sql for querying and manipulating data in databases.\n• Proficient in python programming for scripting, automation, and data manipulation.\n• Excellent problem-solving skills and the ability to communicate effectively with technical and nontechnical stakeholders.\n• Strong leadership skills to effectively lead and motivate technical teams towards project success.\n\n Show more\n\n Show less"
        ],
        [
         "2",
         "e3dd660c-0f65-4aec-894a-a6f68061b4ce",
         "H-E-B",
         "Software Engineer II-Data Solutions (San Antonio, Austin and Dallas)",
         "San Antonio, TX",
         "Remote",
         "Entry level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Retail",
         "16 hours ago",
         "N/A",
         "4290278923",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290278923",
         "https://www.linkedin.com/jobs/view/software-engineer-ii-data-solutions-san-antonio-austin-and-dallas-at-h-e-b-4290278923?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:44",
         "Responsibilities\n\nSince H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, make food decisions, and ultimately get food into their homes. This is an exciting time to join H-E-B Digital-we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience.\n\nAs a Software Engineer II, you'll deliver complex code solutions. You'll contribute to overall system design, architecture, security, scalability, reliability, application performance, and provide end-to-end support.\n\nOnce you're eligible, you'll become an Owner in the company, so we're looking for commitment, hard work, and focus on quality and Customer service. 'Partner-owned' means our most important resources--People--drive the innovation, growth, and success that make H-E-B The Greatest Omnichannel Retailing Company.\n\nDo You Have a\n\nHEART FOR PEOPLE... willing to provide support to junior developers?\n\nHEAD FOR BUSINESS... skills to effectively deliver code solutions and features?\n\nPASSION FOR RESULTS... drive to produce quality results with little direct supervision?\n\nEducation & Experience\n\n• Bachelor’s degree in Computer Science, Information Systems, or equivalent practical experience\n• 2+ years of hands-on experience in software engineering, DevOps, or data engineering roles\n• Proven track record of supporting and maintaining production-grade systems with a strong sense of ownership\n• Experience participating in on-call rotations for mission-critical applications\n\nTechnical Skills\n\n• Programming Languages: Proficient in Python (automation, data processing) and SQL\n• DevOps & Tooling: Hands-on experience with Terraform (IaC), Ansible (configuration management), Git, CI/CD platforms (GitLab, Jenkins), and Linux system administration\n• Cloud Platforms: Familiar with AWS services including EC2, RDS, S3, ALB, Lambda, and Glue; exposure to equivalent services in Azure or GCP\n• Data & Visualization: Skilled in data visualization tools such as Tableau, Looker, and Power BI; strong understanding of data warehousing and modeling concepts\n• ETL & Pipelines: Working knowledge of ETL processes and data pipeline architecture\n\nSoftware Engineering Expertise\n\n• Strong debugging and troubleshooting skills across infrastructure, services, and data workflows\n• Solid understanding of distributed systems, performance optimization, and service reliability engineering\n• Experience with Agile methodologies and iterative development practices\n\nPlatform & Architecture\n\n• Experience designing and managing cloud infrastructure (AWS/GCP), including VPC networking and security best practices\n• Proficient in deploying repeatable infrastructure using Terraform\n• Skilled in automating system provisioning and configuration with Ansible\n• Familiar with orchestrating data pipelines and integrating cloud storage/data lake solutions (e.g., S3, Glue, Athena)\n\nSpecialized Engineering Contributions\n\n• Infrastructure Automation: Designed and maintained infrastructure-as-code for multi-node Tableau clusters and supporting AWS services\n• Data Engineering: Built pipelines to extract data from Tableau’s Postgres repository, transform to Parquet format, and integrate with Glue for downstream analytics\n• Operational Reliability: Managed blue-green deployments, system upgrades, failovers, and implemented monitoring/alerting for performance and availability\n• Scripting & Tooling: Developed Python-based tools for system management, query automation, and batch processing\n\nDo you have what it takes to be an H-E-B Software Engineer II?\n\n• High degree of personal accountability to self and team for continued growth\n• Ability to operate independently while owning your effect on the organization.\n• Resilient and optimistic when faced with the unexpected\n• Can manage most ambiguity within scope of daily work\n\nand is willing to learn how to proactively disambiguate requirements.\n\n• Team player - Actively learning the team's domain by asking questions, sharing knowledge with their teammates, and contributing to their team's documentation. Collaborates well with team and partners outside the team (Product Management, Design, QA, etc.)\n• Committed to adding value by supporting the team, contributing your perspective, and committing to the right amount of work.\n• Growth Mindset - Ability to fail-forward, ask questions, apply coaching, and show a genuine desire to learn, grow, and teach. Serves as a model for more junior engineers and consistently demonstrates team, organization, and company values in daily work.\n• Self-starter - Proactive in seeking out help when unclear about priority and dependencies; take initiative to learn the team, the work, and the business.\n• Impact - Understands area of work and shares knowledge with others. Generously shares opinions, feelings, constructive feedback, and gives credit where it is due.\n• Connect - Learning to facilitate conversations to make sure all viewpoints are represented, and that bias is understood. Listens to opposing perspectives and works toward the best solution for all.\n\nCan you...\n\n• Travel by car or plane with overnight stays\n• Work extended hours; sit for extended periods\n• Work rotating and on-call schedules, as needed\n\n11-2024\n\n Show more\n\n Show less"
        ],
        [
         "3",
         "de58d8f7-b840-4ca9-bf13-84b00d96d833",
         "ClearanceJobs",
         "Tier 3 Level EM Packaging Support Services with Security Clearance",
         "San Antonio, TX",
         "Hybrid",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Defense and Space Manufacturing",
         "12 hours ago",
         "N/A",
         "4287660267",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4287660267",
         "https://www.linkedin.com/jobs/view/tier-3-level-em-packaging-support-services-with-security-clearance-at-clearancejobs-4287660267?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:42",
         "Koniag Data Solutions, LLC, a Koniag Government Services company, is seeking a Tier 3 Level EM Packaging Support Services to support KDS and our government customer at Joint Base San Antonio, TX. This position requires the candidate to be able to obtain a Public Trust. This position is for a Future New Business Opportunity. We offer competitive compensation and an extraordinary benefits package including health, dental and vision insurance, 401K with company matching, flexible spending accounts, paid holidays, three weeks paid time off, and more. Essential Functions, Responsibilities & Duties may include, but are not limited to:\n\n• Provides advanced technical expertise in software packaging, deployment, and management for the Defense Health Agency's enterprise environments.\n• Serves as a top-tier specialist in creating, testing, and maintaining software packages for deployment across the DHA's extensive network, including military hospitals, medical clinics, and dental clinics worldwide.\n• Develops and implements sophisticated packaging solutions for a wide range of applications, ensuring compatibility and security across diverse IT infrastructures.\n• Designs and maintains standardized packaging methodologies that align with DHA's architectural and technical designs for IT infrastructure systems. Ensures all packaged software meets DoD cybersecurity requirements, Risk Management Framework (RMF), and various DoD strategies including Zero Trust, ICAM, Digital Modernization, and Cybersecurity Reference Architecture.\n• Leads efforts in automating the packaging and deployment processes, leveraging advanced scripting and toolsets to improve efficiency and reduce errors.\n• Develops complex transforms and customizations to meet specific DHA requirements for application functionality and security. Provides expert-level support for software distribution systems, ensuring seamless delivery of packages to approximately 250,000 end-user devices across 250 global sites.\n• Plays a crucial role in the preparation and deployment of policies, applications, and operating systems, including applicable upgrades. Manages and optimizes the packaging and deployment aspects of the common system framework for centrally deploying, supporting, and monitoring applications.\n• Ensures all packaged solutions maintain high-availability, reliability, and security across the DHA's environments.\n• Contributes significantly to Configuration Management and Change Management processes, developing comprehensive technical documentation for all packaging and deployment procedures.\n• Participates in the accreditation of operational environments, ensuring packaged software meets all necessary security and compliance standards.\n• Works independently, providing guidance to lower-tier packaging teams and collaborating with other high-level technical experts across various IT disciplines.\n• Must be prepared to support 24-hour operational requirements as needed and contribute to maintaining the stability and continuity of the DHA's IT services. Education:\n• Bachelor's degree in Computer Science, Software Engineering, or a related technical field.\n• Advanced degree (Master's) preferred.\n• Relevant high-level certifications (e.g., Microsoft Certified: Azure Administrator Associate, SCCM, or equivalent) are highly desirable. Experience:\n• 8-10 years of progressive experience in enterprise software packaging and deployment, with at least 5 years in a Tier 3 or equivalent senior technical role.\n• Should have extensive experience in managing complex, large-scale software deployment projects, preferably in military or healthcare settings.\n• Demonstrated expertise in advanced packaging techniques, automation tools, and implementation of enterprise-wide deployment solutions are required. Requirement:\n• Ability to obtain a Public Trust Our Equal Employment Opportunity Policy The company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, ethnicity, sex, sexual orientation, gender or gender identity (except where gender is a bona fide occupational qualification), national origin or ancestry, age, disability, citizenship, military/veteran status, marital status, genetic information or any other characteristic protected by applicable federal, state, or local law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits, and all other privileges, terms, and conditions of employment. The company is dedicated to seeking all qualified applicants. If you require an accommodation to navigate or apply for a position on our website, please get in touch with Heaven Wood via e-mail at or by calling 703-488-9377 to request accommodations. Koniag Government Services (KGS) is an Alaska Native Owned corporation supporting the values and traditions of our native communities through an agile employee and corporate culture that delivers Enterprise Solutions, Professional Services and Operational Management to Federal Government Agencies. As a wholly owned subsidiary of Koniag, we apply our proven commercial solutions to a deep knowledge of Defense and Civilian missions to provide forward leaning technical, professional, and operational solutions. KGS enables successful mission outcomes for our customers through solution-oriented business partnerships and a commitment to exceptional service delivery. We ensure long-term success with a continuous improvement approach while balancing the collective interests of our customers, employees, and native communities. For more information, please visit www.koniag-gs.com . Equal Opportunity Employer/Veterans/Disabled. Shareholder Preference in accordance with Public Law 88-352\n\n Show more\n\n Show less"
        ],
        [
         "4",
         "275bb95f-1f3b-4289-a0f5-cd2318900fb8",
         "H-E-B",
         "Web Analyst II",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         null,
         "Full-time",
         "Research, Analyst, and Information Technology",
         "Retail",
         "16 hours ago",
         "N/A",
         "4290283453",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290283453",
         "https://www.linkedin.com/jobs/view/web-analyst-ii-at-h-e-b-4290283453?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:40",
         "Responsibilities\n\nAs a Web Analyst II, you'll support H-E-B's app / web properties, digital marketing, e-merchandizing and product teams by organizing and analyzing data, supporting tagging strategy, debugging implementations, and creating dashboards that provide insight on-site traffic patterns, marketing channel effectiveness (in-Store and online), feature usage, and customer engagement.\n\nOnce you're eligible, you'll become an Owner in the company, so we're looking for commitment, hard work, and focus on quality and Customer service. 'Partner-owned' means our most important resources--People--drive the innovation, growth, and success that makes H-E-B The Greatest Retailing Company.\n\nDo You Have a\n\nHEART FOR PEOPLE... desire to partner with business leaders to support data and technology requirements?\n\nHEAD FOR BUSINESS... advanced analytical skills? under-standing of SQL / Python / R in a Hadoop environment?\n\nPASSION FOR RESULTS... ability to leverage analytics to influence marketing strategies in order to drive sales?\n\nWe Are Looking For\n\n• 5+ years of experience in Amplitude or Google Analytics/ GA4 or Adobe Analytics, Excel, PowerPoint, Python/R, and SQL, BI Visualization Tools (Looker/Domo/Tableau/PowerBI/etc.)\n• advanced quantitative skills; ability to apply logical thought process to problem-solving\n\nWhat is the work?\n\nAnalytics\n\n• Develops standardized weekly / monthly dashboards; provides analysis and reporting of core website KPIs, effectiveness of new site feature launches, and testing / targeting efforts\n• Provides advice on experimental design, targeting, digital customer experience\n• Serves as an internal consultant on clickstream/ web Analytics capabilities and site tagging requirements\n• Supports digital marketing stakeholders / use of Salesforce / other CRM tool to enable customer campaign targeting\n• Serves as a consultant to the customer analytics team to ensure tracking is sufficient to measure test impacts\n• Uses SQL and Python or R in a Databricks environment to tie online / offline customer behaviors for targeting and measurement\n• Serves as a liaison between the business and IS to influence implementation plans / technology needs\n• Work with data engineering team to translates raw events to usable semantic layer to meet stakeholder needs\n• Provide end to end support of clickstream data life cycle (requirements gathering/tagging/UAT/QA/database org/dashboard/etc.)\n• Implements / improves website tagging process; assists with all QA tagging efforts throughout the site\n• Continuously reviews processes; leverages analytics data to recommend improvements\n• Prepares critical data for feedback to Merchant and Creative teams to drive higher sell-thru key items\n• Supports ad-hoc requests\n\nWhat is your background?\n\n• A related degree or comparable formal training, certification, or work experience\n• 5+ years of experience with Google Analytics or related analytic tool in an omni-channel retail environment\n• 3+ years of experience using SQL, Python, or R on structured or unstructured data\n• 3+ years of experience testing and targeting web tools\n\nDo you have what it takes to be a fit as an H-E-B Web Analyst II?\n\n• Comprehensive working knowledge of amplitude or Google Analytics/ GA4 or Adobe Analytics,, Excel, PowerPoint, Python/R, and SQL\n• Advanced analytic / quantitative skills\n• Strong verbal / written communication and presentation skills\n• Ability to apply logical thought process to problem-solving\n• Ability to analyze, synthesize, and distill large volumes of data down to key takeaways and/or visuals using BI tools\n• Ability to maintain and manage collaborative relationships with Partners and leadership\n• Ability to prioritize work with competing deadlines and frequent interruptions\n\nCan you...\n\n• Function in a fast-paced, retail, office environment\n• Travel by car or plane with overnight stays\n• Sit for extended periods\n• Work extended hours\n\nCPFA3232\n\nDATANL3232\n\n06-2018\n\n Show more\n\n Show less"
        ],
        [
         "5",
         "74da0d3e-3192-4865-836a-9587133eb312",
         "Amazon Web Services (AWS)",
         "Cleared Data Center Electrical Engineer, Field Engineering",
         "San Antonio, TX",
         "On-site",
         "Not Applicable",
         null,
         "Full-time",
         "Information Technology, Consulting, and Engineering",
         "IT Services and IT Consulting",
         "16 hours ago",
         "50 applicants",
         "4225750830",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4225750830",
         "https://www.linkedin.com/jobs/view/cleared-data-center-electrical-engineer-field-engineering-at-amazon-web-services-aws-4225750830?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:38",
         "Description\n\nWe have an immediate opening for a Field Engineer in the San Antonio, TX region.\n\nAs An Amazon Field Engineer, You Will Provide Full Life-cycle Support To AWS Data Centers From Design Inception Through Site Improvement And Maintenance. You Will Be The ‘go To’ Engineering Resource For Your Region When Technical Advice Is Needed, And Will Use Your Subject Matter Expertise And Engage With Diverse Teams To\n\n• Perform design and equipment submittal review for new Data Centers in your region.\n• Troubleshoot, conduct Root Cause Analysis (RCA) and create Corrective Action (CA) documentation for site/equipment failures.\n• Directly support operational issues with ad-hoc training, complex operating procedure reviews, including critical equipment, and event support.\n• Own the design for existing data center upgrades and design-solutions, which add capacity, improve availability, and increase efficiency.\n• Interface with internal data center design engineering team, server hardware team, environmental health and safety team to promote standards that maintain consistency and reliability in services delivered.\n• Work on concurrent projects, sometimes in multiple geographical regions.\n• Initiate and lead engineering site audits within Amazon’s owned or colo data centers. Produce reports outlining risks with recommended mitigations and remediation.\n• Act as resident engineer during new construction projects. Support construction, commissioning, and turnover.\n\nMust have a valid US driver's license and reliable personal transportation by start date.\n\nThis position requires that the candidate selected be a US Citizen and obtain and maintain an active TS/SCI security clearance with polygraph.\n\nKey job responsibilities\n\nRole\n\nAmazon's vision is to be the world's most customer-centric company, and this role is key to that vision. As a Field Engineer, you will be leading projects to fit out our data centers to meet ever-evolving customer needs as we continue expanding our fleet to hyper-scale. As an ideal candidate you:\n\n• Possess Strong Engineering Judgement and are able to provide recommendations despite uncertainty/ambiguity.\n• Are detail and data oriented?\n• Have experience solving problems with engineered solutions.\n• Have experience managing engineering projects and consultants.\n• Build trust and relationships with different stakeholders (e.g., Operations, Controls, Construction, Design, Commissioning, Product Managers, Technical Program Managers).\n• Are adaptable and inclined to get into the field to see things up close.\n• Excited about a mix of office and field work.\n\nA day in the life\n\nEach day you will interact with different teams responsible for all aspects of the data centers. You will prioritize your activities to support data center capacity availability and safety focusing on the actions that are most impactful. You will have the opportunity to work on projects locally and globally.\n\nIf you meet these qualifications, exude passion, and enjoy the challenge of innovative projects at hyper-scale, this job is for you!\n\nAbout The Team\n\nADC (Amazon Dedicated Cloud) Field Engineering provides engineering support to the data center operations personnel at sites supporting the US intelligence community.\n\nAWS Infrastructure Services owns the design, planning, delivery, and operation of all AWS global infrastructure. In other words, we’re the people who keep the cloud running. We support all AWS data centers and all of the servers, storage, networking, power, and cooling equipment that ensure our customers have continual access to the innovation they rely on. We work on the most challenging problems, with thousands of variables impacting the supply chain — and we’re looking for talented people who want to help.\n\nYou’ll join a diverse team of software, hardware, and network engineers, supply chain specialists, security experts, operations managers, and other vital roles. You’ll collaborate with people across AWS to help us deliver the highest standards for safety and security while providing seemingly infinite capacity at the lowest possible cost for our customers. And you’ll experience an inclusive culture that welcomes bold ideas and empowers you to own them to completion.\n\nAmazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.\n\nAmazon values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.\n\nWe value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.\n\nHere at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon conferences, inspire us to never stop embracing our uniqueness.\n\nWe’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.\n\nBasic Qualifications\n\n• Bachelor’s Degree in Electrical Engineering or equivalent experience.\n\nPreferred Qualifications\n\n• Organized and have the ability to set priorities and meet deadlines and budget and experience using a variety of web based and other software tools for calculation and data processing.\n• Direct experience with the design, construction, operation, or maintenance of mission critical facilities, especially data centers.\n• Experience as resident engineer or hands-on (in the field) design consultant or owner’s engineer and knowledge of building codes and regulations for your region.\n• Experience reading, interpreting, and creating construction drawings, specifications, and submittal documents. and ability to carry design concepts through exploration, development, and into deployment/mass production\n• Basic understanding of both mechanical and/or electrical equipment/design related to data centers (Including but not limited to: uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, fans, air economizers, water treatment, etc...), and EPMS/SCADA/BMS Controls system experience (software and/or hardware)\n\nAmazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.\n\nOur inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.\n\n**Company** - Amazon Data Services, Inc.\n\nJob ID: A2976064\n\n Show more\n\n Show less"
        ],
        [
         "6",
         "92a6cbea-5e0d-4a83-b4b0-dff0bc92544e",
         "Booz Allen Hamilton",
         "Systems Engineer",
         "San Antonio, TX",
         "Remote",
         "Not Applicable",
         "$52,900.00/yr - $108,000.00/yr",
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "19 hours ago",
         "N/A",
         "4279024755",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4279024755",
         "https://www.linkedin.com/jobs/view/systems-engineer-at-booz-allen-hamilton-4279024755?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:36",
         "Job Number: R0221318\n\nSystems Engineer\n\nThe Opportunity:\n\nAre you looking for an opportunity to combine your technical skills to develop and optimize cloud environments, provisioning computer networks, storage and virtual networks? With your expertise, you will harness and sharpen your skills to support our client mission to modernize their IT infrastructure and meet the most challenging missions.\n\nAs a Systems Engineer, you will use your experience with scripting technologies, system administration, and networking to assist a team of engineers focusing on building and deploying cloud infrastructure and applications. Your customer will trust you to fully design, implement, and secure these systems, as well as evolve them with new technologies as appropriate. You’ll analyze current infrastructure to understand how to make sustainable improvements to increase security, reliability and availability for mission-critical applications and infrastructure through use of modern automation and virtualization tools.\n\nJoin us. The world can’t wait.\n\nYou Have:\n\n• 1+ years of experience software development, system engineering, or cybersecurity\n• Experience with scripting languages, including Python, Bash, or JavaScript\n• Experience with cloud platforms, including Amazon AWS\n• Experience with container tools using Docker or Podman\n• Experience with Linux operating systems such as RedHat, Rocky, CentOS, Debian, or Ubuntu\n• Experience with building or maintaining workflows in continuous integration/continuous delivery (CI/CD) using tools such as Git, GitLab, or Jenkins\n• TS/SCI clearance\n• HS diploma or GED\n\nNice If You Have:\n\n• Experience working in the DoD or a military environment\n• Experience working within an Agile environment\n• Experience with cloud platforms including Azure or Google Cloud Platform (GCP)\n• Experience with container orchestration using Kubernetes and Helm\n• Experience with Infrastructure as Code (IaC) tools including Ansible or Terraform\n• Security+ Certification\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $52,900.00 to $108,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date.\n\nIdentity Statement\n\nAs part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.\n\nWork Model\n\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\n• If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.\n• If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.\n\nCommitment to Non-Discrimination\n\nAll qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.\n\n Show more\n\n Show less"
        ],
        [
         "7",
         "7f1c9c1b-5c0c-4b01-8523-92bab6665e8a",
         "Deloitte",
         "AI Data Scientist, Manager",
         "San Antonio, TX",
         "Hybrid",
         "Not Applicable",
         "$103,320.00/yr - $235,170.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Accounting, IT Services and IT Consulting, and Business Consulting and Services",
         "19 hours ago",
         "N/A",
         "4278988008",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278988008",
         "https://www.linkedin.com/jobs/view/ai-data-scientist-manager-at-deloitte-4278988008?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:35",
         "If you are a technology visionary with a passion for transforming global tax business with digital technology, consider working with the US Tax Transformation technology team. This is an exciting opportunity to support global execution of Deloitte's tax strategy as we shift from \"doing digital\" to \"being digital\" by reimagining how we engage with our clients, deliver our services, operate our business, and create value.\n\nWork you'll do\n\nAs a Deloitte Manager, AI Data Science Engineer, become a part of a cross-functional development team who is working with GenAI solutions for digital transformation across Enterprise Products.\n\nAdditional responsibilities include:\n\n• Collaborate with engineers, data scientists, and business analysts to understand requirements, refine models, and integrate LLMs into AI solutions\n• Incorporate RLHF and advanced techniques for tax-specific AI outputs.\n• Embed generative AI solutions into consolidation, reconciliation, and reporting processes.\n• Leverage LLMs to interpret unstructured tax documentation.\n• Development and implementation of Deep learning algorithms for AI solutions\n• Stay updated with recent trends in GENAI and apply the latest research and techniques to projects\n• Preprocess raw data, including text normalization, tokenization, and other techniques, to make it suitable for use with NLP models\n• Setup and train large language models and other state-of-the-art neural networks\n• Conduct thorough testing and validation to ensure accuracy and reliability of model implementations\n• Perform statistical analysis of results and optimize model performance for various computational environments, including cloud and edge computing platforms\n• Explore and propose innovative AI use cases to enhance tax functions.\n• Partner with tax, finance, and IT teams to integrate AI workflows.\n• Collaborate with legal teams to meet regulatory standards for tax data.\n• Perform model audits to identify and mitigate risks.\n• Monitor and optimize generative models for performance and scalability.\n\nThe Team\n\nDeloitte Tax LLP's Tax Transformation Office (TTO) is responsible for the design, development, and deployment of innovative, enterprise technology, tools, and standard processes to support the delivery of tax services. The TTO team focuses on enhancing Deloitte Tax LLP's ability to deliver comprehensive, value-added, and efficient tax services to our clients. It is a dynamic team with professionals of varying backgrounds from tax technical, technology development, change management, Six Sigma, and project management. The team consults and executes on a wide range of initiatives involving process and tool development and implementation including training development, engagement management, tool design, and implementation.\n\nQualifications And Skills\n\nRequired:\n\n• Ability to perform job responsibilities within a hybrid work model that requires US Tax professionals to co-locate in person 2 - 3 days per week.\n• Ability to travel 20%, on average, based on the work you do and the clients and industries/sectors you serve.\n• Bachelor's degree in computer science, Engineering, or a related field.\n• 5+ years of programming experience in Python, PyTorch, TensorFlow, and related libraries with demonstrated skills in Prompt Engineering techniques and various vector databases.\n• Evidenced understanding of object-oriented design patterns, concurrency/multithreading, and scalable AI and GenAI model deployment.\n• Proven, hands-on experience in developing, training, and fine-tuning LLMs and AI models.\n• Evidenced understanding and demonstrated experience in implementing techniques like CNN, RNN, GANs, RAG, Langchain, and Transformers.\n• One of the following active accreditations obtained:\n• Licensed CPA in state of practice/primary office if eligible to sit for the CPA\n• If not CPA eligible:\n• Licensed Attorney\n• Enrolled Agent\n• Technology Certifications:\n• Alteryx Designer- Advanced Certification\n• ASQ - American Society for Quality - Software Quality Engineer\n• AWS Certified Solutions Architect\n• CBAP® - Certified Business Analysis Professional\n• Certified in Risk and Information Systems Controls (CRISC)\n• Certified Information Systems Security Professional (CISSP)\n• Certified SAFe® Advanced Scrum Master\n• Certified SAFe® Agile Software Engineer\n• Certified SAFe® Agilist\n• Certified SAFe® Architect\n• Certified SAFe® DevOps Practitioner\n• Certified SAFe® Lean Portfolio Manager\n• Certified SAFe® Practitioner\n• Certified SAFe® Product Owner / Product Manager\n• Certified SAFe® Scrum Master\n• Certified Scrum Developer (CSD)\n• Certified Scrum Product Owner (CSPO)\n• Certified Secure Software Lifecycle Professional (CSSLP)\n• Certified Secure Software Lifecycle Professional (CSSLP) - (ISC)2\n• IASA's Certified IT Architect (CITA) (Level F or A)\n• ISTQB (International Software Testing Qualifications Board)\n• ITIL Certification\n• Java: Java EE Enterprise Architect 5+, Java SE 5+ Programmer, Java EE 5+ Web Component Develope\n• Lifecycle Management and Advanced Functional Testing Certifications (HP)\n• MCSD: Application Lifecycle Management Solutions Developer\n• MCSD: SharePoint\n• MCSD: Web Applications\n• Microsoft Azure\n• Microsoft Certified Solutions Developer (MCSD)\n• Microsoft Certified Solutions Expert (MCSE)\n• Microsoft MCSD Certification\n• Open Group Certified Architect (Open CA)\n• Open Group Certified IT Specialist (Open CITS)\n• Oracle Certified Professional\n• Professional Scrum Developer™ (PSD)\n• Professional Scrum Product Owner™(PSCPO) - SCRUM.org\n• Program Management Professional (PgMP)\n• Project Management Professional (PMP)\n• QAI Global Institute Certification\n• SEI - Software Engineering Institute Certification\n• Six Sigma (Green or Black Belt)\n• UX or UX Master Certification\n\nPreferred:\n\n• Proficiency in RegEx, Spacy, NLTK, and NLP techniques for text representation and semantic extraction.\n• Familiarity with Azure Cloud Computing Platform.\n• Experience with Docker, Kubernetes, CI/CD pipelines.\n• Experience with Deep learning, Computer Vision, CNN, RNN, LSTM.\n• Experience with Vector Databases (Milvus, Postgres, etc.), Database Technologies.\n\nThe wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $103,320 to $235,170.\n\nYou may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.\n\nInformation for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html\n\n Show more\n\n Show less"
        ],
        [
         "8",
         "f2ba1878-ca32-4262-9411-d322bd73c666",
         "Mission Technologies, a division of HII",
         "Platform Engineer (Hybrid) - 23372",
         "San Antonio, Texas Metropolitan Area",
         "Remote",
         "Mid-Senior level",
         "$97,097.00/yr - $135,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Defense and Space Manufacturing",
         "15 hours ago",
         "30 applicants",
         "4238042091",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4238042091",
         "https://www.linkedin.com/jobs/view/platform-engineer-hybrid-23372-at-mission-technologies-a-division-of-hii-4238042091?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:32",
         "Enlighten, honored as a Top Workplace from USA Today, is a leader in big data solution development and deployment, with expertise in cloud-based services, software and systems engineering, cyber capabilities, and data science. Enlighten provides continued innovation and proactivity in meeting our customers’ greatest challenges.\n\nWe recognize that the most effective environment for your projects doesn’t always look the same. Our hybrid work approach ensures that you can make lasting relationships with your team and collaborate in-person to get the job done—while having the flexibility to work from home when needed to achieve focused results.\n\nWhy Enlighten?\n\nBenefits\n\nAt Enlighten, our team’s unwavering work ethic, top talent and celebration of innovative ideas have helped us thrive. We know that our employees are essential to our company’s success, so we seek to take care of you as much as you take care of us. Here are a few highlights of our benefits package:\n\n• 100% paid employee premium for healthcare, vision and dental plans.\n• 10% 401k benefit.\n• Generous PTO + 10 paid holidays.\n• Education/training allowances.\n\nAnticipated Salary Range: $97,097.00 - $135,000.00. The salary range for this role is intended as a good faith estimate based on the role's location, expectations, and responsibilities. When extending an offer, Enlighten takes a variety of factors into consideration which include, but are not limited to, the role's function, internal equity and a candidate's education or training, work experience, certifications and key skills. Occasionally positions/roles may include additional non-recurrent compensation and will be addressed by the recruiter during the interview process.\n\nJob Description\n\nEnlighten is looking for a Cloud Platform Engineer with experience in Cloud technology (AWS), programming skills in languages like Python or Go, and a strong Linux foundation. Will significantly contribute to the development of custom software components and integration of open-source code to address complex problems through the use of cutting edge Big Data / Cloud technology. As a result, the candidate will be expected to work autonomously identifying and solving problems quickly while working toward broader strategic goals set by Architects on the team. Work is performed in a hybrid environment with a great team.\n\n#Mid-Senior Level\n\nEssential Job Responsibilities\n\n• The ideal candidate is a strong systems integrator with an eye for opportunity to enhance, optimize, or increase robustness of an existing code base.\n• The candidate should have experience with infrastructure as code and be able to leverage modern tools to define, build and manage virtual infrastructure in the cloud.\n• Design and implement core architecture and capabilities for software from prototype to operational applications.\n• Other duties as assigned.\n\nMinimum Qualifications\n\n• Security Clearance - A current U.S. Government Security clearance is not required at start, but will be processed for a Secret level clearance; U.S. citizenship required.\n• 5+ years of experience in Platform Engineering or Software Development (Python or Go) with Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience.\n• Must have experience developing and deploying infrastructure in AWS.\n• Experience with Kubernetes (or vendor flavor of Kubernetes).\n• Have a solid understanding of Linux systems, hosts, networks, security, applications and proficiency in shell scripting (Shell/Bash).\n• Excellent problem-solving skills and the ability to identify and troubleshoot complex issues.\n• Excellent oral and written communication skills.\n• Must be able to work in a hybrid environment, spending an average oof 2 days per week at our San Antonio office. Flexibility is essential to adapt to schedule changes as needed.\n\nPreferred Requirements\n\n• Prior experience or familiarity with DISA’s Big Data Platform or other Big Data systems (e.g. Cloudera’s Distribution of Hadoop, Hortonworks Data Platform, MapR, etc..) is a plus.\n• Experience with CI/CD pipelines (e.g. Gitlab-CI, Travis-CI, Jenkins, etc.)\n• Understanding of agile software development methodologies and use of standard software development tool suites. (e.g., JIRA, Confluence, Github, Gitlab, etc.)\n• Experience with puppet, ansible, maven, virtualization (ovirt, proxmox, vmware, etc)\n• DoD 8140 / 8570 IAT Level II compliance certifications may be required in this position as directed by the customer.\n\nWe have many more additional great benefits/perks that you can find on our website at www.eitccorp.com [eitccorp.com].\n\n Show more\n\n Show less"
        ],
        [
         "9",
         "a8df991f-076e-47fb-b155-c7fa4adfe614",
         "Frost",
         "Software Engineer II - Customer Data Platform",
         "Texas, United States",
         "On-site",
         "Associate",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Financial Services",
         "18 hours ago",
         "N/A",
         "4278903512",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278903512",
         "https://www.linkedin.com/jobs/view/software-engineer-ii-customer-data-platform-at-frost-4278903512?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:29",
         "**Immigration Sponsorship: Unfortunately, we currently are not able to sponsor or transfer a sponsorship to Frost. This includes, but is not limited to: H-1B, TN, OPT, O-1, H4EAD, F-1, L-1.**\n\n**This role is in San Antonio, Texas. The candidate for this role will have to go into the San Antonio, Texas corporate campus office (One Frost) 2 to 3 times per month.**\n\n**Job Description**\n\n**It’s about creating solutions that help people.**\n\nDo others often ask you for technology advice and assistance? Are you always looking for innovative ways to help people? Do you like having the autonomy to build new solutions from the ground up? If so, being a Software Engineer II at Frost could be the job for you.\n\nAt Frost, it’s about more than a job. It’s about having a flourishing career where you can thrive, both in and out of work. At Frost, we’re committed to fostering an environment that reflects our values and encourages team members to be the best they can be. In joining our adaptable, integrity-driven team, you’ll become part of Frost’s over 150-year legacy of providing unparalleled banking services.\n\n**Who You Are**\n\nAs a **Software Engineer II - Customer Data Platform**at Frost, *you* are our code guru, not only configuring the systems but understanding the why’s behind them. Our software engineers believe in collaboration, ingenuity, and truly want to drive design and change in the IT realm. In this role, you will be responsible for designing, configuring, testing, implementing, supporting, and documenting solutions for assigned applications across the organization. You welcome a challenge and want to provide next level experiences to every individual that uses our systems.\n\n**What You’ll Do**\n\n• Design, write, test, implement, and document solutions for assigned program modules\n• Collaborate with project teams and other Software Engineers to provide technical support\n• Support assigned IT systems/applications by troubleshooting and resolving defects\n• Always take action using Integrity, Caring, and Excellence to achieve all-win outcomes\n\n**What You’ll Need**\n\n• Bachelor’s degree in Computer Science, Engineering, in a related field, or equivalent experience\n• Demonstrated ability to independently identify program issues and develop the appropriate solution, typically requiring at least 2 years of experience\n• Proficiency in programming languages such as Python\n• Experience with streaming technologies like Kafka, Kinesis, or Spark Streaming\n• Strong understanding of data modeling, data warehousing, and SQL/NoSQL databases\n• Familiarity with cloud platforms such as AWS, GCP, or Azure\n• Experience working with ETL tools, data pipelines, and customer data platforms\n\n**Additional Preferred Skills**\n\n• Strong understanding of commonly-used concepts, practices, and procedures associated with programming\n• Experience with CDP vendors such as Treasure Data, Blue conic, Tealium or Segment.\n• Understanding of marketing technology (MarTech) stack and tools.\n• Familiarity with event-driven architecture and microservices.\n• Prior experience working in agile development environments\n• AI foundational skills ( Gen Ai, MCP, A2A, Adk or others )\n\n**Our Benefits**\n\nAt Frost, we care about your health, your family, and your future and strive to have our benefits reflect that. This includes:\n\n• Medical, dental, vision, long-term disability, and life insurance\n• 401(k) matching\n• Generous holiday and paid time off schedule\n• Tuition reimbursement\n• Extensive health and wellness programs, including our Employee Assistance Program\n• Referral bonus program + more!\n\nSince 1868, Frost has dedicated their expertise to provide exceptional banking, investment, and insurance services to businesses and individuals throughout Texas. Frost is one of the 50 largest U.S. banks by asset size and is a leader in banking customer satisfaction. At Frost, it’s about being part of something bigger. If this sounds like you, we encourage you to apply and see what’s possible at Frost.\n\n Show more\n\n Show less"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>work_location_type</th>\n",
       "      <th>level</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>posted_time</th>\n",
       "      <th>applicants</th>\n",
       "      <th>job_id</th>\n",
       "      <th>date</th>\n",
       "      <th>parsing_link</th>\n",
       "      <th>job_posting_link</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2763d13-9861-4da5-881e-618a3bb9d022</td>\n",
       "      <td>Enlighten</td>\n",
       "      <td>DevOps Engineer - 23884</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$97,097.00/yr - $130,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>110 applicants</td>\n",
       "      <td>4265158800</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/devops-engi...</td>\n",
       "      <td>2025-08-24 05:20:48</td>\n",
       "      <td>Enlighten, honored as a Top Workplace from USA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1f485fb-9741-450f-9278-72301675ce8f</td>\n",
       "      <td>Shrive Technologies</td>\n",
       "      <td>Snowflake Developer with SQL, Python, DBT</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290423063</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/snowflake-d...</td>\n",
       "      <td>2025-08-24 05:20:46</td>\n",
       "      <td>Job Summary\\n\\nThe Senior Technical Lead will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e3dd660c-0f65-4aec-894a-a6f68061b4ce</td>\n",
       "      <td>H-E-B</td>\n",
       "      <td>Software Engineer II-Data Solutions (San Anton...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Retail</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290278923</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>2025-08-24 05:20:44</td>\n",
       "      <td>Responsibilities\\n\\nSince H-E-B Digital Techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de58d8f7-b840-4ca9-bf13-84b00d96d833</td>\n",
       "      <td>ClearanceJobs</td>\n",
       "      <td>Tier 3 Level EM Packaging Support Services wit...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Defense and Space Manufacturing</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4287660267</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/tier-3-leve...</td>\n",
       "      <td>2025-08-24 05:20:42</td>\n",
       "      <td>Koniag Data Solutions, LLC, a Koniag Governmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275bb95f-1f3b-4289-a0f5-cd2318900fb8</td>\n",
       "      <td>H-E-B</td>\n",
       "      <td>Web Analyst II</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Research, Analyst, and Information Technology</td>\n",
       "      <td>Retail</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290283453</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/web-analyst...</td>\n",
       "      <td>2025-08-24 05:20:40</td>\n",
       "      <td>Responsibilities\\n\\nAs a Web Analyst II, you'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74da0d3e-3192-4865-836a-9587133eb312</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Cleared Data Center Electrical Engineer, Field...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology, Consulting, and Engine...</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>50 applicants</td>\n",
       "      <td>4225750830</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/cleared-dat...</td>\n",
       "      <td>2025-08-24 05:20:38</td>\n",
       "      <td>Description\\n\\nWe have an immediate opening fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>92a6cbea-5e0d-4a83-b4b0-dff0bc92544e</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Systems Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>$52,900.00/yr - $108,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4279024755</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/systems-eng...</td>\n",
       "      <td>2025-08-24 05:20:36</td>\n",
       "      <td>Job Number: R0221318\\n\\nSystems Engineer\\n\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7f1c9c1b-5c0c-4b01-8523-92bab6665e8a</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>AI Data Scientist, Manager</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>$103,320.00/yr - $235,170.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Accounting, IT Services and IT Consulting, and...</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4278988008</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/ai-data-sci...</td>\n",
       "      <td>2025-08-24 05:20:35</td>\n",
       "      <td>If you are a technology visionary with a passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f2ba1878-ca32-4262-9411-d322bd73c666</td>\n",
       "      <td>Mission Technologies, a division of HII</td>\n",
       "      <td>Platform Engineer (Hybrid) - 23372</td>\n",
       "      <td>San Antonio, Texas Metropolitan Area</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$97,097.00/yr - $135,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Defense and Space Manufacturing</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>30 applicants</td>\n",
       "      <td>4238042091</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/platform-en...</td>\n",
       "      <td>2025-08-24 05:20:32</td>\n",
       "      <td>Enlighten, honored as a Top Workplace from USA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a8df991f-076e-47fb-b155-c7fa4adfe614</td>\n",
       "      <td>Frost</td>\n",
       "      <td>Software Engineer II - Customer Data Platform</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Associate</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>18 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4278903512</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>2025-08-24 05:20:29</td>\n",
       "      <td>**Immigration Sponsorship: Unfortunately, we c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  e2763d13-9861-4da5-881e-618a3bb9d022   \n",
       "1  b1f485fb-9741-450f-9278-72301675ce8f   \n",
       "2  e3dd660c-0f65-4aec-894a-a6f68061b4ce   \n",
       "3  de58d8f7-b840-4ca9-bf13-84b00d96d833   \n",
       "4  275bb95f-1f3b-4289-a0f5-cd2318900fb8   \n",
       "5  74da0d3e-3192-4865-836a-9587133eb312   \n",
       "6  92a6cbea-5e0d-4a83-b4b0-dff0bc92544e   \n",
       "7  7f1c9c1b-5c0c-4b01-8523-92bab6665e8a   \n",
       "8  f2ba1878-ca32-4262-9411-d322bd73c666   \n",
       "9  a8df991f-076e-47fb-b155-c7fa4adfe614   \n",
       "\n",
       "                                   company  \\\n",
       "0                                Enlighten   \n",
       "1                      Shrive Technologies   \n",
       "2                                    H-E-B   \n",
       "3                            ClearanceJobs   \n",
       "4                                    H-E-B   \n",
       "5                Amazon Web Services (AWS)   \n",
       "6                      Booz Allen Hamilton   \n",
       "7                                 Deloitte   \n",
       "8  Mission Technologies, a division of HII   \n",
       "9                                    Frost   \n",
       "\n",
       "                                               title  \\\n",
       "0                            DevOps Engineer - 23884   \n",
       "1          Snowflake Developer with SQL, Python, DBT   \n",
       "2  Software Engineer II-Data Solutions (San Anton...   \n",
       "3  Tier 3 Level EM Packaging Support Services wit...   \n",
       "4                                     Web Analyst II   \n",
       "5  Cleared Data Center Electrical Engineer, Field...   \n",
       "6                                   Systems Engineer   \n",
       "7                         AI Data Scientist, Manager   \n",
       "8                 Platform Engineer (Hybrid) - 23372   \n",
       "9      Software Engineer II - Customer Data Platform   \n",
       "\n",
       "                               location work_location_type             level  \\\n",
       "0                       San Antonio, TX             Hybrid  Mid-Senior level   \n",
       "1                       San Antonio, TX            On-site       Entry level   \n",
       "2                       San Antonio, TX             Remote       Entry level   \n",
       "3                       San Antonio, TX             Hybrid       Entry level   \n",
       "4                       San Antonio, TX            On-site  Mid-Senior level   \n",
       "5                       San Antonio, TX            On-site    Not Applicable   \n",
       "6                       San Antonio, TX             Remote    Not Applicable   \n",
       "7                       San Antonio, TX             Hybrid    Not Applicable   \n",
       "8  San Antonio, Texas Metropolitan Area             Remote  Mid-Senior level   \n",
       "9                  Texas, United States            On-site         Associate   \n",
       "\n",
       "                      salary_range employment_type  \\\n",
       "0   $97,097.00/yr - $130,000.00/yr       Full-time   \n",
       "1                             None       Full-time   \n",
       "2                             None       Full-time   \n",
       "3                             None       Full-time   \n",
       "4                             None       Full-time   \n",
       "5                             None       Full-time   \n",
       "6   $52,900.00/yr - $108,000.00/yr       Full-time   \n",
       "7  $103,320.00/yr - $235,170.00/yr       Full-time   \n",
       "8   $97,097.00/yr - $135,000.00/yr       Full-time   \n",
       "9                             None       Full-time   \n",
       "\n",
       "                                        job_function  \\\n",
       "0             Engineering and Information Technology   \n",
       "1                             Information Technology   \n",
       "2             Engineering and Information Technology   \n",
       "3                             Information Technology   \n",
       "4      Research, Analyst, and Information Technology   \n",
       "5  Information Technology, Consulting, and Engine...   \n",
       "6                             Information Technology   \n",
       "7             Engineering and Information Technology   \n",
       "8             Engineering and Information Technology   \n",
       "9             Engineering and Information Technology   \n",
       "\n",
       "                                          industries   posted_time  \\\n",
       "0                               Software Development  15 hours ago   \n",
       "1                      IT Services and IT Consulting   9 hours ago   \n",
       "2                                             Retail  16 hours ago   \n",
       "3                    Defense and Space Manufacturing  12 hours ago   \n",
       "4                                             Retail  16 hours ago   \n",
       "5                      IT Services and IT Consulting  16 hours ago   \n",
       "6                      IT Services and IT Consulting  19 hours ago   \n",
       "7  Accounting, IT Services and IT Consulting, and...  19 hours ago   \n",
       "8                    Defense and Space Manufacturing  15 hours ago   \n",
       "9                                 Financial Services  18 hours ago   \n",
       "\n",
       "       applicants      job_id        date  \\\n",
       "0  110 applicants  4265158800  2025-08-24   \n",
       "1             N/A  4290423063  2025-08-24   \n",
       "2             N/A  4290278923  2025-08-24   \n",
       "3             N/A  4287660267  2025-08-24   \n",
       "4             N/A  4290283453  2025-08-24   \n",
       "5   50 applicants  4225750830  2025-08-24   \n",
       "6             N/A  4279024755  2025-08-24   \n",
       "7             N/A  4278988008  2025-08-24   \n",
       "8   30 applicants  4238042091  2025-08-24   \n",
       "9             N/A  4278903512  2025-08-24   \n",
       "\n",
       "                                        parsing_link  \\\n",
       "0  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "1  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "2  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "3  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "4  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "5  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "6  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "7  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "8  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "9  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "\n",
       "                                    job_posting_link           created_at  \\\n",
       "0  https://www.linkedin.com/jobs/view/devops-engi...  2025-08-24 05:20:48   \n",
       "1  https://www.linkedin.com/jobs/view/snowflake-d...  2025-08-24 05:20:46   \n",
       "2  https://www.linkedin.com/jobs/view/software-en...  2025-08-24 05:20:44   \n",
       "3  https://www.linkedin.com/jobs/view/tier-3-leve...  2025-08-24 05:20:42   \n",
       "4  https://www.linkedin.com/jobs/view/web-analyst...  2025-08-24 05:20:40   \n",
       "5  https://www.linkedin.com/jobs/view/cleared-dat...  2025-08-24 05:20:38   \n",
       "6  https://www.linkedin.com/jobs/view/systems-eng...  2025-08-24 05:20:36   \n",
       "7  https://www.linkedin.com/jobs/view/ai-data-sci...  2025-08-24 05:20:35   \n",
       "8  https://www.linkedin.com/jobs/view/platform-en...  2025-08-24 05:20:32   \n",
       "9  https://www.linkedin.com/jobs/view/software-en...  2025-08-24 05:20:29   \n",
       "\n",
       "                                             content  \n",
       "0  Enlighten, honored as a Top Workplace from USA...  \n",
       "1  Job Summary\\n\\nThe Senior Technical Lead will ...  \n",
       "2  Responsibilities\\n\\nSince H-E-B Digital Techno...  \n",
       "3  Koniag Data Solutions, LLC, a Koniag Governmen...  \n",
       "4  Responsibilities\\n\\nAs a Web Analyst II, you'l...  \n",
       "5  Description\\n\\nWe have an immediate opening fo...  \n",
       "6  Job Number: R0221318\\n\\nSystems Engineer\\n\\nTh...  \n",
       "7  If you are a technology visionary with a passi...  \n",
       "8  Enlighten, honored as a Top Workplace from USA...  \n",
       "9  **Immigration Sponsorship: Unfortunately, we c...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 20 most recent jobs with enhanced data structure\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        company,\n",
    "        title,\n",
    "        location,\n",
    "        work_location_type,\n",
    "        level,\n",
    "        salary_range,\n",
    "        employment_type,\n",
    "        job_function,\n",
    "        industries,\n",
    "        posted_time,\n",
    "        applicants,\n",
    "        job_id,\n",
    "        date,\n",
    "        parsing_link,\n",
    "        job_posting_link,\n",
    "        created_at,\n",
    "        content\n",
    "    FROM jobs \n",
    "    WHERE date = (SELECT MAX(date) FROM jobs)\n",
    "    ORDER BY created_at DESC \n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "\n",
    "    top_jobs_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(f\"📊 Enhanced Job Data Analysis\")\n",
    "print(f\"Database contains: {len(top_jobs_df)} recent jobs\")\n",
    "print(f\"Columns: {top_jobs_df.shape[1]} (17-column structure)\")\n",
    "print(f\"\\nColumn names: {list(top_jobs_df.columns)}\")\n",
    "top_jobs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d76327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlighten, honored as a Top Workplace from USA Today, is a leader in big data solution development and deployment, with expertise in cloud-based services, software and systems engineering, cyber capabilities, and data science. Enlighten provides continued innovation and proactivity in meeting our customers’ greatest challenges.\n",
      "\n",
      "Why Enlighten?\n",
      "\n",
      "Benefits\n",
      "\n",
      "At Enlighten, our team’s unwavering work ethic, top talent and celebration of innovative ideas have helped us thrive. We know that our employees are essential to our company’s success, so we seek to take care of you as much as you take care of us. Here are a few highlights of our benefits package:\n",
      "\n",
      "• 100% paid employee premium for healthcare, vision and dental plans.\n",
      "• 10% 401k benefit.\n",
      "• Generous PTO + 10 paid holidays.\n",
      "• Education/training allowances.\n",
      "\n",
      "Anticipated Salary Range: $97,097.00 - $130,000.00. The salary range for this role is intended as a good faith estimate based on the role's location, expectations, and responsibilities. When extending an offer, Enlighten takes a variety of factors into consideration which include, but are not limited to, the role's function, internal equity and a candidate's education or training, work experience, certifications and key skills. Occasionally positions/roles may include additional non-recurrent compensation and will be addressed by the recruiter during the interview process.\n",
      "\n",
      "Job Description\n",
      "\n",
      "Enlighten is seeking a highly motivated and experienced DevOps Engineer to join our fast-paced development team. The ideal candidate will have strong working knowledge in Linux systems administration, and a background in Big Data solutions, configuration management, automation, scripting, and AWS. The DevOps Engineer will be responsible for implementing infrastructure, automating deployment processes, and ensuring the reliability and scalability of our services. Work is performed on a San Antonio, TX customer site 5 days/week some weeks and some weeks it will be hybrid with the ability to be working from home. This will change as needed, so flexibility is key.\n",
      "\n",
      "If you have a passion for DevOps and are interested in working with a dynamic and innovative team, we encourage you to apply for this exciting opportunity.\n",
      "\n",
      "#Mid-Senior Level\n",
      "\n",
      "Essential Job Responsibilities\n",
      "\n",
      "• Support development and deployment of infrastructure in AWS\n",
      "• Automate deployment processes and ensure reliability and scalability of services\n",
      "• Manage and maintain cloud infrastructure on AWS\n",
      "• Collaborate with development teams to integrate their applications into the infrastructure\n",
      "• Monitor and troubleshoot production systems and resolve issues as necessary\n",
      "• Continuously improve processes and tools to ensure high availability and performance\n",
      "• Stay current with new technologies and industry trends, continuously exploring new ways to improve our infrastructure\n",
      "• Other duties as assigned\n",
      "\n",
      "Minimum Qualifications\n",
      "\n",
      "• Security Clearance - A current TS/SCI U.S. Government Security clearance is required; U.S. citizenship required.\n",
      "• 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience.\n",
      "• Strong Knowledge of AWS services (EKS, EC2, EBS, S3, Lambda) and their application to deployment and management of infrastructure.\n",
      "• Proficient knowledge of Linux, including system administration and troubleshooting.\n",
      "• Proficient in configuration management tools such as Terraform and Ansible\n",
      "• Experience with application, container, and OS deployment, scaling, and management.\n",
      "• Ability to develop in multiple programming languages such as Python, Bash, or Go.\n",
      "• Familiarity with Git, Flux, and other development and deployment tools.\n",
      "• Excellent problem-solving skills and the ability to identify and troubleshoot complex issues\n",
      "• Excellent oral and written communication skills.\n",
      "• Understanding of AGILE software development methodologies and use of standard software development tool suites\n",
      "• Must be able to obtain Security+ certification within 60 days of hire.\n",
      "• Must be able to work daily on customer site in San Antonio, TX. Will work some days from home in a hybrid schedule as well. Flexibility is key to accommodate any schedules changes per the customer and team in place.\n",
      "\n",
      "Preferred Requirements\n",
      "\n",
      "• Security+ certification is highly desired.\n",
      "• Experience with big data technologies like: Hadoop, Accumulo, Ceph, Spark, NiFi, Kafka, PostgreSQL, ElasticSearch, Hive, Drill, Impala, Trino, Presto, etc.\n",
      "• Experience with containers, EKS, Diode, CI/CD, and Terraform are a plus.\n",
      "• Work could possibly require some on-call work.\n",
      "\n",
      "We have many more additional great benefits/perks that you can find on our website at www.eitccorp.com [eitccorp.com].\n",
      "\n",
      " Show more\n",
      "\n",
      " Show less\n"
     ]
    }
   ],
   "source": [
    "print(top_jobs_df.loc[0, \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f84df63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENHANCED JOB LISTINGS WITH LOCATION INTELLIGENCE\n",
      "================================================================================\n",
      "Showing first 5 of 10 jobs:\n",
      "\n",
      "📋 JOB #1\n",
      "Title: DevOps Engineer - 23884\n",
      "Company: Enlighten\n",
      "📍 Location: San Antonio, TX\n",
      "🔄 Work Type: Hybrid\n",
      "🎯 Level: Mid-Senior level\n",
      "💰 Salary: $97,097.00/yr - $130,000.00/yr\n",
      "📝 Employment: Full-time\n",
      "⚙️ Function: Engineering and Information Technology\n",
      "🏭 Industries: Software Development\n",
      "👥 Applicants: 110 applicants\n",
      "📅 Posted: 15 hours ago\n",
      "🔗 LinkedIn URL: https://www.linkedin.com/jobs/view/devops-engineer-23884-at-enlighten-4265158800?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "📋 JOB #2\n",
      "Title: Snowflake Developer with SQL, Python, DBT\n",
      "Company: Shrive Technologies\n",
      "📍 Location: San Antonio, TX\n",
      "🏢 Work Type: On-site\n",
      "🎯 Level: Entry level\n",
      "📝 Employment: Full-time\n",
      "⚙️ Function: Information Technology\n",
      "🏭 Industries: IT Services and IT Consulting\n",
      "👥 Applicants: N/A\n",
      "📅 Posted: 9 hours ago\n",
      "🔗 LinkedIn URL: https://www.linkedin.com/jobs/view/snowflake-developer-with-sql-python-dbt-at-shrive-technologies-4290423063?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "📋 JOB #3\n",
      "Title: Software Engineer II-Data Solutions (San Antonio, Austin and Dallas)\n",
      "Company: H-E-B\n",
      "📍 Location: San Antonio, TX\n",
      "🏠 Work Type: Remote\n",
      "🎯 Level: Entry level\n",
      "📝 Employment: Full-time\n",
      "⚙️ Function: Engineering and Information Technology\n",
      "🏭 Industries: Retail\n",
      "👥 Applicants: N/A\n",
      "📅 Posted: 16 hours ago\n",
      "🔗 LinkedIn URL: https://www.linkedin.com/jobs/view/software-engineer-ii-data-solutions-san-antonio-austin-and-dallas-at-h-e-b-4290278923?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "📋 JOB #4\n",
      "Title: Tier 3 Level EM Packaging Support Services with Security Clearance\n",
      "Company: ClearanceJobs\n",
      "📍 Location: San Antonio, TX\n",
      "🔄 Work Type: Hybrid\n",
      "🎯 Level: Entry level\n",
      "📝 Employment: Full-time\n",
      "⚙️ Function: Information Technology\n",
      "🏭 Industries: Defense and Space Manufacturing\n",
      "👥 Applicants: N/A\n",
      "📅 Posted: 12 hours ago\n",
      "🔗 LinkedIn URL: https://www.linkedin.com/jobs/view/tier-3-level-em-packaging-support-services-with-security-clearance-at-clearancejobs-4287660267?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "📋 JOB #5\n",
      "Title: Web Analyst II\n",
      "Company: H-E-B\n",
      "📍 Location: San Antonio, TX\n",
      "🏢 Work Type: On-site\n",
      "🎯 Level: Mid-Senior level\n",
      "📝 Employment: Full-time\n",
      "⚙️ Function: Research, Analyst, and Information Technology\n",
      "🏭 Industries: Retail\n",
      "👥 Applicants: N/A\n",
      "📅 Posted: 16 hours ago\n",
      "🔗 LinkedIn URL: https://www.linkedin.com/jobs/view/web-analyst-ii-at-h-e-b-4290283453?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "\n",
      "... and 5 more jobs in the database\n",
      "💡 Tip: Run the statistics cell below for a summary of all jobs\n"
     ]
    }
   ],
   "source": [
    "# Display detailed information for each job with enhanced data (limited output)\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED JOB LISTINGS WITH LOCATION INTELLIGENCE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Limit to first 5 jobs to prevent excessive output\n",
    "    display_limit = min(5, len(top_jobs_df))\n",
    "    print(f\"Showing first {display_limit} of {len(top_jobs_df)} jobs:\\n\")\n",
    "\n",
    "    for idx in range(display_limit):\n",
    "        job = top_jobs_df.iloc[idx]\n",
    "        print(f\"📋 JOB #{idx + 1}\")\n",
    "        print(f\"Title: {job['title']}\")\n",
    "        print(f\"Company: {job['company']}\")\n",
    "\n",
    "        # Enhanced location information\n",
    "        if pd.notna(job[\"location\"]) and job[\"location\"]:\n",
    "            print(f\"📍 Location: {job['location']}\")\n",
    "\n",
    "        if pd.notna(job[\"work_location_type\"]) and job[\"work_location_type\"]:\n",
    "            # Use emoji for work type\n",
    "            work_type_emoji = {\"Remote\": \"🏠\", \"Hybrid\": \"🔄\", \"On-site\": \"🏢\"}\n",
    "            emoji = work_type_emoji.get(job[\"work_location_type\"], \"📍\")\n",
    "            print(f\"{emoji} Work Type: {job['work_location_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"level\"]) and job[\"level\"]:\n",
    "            print(f\"🎯 Level: {job['level']}\")\n",
    "\n",
    "        if pd.notna(job[\"salary_range\"]) and job[\"salary_range\"]:\n",
    "            print(f\"💰 Salary: {job['salary_range']}\")\n",
    "\n",
    "        if pd.notna(job[\"employment_type\"]) and job[\"employment_type\"]:\n",
    "            print(f\"📝 Employment: {job['employment_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_function\"]) and job[\"job_function\"]:\n",
    "            print(f\"⚙️ Function: {job['job_function']}\")\n",
    "\n",
    "        if pd.notna(job[\"industries\"]) and job[\"industries\"]:\n",
    "            print(f\"🏭 Industries: {job['industries']}\")\n",
    "\n",
    "        if pd.notna(job[\"applicants\"]) and job[\"applicants\"]:\n",
    "            print(f\"👥 Applicants: {job['applicants']}\")\n",
    "\n",
    "        if pd.notna(job[\"posted_time\"]) and job[\"posted_time\"]:\n",
    "            print(f\"📅 Posted: {job['posted_time']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_posting_link\"]) and job[\"job_posting_link\"]:\n",
    "            print(f\"🔗 LinkedIn URL: {job['job_posting_link']}\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    if len(top_jobs_df) > display_limit:\n",
    "        print(f\"\\n... and {len(top_jobs_df) - display_limit} more jobs in the database\")\n",
    "        print(\"💡 Tip: Run the statistics cell below for a summary of all jobs\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs found in database. Run 'make run-parser' first to collect job data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05cc1bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 ENHANCED JOB STATISTICS WITH LOCATION INTELLIGENCE\n",
      "============================================================\n",
      "\n",
      "🏢 Top Companies:\n",
      "  • H-E-B: 2 job(s)\n",
      "  • Enlighten: 1 job(s)\n",
      "  • Shrive Technologies: 1 job(s)\n",
      "  • ClearanceJobs: 1 job(s)\n",
      "  • Amazon Web Services (AWS): 1 job(s)\n",
      "\n",
      "📍 Top Locations:\n",
      "  • San Antonio, TX: 8 job(s)\n",
      "  • San Antonio, Texas Metropolitan Area: 1 job(s)\n",
      "  • Texas, United States: 1 job(s)\n",
      "\n",
      "🏠 Work Location Types (Location Intelligence):\n",
      "  🏢 On-site: 4 job(s) (40.0%)\n",
      "  🔄 Hybrid: 3 job(s) (30.0%)\n",
      "  🏠 Remote: 3 job(s) (30.0%)\n",
      "\n",
      "🎯 Experience Levels:\n",
      "  • Mid-Senior level: 3 job(s)\n",
      "  • Entry level: 3 job(s)\n",
      "  • Not Applicable: 3 job(s)\n",
      "  • Associate: 1 job(s)\n",
      "\n",
      "💼 Employment Types:\n",
      "  • Full-time: 10 job(s)\n",
      "\n",
      "⚙️ Top Job Functions:\n",
      "  • Engineering and Information Technology: 5 job(s)\n",
      "  • Information Technology: 3 job(s)\n",
      "  • Research, Analyst, and Information Technology: 1 job(s)\n",
      "  • Information Technology, Consulting, and Engineering: 1 job(s)\n",
      "\n",
      "💰 Salary Information: 4 out of 10 jobs (40.0%)\n",
      "👥 Applicant Count Available: 10 out of 10 jobs (100.0%)\n",
      "\n",
      "📈 Data Quality Summary:\n",
      "  ✅ All jobs have location intelligence classification\n",
      "  ✅ Enhanced 17-column data structure\n",
      "  ✅ Comprehensive job metadata available\n"
     ]
    }
   ],
   "source": [
    "# Enhanced job statistics with location intelligence\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"📊 ENHANCED JOB STATISTICS WITH LOCATION INTELLIGENCE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Company distribution\n",
    "    company_counts = top_jobs_df[\"company\"].value_counts()\n",
    "    print(f\"\\n🏢 Top Companies:\")\n",
    "    for company, count in company_counts.head().items():\n",
    "        print(f\"  • {company}: {count} job(s)\")\n",
    "\n",
    "    # Location distribution (enhanced)\n",
    "    location_counts = top_jobs_df[\"location\"].value_counts()\n",
    "    print(f\"\\n📍 Top Locations:\")\n",
    "    for location, count in location_counts.head().items():\n",
    "        print(f\"  • {location}: {count} job(s)\")\n",
    "\n",
    "    # NEW: Work location type analysis\n",
    "    if \"work_location_type\" in top_jobs_df.columns:\n",
    "        work_type_counts = top_jobs_df[\"work_location_type\"].value_counts(dropna=True)\n",
    "        print(f\"\\n🏠 Work Location Types (Location Intelligence):\")\n",
    "        for work_type, count in work_type_counts.items():\n",
    "            emoji = {\"Remote\": \"🏠\", \"Hybrid\": \"🔄\", \"On-site\": \"🏢\"}.get(\n",
    "                work_type, \"📍\"\n",
    "            )\n",
    "            percentage = count / len(top_jobs_df) * 100\n",
    "            print(f\"  {emoji} {work_type}: {count} job(s) ({percentage:.1f}%)\")\n",
    "\n",
    "    # Experience level distribution\n",
    "    if \"level\" in top_jobs_df.columns:\n",
    "        level_counts = top_jobs_df[\"level\"].value_counts(dropna=True)\n",
    "        if not level_counts.empty:\n",
    "            print(f\"\\n🎯 Experience Levels:\")\n",
    "            for level, count in level_counts.items():\n",
    "                print(f\"  • {level}: {count} job(s)\")\n",
    "\n",
    "    # Employment type distribution\n",
    "    if \"employment_type\" in top_jobs_df.columns:\n",
    "        employment_counts = top_jobs_df[\"employment_type\"].value_counts(dropna=True)\n",
    "        if not employment_counts.empty:\n",
    "            print(f\"\\n💼 Employment Types:\")\n",
    "            for emp_type, count in employment_counts.items():\n",
    "                print(f\"  • {emp_type}: {count} job(s)\")\n",
    "\n",
    "    # Job function analysis\n",
    "    if \"job_function\" in top_jobs_df.columns:\n",
    "        function_counts = top_jobs_df[\"job_function\"].value_counts(dropna=True)\n",
    "        if not function_counts.empty:\n",
    "            print(f\"\\n⚙️ Top Job Functions:\")\n",
    "            for function, count in function_counts.head().items():\n",
    "                print(f\"  • {function}: {count} job(s)\")\n",
    "\n",
    "    # Salary information availability\n",
    "    salary_jobs = top_jobs_df[\"salary_range\"].notna().sum()\n",
    "    print(\n",
    "        f\"\\n💰 Salary Information: {salary_jobs} out of {len(top_jobs_df)} jobs ({salary_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Applicant information\n",
    "    applicant_jobs = top_jobs_df[\"applicants\"].notna().sum()\n",
    "    print(\n",
    "        f\"👥 Applicant Count Available: {applicant_jobs} out of {len(top_jobs_df)} jobs ({applicant_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n📈 Data Quality Summary:\")\n",
    "    print(f\"  ✅ All jobs have location intelligence classification\")\n",
    "    print(f\"  ✅ Enhanced 17-column data structure\")\n",
    "    print(f\"  ✅ Comprehensive job metadata available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7613ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💰 JOBS WITH SALARY INFORMATION + LOCATION INTELLIGENCE\n",
      "=================================================================\n",
      " 1. DevOps Engineer - 23884 at Enlighten\n",
      "    💰 $97,097.00/yr - $130,000.00/yr\n",
      "    📍 San Antonio, TX | 🔄 Hybrid\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      " 2. Systems Engineer at Booz Allen Hamilton\n",
      "    💰 $52,900.00/yr - $108,000.00/yr\n",
      "    📍 San Antonio, TX | 🏠 Remote\n",
      "    🎯 Not Applicable\n",
      "    📝 Full-time\n",
      "\n",
      " 3. AI Data Scientist, Manager at Deloitte\n",
      "    💰 $103,320.00/yr - $235,170.00/yr\n",
      "    📍 San Antonio, TX | 🔄 Hybrid\n",
      "    🎯 Not Applicable\n",
      "    📝 Full-time\n",
      "\n",
      " 4. Platform Engineer (Hybrid) - 23372 at Mission Technologies, a division of HII\n",
      "    💰 $97,097.00/yr - $135,000.00/yr\n",
      "    📍 San Antonio, Texas Metropolitan Area | 🏠 Remote\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      " 5. Senior ML Engineer at Launch Potato\n",
      "    💰 $160,000.00/yr - $220,000.00/yr\n",
      "    📍 San Antonio, TX | 🏠 Remote\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      " 6. DevOps Engineer - 23859 at Enlighten\n",
      "    💰 $119,574.00/yr - $170,000.00/yr\n",
      "    📍 San Antonio, TX | 🔄 Hybrid\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      " 7. Lead ML Engineer at Launch Potato\n",
      "    💰 $130,000.00/yr - $250,000.00/yr\n",
      "    📍 San Antonio, TX | 🏢 On-site\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      " 8. BI Reporting Analyst (Collections) at Piper Companies\n",
      "    💰 $80,000.00/yr - $100,000.00/yr\n",
      "    📍 San Antonio, TX | 🔄 Hybrid\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      " 9. SAP - SuccessFactors Compensation - Senior - Location OPEN at EY\n",
      "    💰 $102,500.00/yr - $187,900.00/yr\n",
      "    📍 San Antonio, TX | 🏠 Remote\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      "10. Lead Data Scientist at Deloitte\n",
      "    💰 $97,600.00/yr - $179,900.00/yr\n",
      "    📍 San Antonio, TX | 🏢 On-site\n",
      "    🎯 Not Applicable\n",
      "    📝 Full-time\n",
      "\n",
      "11. Senior Full Stack Developer at Jobs via Dice\n",
      "    💰 $92,000.00/yr - $153,000.00/yr\n",
      "    📍 San Antonio, TX | 🏠 Remote\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      "12. Decision Science Analyst Senior - Claims Analytics at USAA\n",
      "    💰 $114,080.00/yr - $205,340.00/yr\n",
      "    📍 San Antonio, TX | 🔄 Hybrid\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      "13. Decision Science Analyst Senior - Claims Service Analytics at USAA\n",
      "    💰 $114,080.00/yr - $205,340.00/yr\n",
      "    📍 San Antonio, TX | 🔄 Hybrid\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      "14. Associate Software Engineer at Lensa\n",
      "    💰 $58,800.00/yr - $105,000.00/yr\n",
      "    📍 San Antonio, TX | 🏠 Remote\n",
      "    🎯 Entry level\n",
      "    📝 Full-time\n",
      "\n",
      "15. Platform Engineer (Hybrid) - 22394 at Enlighten\n",
      "    💰 $119,574.00/yr - $170,000.00/yr\n",
      "    📍 San Antonio, TX | 🔄 Hybrid\n",
      "    🎯 Mid-Senior level\n",
      "    📝 Full-time\n",
      "\n",
      "📈 SALARY ANALYSIS BY WORK TYPE\n",
      "========================================\n",
      "🔄 Hybrid: 7 jobs with salary info\n",
      "🏢 On-site: 2 jobs with salary info\n",
      "🏠 Remote: 6 jobs with salary info\n"
     ]
    }
   ],
   "source": [
    "# Enhanced salary analysis with location intelligence\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    salary_query = \"\"\"\n",
    "    SELECT title, company, salary_range, location, work_location_type, level, employment_type\n",
    "    FROM jobs \n",
    "    WHERE salary_range IS NOT NULL AND salary_range != ''\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 15\n",
    "    \"\"\"\n",
    "\n",
    "    salary_jobs = pd.read_sql_query(salary_query, conn)\n",
    "\n",
    "if not salary_jobs.empty:\n",
    "    print(\"💰 JOBS WITH SALARY INFORMATION + LOCATION INTELLIGENCE\")\n",
    "    print(\"=\" * 65)\n",
    "    for idx, job in salary_jobs.iterrows():\n",
    "        # Work type emoji\n",
    "        work_emoji = {\"Remote\": \"🏠\", \"Hybrid\": \"🔄\", \"On-site\": \"🏢\"}.get(\n",
    "            job[\"work_location_type\"], \"📍\"\n",
    "        )\n",
    "\n",
    "        print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "        print(f\"    💰 {job['salary_range']}\")\n",
    "        print(f\"    📍 {job['location']} | {work_emoji} {job['work_location_type']}\")\n",
    "\n",
    "        if job[\"level\"]:\n",
    "            print(f\"    🎯 {job['level']}\")\n",
    "        if job[\"employment_type\"]:\n",
    "            print(f\"    📝 {job['employment_type']}\")\n",
    "        print()\n",
    "\n",
    "    # Salary analysis by work type\n",
    "    if \"work_location_type\" in salary_jobs.columns:\n",
    "        print(\"📈 SALARY ANALYSIS BY WORK TYPE\")\n",
    "        print(\"=\" * 40)\n",
    "        work_type_salary = salary_jobs.groupby(\"work_location_type\").size()\n",
    "        for work_type, count in work_type_salary.items():\n",
    "            emoji = {\"Remote\": \"🏠\", \"Hybrid\": \"🔄\", \"On-site\": \"🏢\"}.get(\n",
    "                work_type, \"📍\"\n",
    "            )\n",
    "            print(f\"{emoji} {work_type}: {count} jobs with salary info\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs with salary information found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9879302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 LOCATION INTELLIGENCE ANALYSIS\n",
      "==================================================\n",
      "📊 Location + Work Type Distribution:\n",
      "🏢 San Antonio, TX - On-site: 64 jobs\n",
      "    Companies: VETROMAC, Inherent Technologies, SwRI Structural Geology & Geomechanics... (+10 more)\n",
      "\n",
      "🔄 San Antonio, TX - Hybrid: 52 jobs\n",
      "    Companies: GovCIO, USAA, Modern Technology Solutions... (+8 more)\n",
      "\n",
      "🏠 San Antonio, TX - Remote: 45 jobs\n",
      "    Companies: Raft, Mindrift, Lensa... (+6 more)\n",
      "\n",
      "🏢 San Antonio, Texas Metropolitan Area - On-site: 11 jobs\n",
      "    Companies: Oteemo Inc., Mission Technologies,  a division of HII\n",
      "\n",
      "🏠 San Antonio, Texas Metropolitan Area - Remote: 4 jobs\n",
      "    Companies: Compri Consulting, Mission Technologies,  a division of HII\n",
      "\n",
      "🏢 Lackland Air Force Base, TX - On-site: 3 jobs\n",
      "    Companies: Knowesis Inc.\n",
      "\n",
      "🏢 Texas, United States - On-site: 1 jobs\n",
      "    Companies: Frost\n",
      "\n",
      "🎯 WORK TYPE INTELLIGENCE SUMMARY:\n",
      "----------------------------------------\n",
      "🏢 On-site :  79 jobs ( 41.6%)\n",
      "🔄 Hybrid  :  52 jobs ( 27.4%)\n",
      "🏠 Remote  :  49 jobs ( 25.8%)\n",
      "\n",
      "✨ Location Intelligence Features:\n",
      "   🎯 Automatic location extraction from job postings\n",
      "   🤖 AI-powered work type classification\n",
      "   📊 Enhanced analytics with location data\n",
      "   💾 17-column output maintaining legacy compatibility\n"
     ]
    }
   ],
   "source": [
    "# 🎯 LOCATION INTELLIGENCE SHOWCASE\n",
    "print(\"🌍 LOCATION INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get location intelligence statistics\n",
    "    location_intel_query = \"\"\"\n",
    "    SELECT \n",
    "        location,\n",
    "        work_location_type,\n",
    "        COUNT(*) as job_count,\n",
    "        GROUP_CONCAT(DISTINCT company) as companies\n",
    "    FROM jobs \n",
    "    WHERE location IS NOT NULL\n",
    "    GROUP BY location, work_location_type\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    location_intel_df = pd.read_sql_query(location_intel_query, conn)\n",
    "\n",
    "if not location_intel_df.empty:\n",
    "    print(\"📊 Location + Work Type Distribution:\")\n",
    "    for idx, row in location_intel_df.iterrows():\n",
    "        emoji = {\"Remote\": \"🏠\", \"Hybrid\": \"🔄\", \"On-site\": \"🏢\"}.get(\n",
    "            row[\"work_location_type\"], \"📍\"\n",
    "        )\n",
    "        companies = row[\"companies\"].split(\",\") if row[\"companies\"] else []\n",
    "        company_preview = (\n",
    "            f\" (Companies: {', '.join(companies[:3])}\"\n",
    "            + (\"...\" if len(companies) > 3 else \"\")\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{emoji} {row['location']} - {row['work_location_type']}: {row['job_count']} jobs\"\n",
    "        )\n",
    "        if len(companies) <= 3:\n",
    "            print(f\"    Companies: {', '.join(companies)}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"    Companies: {', '.join(companies[:3])}... (+{len(companies)-3} more)\"\n",
    "            )\n",
    "        print()\n",
    "\n",
    "    # Overall location intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        summary_query = \"\"\"\n",
    "        SELECT \n",
    "            work_location_type,\n",
    "            COUNT(*) as count,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM jobs), 1) as percentage\n",
    "        FROM jobs \n",
    "        WHERE work_location_type IS NOT NULL\n",
    "        GROUP BY work_location_type\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        summary_df = pd.read_sql_query(summary_query, conn)\n",
    "\n",
    "    print(\"🎯 WORK TYPE INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        emoji = {\"Remote\": \"🏠\", \"Hybrid\": \"🔄\", \"On-site\": \"🏢\"}.get(\n",
    "            row[\"work_location_type\"], \"📍\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{emoji} {row['work_location_type']:8s}: {row['count']:3d} jobs ({row['percentage']:5.1f}%)\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n✨ Location Intelligence Features:\")\n",
    "    print(f\"   🎯 Automatic location extraction from job postings\")\n",
    "    print(f\"   🤖 AI-powered work type classification\")\n",
    "    print(f\"   📊 Enhanced analytics with location data\")\n",
    "    print(f\"   💾 17-column output maintaining legacy compatibility\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"No location data found. Run 'make run-parser' to collect jobs with location intelligence.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27363121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 CSV EXPORT WITH ENHANCED DATA\n",
      "========================================\n",
      "✅ Jobs exported to: ../data/notebook_analysis_export.csv\n",
      "\n",
      "📋 Export Validation:\n",
      "   Shape: (190, 17)\n",
      "   Columns: 17 (should be 17)\n",
      "\n",
      "✅ Column Validation:\n",
      "   🎯 Perfect! All 17 expected columns present\n",
      "\n",
      "📊 Data Quality Check:\n",
      "   Location data: 180/190 jobs (94.7%)\n",
      "   Work type data: 180/190 jobs (94.7%)\n",
      "   Company data: 190/190 jobs\n",
      "   Title data: 190/190 jobs\n",
      "\n",
      "🎉 SUCCESS: Enhanced LinkedIn parser with location intelligence is working perfectly!\n",
      "   💾 Database: data/jobs.db\n",
      "   📤 Export: ../data/notebook_analysis_export.csv\n",
      "   🎯 Use: make run-parser (to collect more jobs)\n",
      "\n",
      "==================================================\n",
      "🚀 ANALYSIS COMPLETE - Enhanced LinkedIn Parser Ready!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 📊 EXPORT & DATA VALIDATION\n",
    "print(\"📤 CSV EXPORT WITH ENHANCED DATA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Export current job data to CSV in the main data folder\n",
    "csv_filename = db.export_jobs_to_csv(\"../data/notebook_analysis_export.csv\")\n",
    "print(f\"✅ Jobs exported to: {csv_filename}\")\n",
    "\n",
    "# Validate the exported CSV structure\n",
    "if csv_filename:\n",
    "    import pandas as pd\n",
    "\n",
    "    exported_df = pd.read_csv(csv_filename)\n",
    "\n",
    "    print(f\"\\n📋 Export Validation:\")\n",
    "    print(f\"   Shape: {exported_df.shape}\")\n",
    "    print(f\"   Columns: {exported_df.shape[1]} (should be 17)\")\n",
    "\n",
    "    expected_columns = [\n",
    "        \"id\",\n",
    "        \"company\",\n",
    "        \"title\",\n",
    "        \"location\",\n",
    "        \"work_location_type\",\n",
    "        \"level\",\n",
    "        \"salary_range\",\n",
    "        \"content\",\n",
    "        \"employment_type\",\n",
    "        \"job_function\",\n",
    "        \"industries\",\n",
    "        \"posted_time\",\n",
    "        \"applicants\",\n",
    "        \"job_id\",\n",
    "        \"date\",\n",
    "        \"parsing_link\",\n",
    "        \"job_posting_link\",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n✅ Column Validation:\")\n",
    "    missing_cols = set(expected_columns) - set(exported_df.columns)\n",
    "    extra_cols = set(exported_df.columns) - set(expected_columns)\n",
    "\n",
    "    if not missing_cols and not extra_cols:\n",
    "        print(\"   🎯 Perfect! All 17 expected columns present\")\n",
    "    else:\n",
    "        if missing_cols:\n",
    "            print(f\"   ⚠️  Missing columns: {missing_cols}\")\n",
    "        if extra_cols:\n",
    "            print(f\"   ➕ Extra columns: {extra_cols}\")\n",
    "\n",
    "    print(f\"\\n📊 Data Quality Check:\")\n",
    "    print(\n",
    "        f\"   Location data: {exported_df['location'].notna().sum()}/{len(exported_df)} jobs ({exported_df['location'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Work type data: {exported_df['work_location_type'].notna().sum()}/{len(exported_df)} jobs ({exported_df['work_location_type'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company data: {exported_df['company'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Title data: {exported_df['title'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\n🎉 SUCCESS: Enhanced LinkedIn parser with location intelligence is working perfectly!\"\n",
    "    )\n",
    "    print(f\"   💾 Database: data/jobs.db\")\n",
    "    print(f\"   📤 Export: {csv_filename}\")\n",
    "    print(f\"   🎯 Use: make run-parser (to collect more jobs)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"🚀 ANALYSIS COMPLETE - Enhanced LinkedIn Parser Ready!\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-job-finder-Y_k-9c-5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
