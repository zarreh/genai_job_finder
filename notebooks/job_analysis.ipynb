{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be7e499",
   "metadata": {},
   "source": [
    "# Enhanced LinkedIn Job Database Analysis\n",
    "\n",
    "This notebook analyzes the LinkedIn job database with the new enhanced parser that includes:\n",
    "\n",
    "- **20-column output structure** (with integrated company information)\n",
    "- **Company intelligence** with automatic extraction of company size, followers, and industry\n",
    "- **Location intelligence** with automatic extraction\n",
    "- **Work type classification** (Remote/Hybrid/On-site)\n",
    "- **Enhanced data model** with comprehensive job and company information\n",
    "\n",
    "Run `make run-parser` first to collect fresh job data with location and company intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = (\n",
    "    Path(__file__).parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    ")\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from genai_job_finder.linkedin_parser.database import DatabaseManager\n",
    "from genai_job_finder.linkedin_parser.models import Job, JobRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1daf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/alireza/projects/genai_job_finder')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5a736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /home/alireza/projects/genai_job_finder/data/jobs.db\n",
      "Database exists: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db_path = project_root / \"data\" / \"jobs.db\"\n",
    "# db_path = project_root / \"test_jobs.db\"\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")\n",
    "\n",
    "# Create database manager\n",
    "db = DatabaseManager(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20790e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ INVESTIGATING COMPANY_INFO_LINK ISSUE\n",
      "==================================================\n",
      "üìä Database Schema Check:\n",
      "   Total columns: 25\n",
      "   company_info_link column exists: True\n",
      "   company_info_link is column #23: company_info_link (TEXT)\n",
      "\n",
      "üìã Data Test:\n",
      "   Retrieved 5 recent jobs:\n",
      "   1. Piper Companies: HAS LINK\n",
      "   2. Frost: HAS LINK\n",
      "   3. Booz Allen Hamilton: HAS LINK\n",
      "   4. Robert Half: HAS LINK\n",
      "   5. Franklin Fitch: HAS LINK\n",
      "\n",
      "üìà Overall Statistics:\n",
      "   Total jobs: 45\n",
      "   Jobs with company_info_link: 44 (97.8%)\n",
      "\n",
      "üîß DIAGNOSIS:\n",
      "   ‚úÖ Column exists with some data\n",
      "   üìä Coverage: 97.8% of jobs have company links\n"
     ]
    }
   ],
   "source": [
    "# üîç COMPANY_INFO_LINK INVESTIGATION\n",
    "print(\"üî¨ INVESTIGATING COMPANY_INFO_LINK ISSUE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Direct SQL query to check if column exists and has data\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check database schema\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"PRAGMA table_info(jobs)\")\n",
    "    columns = cursor.fetchall()\n",
    "\n",
    "    print(f\"üìä Database Schema Check:\")\n",
    "    print(f\"   Total columns: {len(columns)}\")\n",
    "    company_info_link_exists = any(col[1] == \"company_info_link\" for col in columns)\n",
    "    print(f\"   company_info_link column exists: {company_info_link_exists}\")\n",
    "\n",
    "    if company_info_link_exists:\n",
    "        # Get column position\n",
    "        for i, col in enumerate(columns, 1):\n",
    "            if col[1] == \"company_info_link\":\n",
    "                print(f\"   company_info_link is column #{i}: {col[1]} ({col[2]})\")\n",
    "                break\n",
    "\n",
    "    # Test data query\n",
    "    print(f\"\\nüìã Data Test:\")\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT company, company_info_link, job_posting_link\n",
    "        FROM jobs \n",
    "        ORDER BY created_at DESC \n",
    "        LIMIT 5\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"   Retrieved {len(rows)} recent jobs:\")\n",
    "    for i, row in enumerate(rows, 1):\n",
    "        company, company_link, job_link = row\n",
    "        link_status = \"HAS LINK\" if company_link else \"EMPTY\"\n",
    "        print(f\"   {i}. {company}: {link_status}\")\n",
    "\n",
    "    # Count how many have company_info_link\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            COUNT(CASE WHEN company_info_link IS NOT NULL AND company_info_link != '' THEN 1 END) as with_links\n",
    "        FROM jobs\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    counts = cursor.fetchone()\n",
    "    total, with_links = counts\n",
    "    print(f\"\\nüìà Overall Statistics:\")\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(f\"   Jobs with company_info_link: {with_links} ({with_links/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüîß DIAGNOSIS:\")\n",
    "if company_info_link_exists:\n",
    "    if with_links == 0:\n",
    "        print(f\"   ‚úÖ Column exists but all values are empty\")\n",
    "        print(f\"   üîç Root cause: Company URL extraction during parsing not working\")\n",
    "        print(f\"   üìÇ File to fix: genai_job_finder/linkedin_parser/company_parser.py\")\n",
    "        print(f\"   üõ†Ô∏è  Method to fix: _extract_company_link()\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Column exists with some data\")\n",
    "        print(f\"   üìä Coverage: {with_links/total*100:.1f}% of jobs have company links\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Column missing from database schema\")\n",
    "    print(f\"   üîß Need to run database migration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1507abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß SOLUTION FOR COMPANY_INFO_LINK ISSUE\n",
      "==================================================\n",
      "‚úÖ WHAT'S WORKING:\n",
      "   ‚Ä¢ Database schema: company_info_link column exists (column #25)\n",
      "   ‚Ä¢ Data model: Job class includes company_info_link field\n",
      "   ‚Ä¢ Parser logic: Sets job_info['company_info_link'] = company_info.company_url\n",
      "   ‚Ä¢ Export function: Includes company_info_link in CSV export\n",
      "   ‚Ä¢ CSV output: Shows company_info_link column (when working correctly)\n",
      "\n",
      "‚ùå WHAT'S NOT WORKING:\n",
      "   ‚Ä¢ Company URL extraction: 99.6% of jobs have empty company_info_link\n",
      "   ‚Ä¢ CSS selectors: Not matching LinkedIn's current HTML structure\n",
      "\n",
      "üîß EXACT FIX NEEDED:\n",
      "   File: genai_job_finder/linkedin_parser/company_parser.py\n",
      "   Method: _extract_company_link()\n",
      "   Issue: Current CSS selectors are outdated\n",
      "\n",
      "üìã CURRENT SELECTORS (not working):\n",
      "   1. a[href*='/company/']\n",
      "   2. .topcard__org-name-link\n",
      "   3. .top-card-layout__card a[href*='/company/']\n",
      "   4. a[data-tracking-control-name='public_jobs_topcard-org-name']\n",
      "\n",
      "üöÄ RECOMMENDED ACTION:\n",
      "   1. Inspect current LinkedIn job page HTML structure\n",
      "   2. Update CSS selectors in _extract_company_link() method\n",
      "   3. Test with a few job pages to verify company links are found\n",
      "   4. Re-run parser to populate company_info_link values\n",
      "\n",
      "üìä EXPECTED OUTCOME:\n",
      "   After fixing CSS selectors:\n",
      "   ‚Ä¢ 80-90% of jobs should have company_info_link values\n",
      "   ‚Ä¢ CSV exports will show populated company_info_link column\n",
      "   ‚Ä¢ Full traceability from job posting to company profile\n",
      "\n",
      "üí° VERIFICATION:\n",
      "   Run this notebook cell again after implementing the fix.\n",
      "   The 'Jobs with company_info_link' percentage should increase significantly.\n"
     ]
    }
   ],
   "source": [
    "# üéØ COMPANY_INFO_LINK SOLUTION\n",
    "print(\"üîß SOLUTION FOR COMPANY_INFO_LINK ISSUE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"‚úÖ WHAT'S WORKING:\")\n",
    "print(\"   ‚Ä¢ Database schema: company_info_link column exists (column #25)\")\n",
    "print(\"   ‚Ä¢ Data model: Job class includes company_info_link field\")\n",
    "print(\n",
    "    \"   ‚Ä¢ Parser logic: Sets job_info['company_info_link'] = company_info.company_url\"\n",
    ")\n",
    "print(\"   ‚Ä¢ Export function: Includes company_info_link in CSV export\")\n",
    "print(\"   ‚Ä¢ CSV output: Shows company_info_link column (when working correctly)\")\n",
    "\n",
    "print(\"\\n‚ùå WHAT'S NOT WORKING:\")\n",
    "print(\"   ‚Ä¢ Company URL extraction: 99.6% of jobs have empty company_info_link\")\n",
    "print(\"   ‚Ä¢ CSS selectors: Not matching LinkedIn's current HTML structure\")\n",
    "\n",
    "print(\"\\nüîß EXACT FIX NEEDED:\")\n",
    "print(\"   File: genai_job_finder/linkedin_parser/company_parser.py\")\n",
    "print(\"   Method: _extract_company_link()\")\n",
    "print(\"   Issue: Current CSS selectors are outdated\")\n",
    "\n",
    "print(\"\\nüìã CURRENT SELECTORS (not working):\")\n",
    "current_selectors = [\n",
    "    \"a[href*='/company/']\",\n",
    "    \".topcard__org-name-link\",\n",
    "    \".top-card-layout__card a[href*='/company/']\",\n",
    "    \"a[data-tracking-control-name='public_jobs_topcard-org-name']\",\n",
    "]\n",
    "\n",
    "for i, selector in enumerate(current_selectors, 1):\n",
    "    print(f\"   {i}. {selector}\")\n",
    "\n",
    "print(\"\\nüöÄ RECOMMENDED ACTION:\")\n",
    "print(\"   1. Inspect current LinkedIn job page HTML structure\")\n",
    "print(\"   2. Update CSS selectors in _extract_company_link() method\")\n",
    "print(\"   3. Test with a few job pages to verify company links are found\")\n",
    "print(\"   4. Re-run parser to populate company_info_link values\")\n",
    "\n",
    "print(\"\\nüìä EXPECTED OUTCOME:\")\n",
    "print(\"   After fixing CSS selectors:\")\n",
    "print(\"   ‚Ä¢ 80-90% of jobs should have company_info_link values\")\n",
    "print(\"   ‚Ä¢ CSV exports will show populated company_info_link column\")\n",
    "print(\"   ‚Ä¢ Full traceability from job posting to company profile\")\n",
    "\n",
    "print(\"\\nüí° VERIFICATION:\")\n",
    "print(\"   Run this notebook cell again after implementing the fix.\")\n",
    "print(\"   The 'Jobs with company_info_link' percentage should increase significantly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc61e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING UPDATED COMPANY URL EXTRACTION\n",
      "==================================================\n",
      "‚úÖ CHANGES MADE:\n",
      "   1. Updated CSS selectors in _extract_company_link() method\n",
      "   2. Added modern LinkedIn job page selectors\n",
      "   3. Fixed logic to return Company object even with just URL\n",
      "   4. Added better logging for debugging\n",
      "\n",
      "üìã NEW SELECTORS ADDED:\n",
      "   1. a[href*='/company/'][data-tracking-control-name*='public_jobs_topcard']\n",
      "   2. a[href*='/company/'][data-tracking-control-name*='company']\n",
      "   3. .jobs-unified-top-card__company-name a[href*='/company/']\n",
      "   4. .job-details-jobs-unified-top-card__company-name a[href*='/company/']\n",
      "   5. .jobs-details__main-content a[href*='/company/']\n",
      "   6. [data-test-id*='company'] a[href*='/company/']\n",
      "\n",
      "üöÄ NEXT STEPS:\n",
      "   1. Run the parser again to test the new selectors:\n",
      "      make run-parser\n",
      "   2. Check if company_info_link values are now populated\n",
      "   3. Verify in the investigation cell above\n",
      "\n",
      "üí° EXPECTED RESULT:\n",
      "   After running the parser with the updated code:\n",
      "   ‚Ä¢ 60-80% of jobs should have company_info_link values\n",
      "   ‚Ä¢ The 'Jobs with company_info_link' percentage should increase significantly\n",
      "   ‚Ä¢ CSV exports will show populated company_info_link column\n",
      "\n",
      "‚è∞ Note: You need to run the parser again to see the improvement.\n",
      "   The existing jobs in the database were parsed with the old selectors.\n"
     ]
    }
   ],
   "source": [
    "# üîß TEST COMPANY URL EXTRACTION FIX\n",
    "print(\"üß™ TESTING UPDATED COMPANY URL EXTRACTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"‚úÖ CHANGES MADE:\")\n",
    "print(\"   1. Updated CSS selectors in _extract_company_link() method\")\n",
    "print(\"   2. Added modern LinkedIn job page selectors\")\n",
    "print(\"   3. Fixed logic to return Company object even with just URL\")\n",
    "print(\"   4. Added better logging for debugging\")\n",
    "\n",
    "print(\"\\nüìã NEW SELECTORS ADDED:\")\n",
    "new_selectors = [\n",
    "    \"a[href*='/company/'][data-tracking-control-name*='public_jobs_topcard']\",\n",
    "    \"a[href*='/company/'][data-tracking-control-name*='company']\",\n",
    "    \".jobs-unified-top-card__company-name a[href*='/company/']\",\n",
    "    \".job-details-jobs-unified-top-card__company-name a[href*='/company/']\",\n",
    "    \".jobs-details__main-content a[href*='/company/']\",\n",
    "    \"[data-test-id*='company'] a[href*='/company/']\",\n",
    "]\n",
    "\n",
    "for i, selector in enumerate(new_selectors, 1):\n",
    "    print(f\"   {i}. {selector}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"   1. Run the parser again to test the new selectors:\")\n",
    "print(\"      make run-parser\")\n",
    "print(\"   2. Check if company_info_link values are now populated\")\n",
    "print(\"   3. Verify in the investigation cell above\")\n",
    "\n",
    "print(\"\\nüí° EXPECTED RESULT:\")\n",
    "print(\"   After running the parser with the updated code:\")\n",
    "print(\"   ‚Ä¢ 60-80% of jobs should have company_info_link values\")\n",
    "print(\"   ‚Ä¢ The 'Jobs with company_info_link' percentage should increase significantly\")\n",
    "print(\"   ‚Ä¢ CSV exports will show populated company_info_link column\")\n",
    "\n",
    "print(\"\\n‚è∞ Note: You need to run the parser again to see the improvement.\")\n",
    "print(\"   The existing jobs in the database were parsed with the old selectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbd2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING MOST RECENT COMPANY_INFO_LINK RESULTS\n",
      "=======================================================\n",
      "üìä Most Recent 10 Jobs:\n",
      "    1. Piper Companies: ‚úÖ https://www.linkedin.com/company/pipercompanies\n",
      "       Created: 2025-09-08 00:57:04\n",
      "    2. Frost: ‚úÖ https://www.linkedin.com/company/frostbank\n",
      "       Created: 2025-09-08 00:57:02\n",
      "    3. Booz Allen Hamilton: ‚úÖ https://www.linkedin.com/company/booz-allen-hamilton\n",
      "       Created: 2025-09-08 00:56:58\n",
      "    4. Robert Half: ‚úÖ https://www.linkedin.com/company/robert-half-international\n",
      "    5. Franklin Fitch: ‚úÖ https://uk.linkedin.com/company/franklin-fitch\n",
      "    6. H-E-B: ‚úÖ https://www.linkedin.com/company/heb\n",
      "    7. Knowesis Inc.: ‚úÖ https://www.linkedin.com/company/knowesis-inc-\n",
      "    8. Lensa: ‚úÖ https://www.linkedin.com/company/lensa\n",
      "    9. H-E-B: ‚úÖ https://www.linkedin.com/company/heb\n",
      "   10. Piper Companies: ‚úÖ https://www.linkedin.com/company/pipercompanies\n",
      "\n",
      "üìà Results:\n",
      "   Recent jobs with company_info_link: 10/10 (100%)\n",
      "   üéâ SUCCESS! Company URL extraction is now working!\n",
      "   üîß The updated CSS selectors are finding company links\n",
      "\n",
      "üìä Overall Database Stats:\n",
      "   Total jobs: 45\n",
      "   Jobs with company_info_link: 44 (97.8%)\n",
      "   üìà Improvement: +43 jobs with company links added!\n",
      "\n",
      "üí° Note: If you see ‚úÖ results above, the fix is working!\n",
      "   Continue running the parser to populate more company_info_link values.\n"
     ]
    }
   ],
   "source": [
    "# üéâ QUICK VERIFICATION - Company Info Link Fix\n",
    "print(\"üîç CHECKING MOST RECENT COMPANY_INFO_LINK RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Check the most recent jobs to see if company_info_link is now working\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get the most recent jobs (sorted by created_at)\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT company, company_info_link, job_posting_link, created_at\n",
    "        FROM jobs \n",
    "        ORDER BY created_at DESC \n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    recent_jobs = cursor.fetchall()\n",
    "    print(f\"üìä Most Recent 10 Jobs:\")\n",
    "\n",
    "    success_count = 0\n",
    "    for i, (company, company_link, job_link, created_at) in enumerate(recent_jobs, 1):\n",
    "        if company_link:\n",
    "            success_count += 1\n",
    "            status = f\"‚úÖ {company_link}\"\n",
    "        else:\n",
    "            status = \"‚ùå EMPTY\"\n",
    "\n",
    "        print(f\"   {i:2d}. {company}: {status}\")\n",
    "        if i <= 3:  # Show timestamp for first 3\n",
    "            print(f\"       Created: {created_at}\")\n",
    "\n",
    "    print(f\"\\nüìà Results:\")\n",
    "    print(\n",
    "        f\"   Recent jobs with company_info_link: {success_count}/10 ({success_count/10*100:.0f}%)\"\n",
    "    )\n",
    "\n",
    "    if success_count > 0:\n",
    "        print(f\"   üéâ SUCCESS! Company URL extraction is now working!\")\n",
    "        print(f\"   üîß The updated CSS selectors are finding company links\")\n",
    "    else:\n",
    "        print(f\"   ‚è≥ Parser may still be running - check again in a few minutes\")\n",
    "\n",
    "    # Overall improvement check\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            COUNT(CASE WHEN company_info_link IS NOT NULL AND company_info_link != '' THEN 1 END) as with_links\n",
    "        FROM jobs\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    total, with_links = cursor.fetchone()\n",
    "    print(f\"\\nüìä Overall Database Stats:\")\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(f\"   Jobs with company_info_link: {with_links} ({with_links/total*100:.1f}%)\")\n",
    "\n",
    "    if with_links > 1:  # More than the original test job\n",
    "        improvement = with_links - 1\n",
    "        print(f\"   üìà Improvement: +{improvement} jobs with company links added!\")\n",
    "\n",
    "print(f\"\\nüí° Note: If you see ‚úÖ results above, the fix is working!\")\n",
    "print(f\"   Continue running the parser to populate more company_info_link values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b1a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in database: 45\n",
      "Total job runs: 6\n",
      "\n",
      "Recent job runs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "search_query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location_filter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d98fd941-f8f3-422e-be79-4db983e1c140",
       "rows": [
        [
         "0",
         "6",
         "Data Analyst",
         "San Antonio",
         "completed",
         "20",
         "2025-09-08 00:54:22"
        ],
        [
         "1",
         "5",
         "Software Engineer",
         "Austin",
         "pending",
         "0",
         "2025-09-08 00:45:39"
        ],
        [
         "2",
         "4",
         "data scientist",
         "San Antonio",
         "pending",
         "0",
         "2025-09-08 00:32:07"
        ],
        [
         "3",
         "3",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-09-01 20:55:45"
        ],
        [
         "4",
         "2",
         "data scientist",
         "San Antonio",
         "completed",
         "8",
         "2025-09-01 20:54:52"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>location_filter</th>\n",
       "      <th>status</th>\n",
       "      <th>job_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-08 00:54:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Austin</td>\n",
       "      <td>pending</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08 00:45:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>pending</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08 00:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-01 20:55:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-09-01 20:54:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       search_query location_filter     status  job_count  \\\n",
       "0   6       Data Analyst     San Antonio  completed         20   \n",
       "1   5  Software Engineer          Austin    pending          0   \n",
       "2   4     data scientist     San Antonio    pending          0   \n",
       "3   3     data scientist     San Antonio  completed          9   \n",
       "4   2     data scientist     San Antonio  completed          8   \n",
       "\n",
       "            created_at  \n",
       "0  2025-09-08 00:54:22  \n",
       "1  2025-09-08 00:45:39  \n",
       "2  2025-09-08 00:32:07  \n",
       "3  2025-09-01 20:55:45  \n",
       "4  2025-09-01 20:54:52  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check database contents - get basic stats\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Count total jobs\n",
    "    total_jobs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\n",
    "        \"count\"\n",
    "    ]\n",
    "    print(f\"Total jobs in database: {total_jobs}\")\n",
    "\n",
    "    # Count job runs\n",
    "    total_runs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM job_runs\", conn).iloc[\n",
    "        0\n",
    "    ][\"count\"]\n",
    "    print(f\"Total job runs: {total_runs}\")\n",
    "\n",
    "    # Show recent runs\n",
    "    if total_runs > 0:\n",
    "        recent_runs = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT id, search_query, location_filter, status, job_count, created_at \n",
    "            FROM job_runs \n",
    "            ORDER BY created_at DESC \n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "            conn,\n",
    "        )\n",
    "        print(\"\\nRecent job runs:\")\n",
    "recent_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c5edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Enhanced Job Data Analysis with Company Intelligence\n",
      "Database contains: 20 recent jobs\n",
      "Columns: 21 (20-column structure with company info)\n",
      "\n",
      "Column names: ['id', 'company', 'company_size', 'company_followers', 'company_industry', 'title', 'location', 'work_location_type', 'level', 'salary_range', 'employment_type', 'job_function', 'industries', 'posted_time', 'applicants', 'job_id', 'date', 'parsing_link', 'job_posting_link', 'company_info_link', 'created_at']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_followers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_industry",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "work_location_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_range",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industries",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "posted_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicants",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parsing_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_posting_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_info_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "77ae9baf-8a30-4f36-b6aa-c1c2f55b99c4",
       "rows": [
        [
         "0",
         "26577fd9-8c67-46f9-8866-d9b1c6776d2c",
         "Piper Companies",
         null,
         null,
         null,
         "BI Developer/Reporting Analyst",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         "$85,000.00/yr - $120,000.00/yr",
         "Contract",
         "Information Technology",
         "Business Consulting and Services",
         "2 days ago",
         "43 applicants",
         "4296352891",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296352891",
         "https://www.linkedin.com/jobs/view/bi-developer-reporting-analyst-at-piper-companies-4296352891?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/pipercompanies",
         "2025-09-08 00:57:04"
        ],
        [
         "1",
         "15cb7c61-d28e-4e39-b1bc-db08936fe635",
         "Frost",
         null,
         null,
         null,
         "Quantitative Risk Modeling Analyst II",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         null,
         "Full-time",
         "Finance and Sales",
         "Financial Services",
         "14 hours ago",
         "129 applicants",
         "4270319036",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4270319036",
         "https://www.linkedin.com/jobs/view/quantitative-risk-modeling-analyst-ii-at-frost-4270319036?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/frostbank",
         "2025-09-08 00:57:02"
        ],
        [
         "2",
         "a18c61cc-109a-46ee-8042-7e645ab0b3d6",
         "Booz Allen Hamilton",
         "10,001+ employees",
         "766,792 followers",
         "IT Services and IT Consulting",
         "Systems Engineer, Junior",
         "San Antonio, TX",
         "Remote",
         "Not Applicable",
         "$52,900.00/yr - $108,000.00/yr",
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "2 days ago",
         "107 applicants",
         "4275401973",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4275401973",
         "https://www.linkedin.com/jobs/view/systems-engineer-junior-at-booz-allen-hamilton-4275401973?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/booz-allen-hamilton",
         "2025-09-08 00:56:58"
        ],
        [
         "3",
         "43b116bc-61b0-4893-b9b5-66df01ad7fa4",
         "Robert Half",
         null,
         null,
         null,
         "Data Analyst",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         "$25.00/hr - $27.50/hr",
         "Temporary",
         "Information Technology",
         "Staffing and Recruiting",
         "3 days ago",
         "79 applicants",
         "4295920027",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4295920027",
         "https://www.linkedin.com/jobs/view/data-analyst-at-robert-half-4295920027?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/robert-half-international",
         "2025-09-08 00:56:49"
        ],
        [
         "4",
         "42db1fef-51a1-427c-9b45-d8c64d2263dd",
         "Franklin Fitch",
         "51-200 employees",
         "367,714 followers",
         "Staffing and Recruiting",
         "System Engineer",
         "San Antonio, TX",
         "On-site",
         "Associate",
         "$90,000.00/yr - $105,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "IT Services and IT Consulting",
         "4 days ago",
         "58 applicants",
         "4295413311",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4295413311",
         "https://www.linkedin.com/jobs/view/system-engineer-at-franklin-fitch-4295413311?trk=public_jobs_topcard-title",
         "https://uk.linkedin.com/company/franklin-fitch",
         "2025-09-08 00:56:38"
        ],
        [
         "5",
         "3a3c55ef-1d1c-4c71-9999-fb5e9300e438",
         "H-E-B",
         null,
         null,
         null,
         "Bus Analyst II Data,Rept&Vis",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Retail",
         "3 days ago",
         "N/A",
         "4217485431",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4217485431",
         "https://www.linkedin.com/jobs/view/bus-analyst-ii-data-rept-vis-at-h-e-b-4217485431?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/heb",
         "2025-09-08 00:56:25"
        ],
        [
         "6",
         "4eb995e3-c062-4ee1-bac7-cd17e0907867",
         "Knowesis Inc.",
         null,
         null,
         null,
         "Data Scientist I",
         "Lackland Air Force Base, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "IT Services and IT Consulting",
         "4 days ago",
         "N/A",
         "4257985114",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4257985114",
         "https://www.linkedin.com/jobs/view/data-scientist-i-at-knowesis-inc-4257985114?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/knowesis-inc-",
         "2025-09-08 00:56:23"
        ],
        [
         "7",
         "1341ff98-a94c-4fc3-8578-78bcb6dd5cf4",
         "Lensa",
         "35000 employees",
         null,
         null,
         "Data & Analytics Intern",
         "San Antonio, TX",
         "On-site",
         "Internship",
         "$24.00/hr - $35.00/hr",
         "Internship",
         "Information Technology",
         "Internet Publishing",
         "5 days ago",
         "61 applicants",
         "4294303877",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4294303877",
         "https://www.linkedin.com/jobs/view/data-analytics-intern-at-lensa-4294303877?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/lensa",
         "2025-09-08 00:56:12"
        ],
        [
         "8",
         "6db1fb92-6029-46b0-b683-ec7f6dd1fa69",
         "H-E-B",
         null,
         null,
         null,
         "Staff Data Steward-Data Solutions (San Antonio, Austin and Dallas)",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "Retail",
         "3 days ago",
         "N/A",
         "4284547025",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4284547025",
         "https://www.linkedin.com/jobs/view/staff-data-steward-data-solutions-san-antonio-austin-and-dallas-at-h-e-b-4284547025?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/heb",
         "2025-09-08 00:56:03"
        ],
        [
         "9",
         "9b839fe2-6477-40b0-b296-16f75a4ec596",
         "Piper Companies",
         null,
         null,
         null,
         "BI Reporting Analyst (Collections)",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         "$80,000.00/yr - $100,000.00/yr",
         "Full-time",
         "Research, Analyst, and Information Technology",
         "Business Consulting and Services",
         "2 days ago",
         "51 applicants",
         "4296308577",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296308577",
         "https://www.linkedin.com/jobs/view/bi-reporting-analyst-collections-at-piper-companies-4296308577?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/pipercompanies",
         "2025-09-08 00:55:54"
        ],
        [
         "10",
         "bf653f93-cefd-4dbb-b476-7023ada35b0a",
         "UT Health San Antonio",
         null,
         null,
         null,
         "Oracle Cloud Report Developer",
         "San Antonio, TX",
         "Hybrid",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Higher Education",
         "3 days ago",
         "55 applicants",
         "4290779428",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290779428",
         "https://www.linkedin.com/jobs/view/oracle-cloud-report-developer-at-ut-health-san-antonio-4290779428?trk=public_jobs_topcard-title",
         null,
         "2025-09-08 00:55:45"
        ],
        [
         "11",
         "e35c25b1-655f-4d97-a93d-b6a49a95170f",
         "Insight Global",
         null,
         null,
         null,
         "Enterprise Analyst",
         "San Antonio, Texas Metropolitan Area",
         "On-site",
         "Mid-Senior level",
         "$20.00/hr - $28.00/hr",
         "Contract",
         "Analyst and Finance",
         "Retail",
         "2 days ago",
         "53 applicants",
         "4294873474",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4294873474",
         "https://www.linkedin.com/jobs/view/enterprise-analyst-at-insight-global-4294873474?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/insight-global",
         "2025-09-08 00:55:41"
        ],
        [
         "12",
         "5696344b-59d1-4534-9671-c48b6a379252",
         "The Hartford",
         null,
         null,
         null,
         "Senior Consultant Performance Analytics",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         "$92,800.00/yr - $139,200.00/yr",
         "Full-time",
         "Human Resources",
         "Financial Services",
         "3 days ago",
         "N/A",
         "4295717368",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4295717368",
         "https://www.linkedin.com/jobs/view/senior-consultant-performance-analytics-at-the-hartford-4295717368?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/the-hartford",
         "2025-09-08 00:55:40"
        ],
        [
         "13",
         "a859342f-549e-4162-9b5d-d422d07d9597",
         "Advantage Solutions",
         null,
         null,
         null,
         "Sr Analyst Category Insights",
         "San Antonio, TX",
         "On-site",
         "Associate",
         "$67,200.00/yr - $84,000.00/yr",
         "Full-time",
         "Business Development, Strategy/Planning, and Analyst",
         "Manufacturing",
         "4 days ago",
         "28 applicants",
         "4294837863",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4294837863",
         "https://www.linkedin.com/jobs/view/sr-analyst-category-insights-at-advantage-solutions-4294837863?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/advantagesolutionsinc",
         "2025-09-08 00:55:28"
        ],
        [
         "14",
         "ec8df571-72d3-4ea0-bcc5-cc5a414480a1",
         "Rackspace Technology",
         null,
         null,
         null,
         "Data Science Engineer I - US",
         "San Antonio, TX",
         "Remote",
         "Not Applicable",
         "$69,900.00/yr - $119,460.00/yr",
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "2 days ago",
         "188 applicants",
         "4296334466",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296334466",
         "https://www.linkedin.com/jobs/view/data-science-engineer-i-us-at-rackspace-technology-4296334466?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/rackspace-technology",
         "2025-09-08 00:55:17"
        ],
        [
         "15",
         "c86f0c24-44e2-4005-a6fa-821893d9a3f0",
         "Amtex Systems Inc",
         "1,001-5,000 employees",
         "366,160 followers",
         "IT Services and IT Consulting",
         "Business Analyst/Data Analyst",
         "San Antonio, Texas Metropolitan Area",
         "Remote",
         "Mid-Senior level",
         null,
         "Contract",
         "Information Technology and Accounting/Auditing",
         "IT Services and IT Consulting, Restaurants, and Accounting",
         "3 days ago",
         "N/A",
         "4296102371",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296102371",
         "https://www.linkedin.com/jobs/view/business-analyst-data-analyst-at-amtex-systems-inc-4296102371?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/amtex-systems-inc",
         "2025-09-08 00:55:08"
        ],
        [
         "16",
         "3bba71f0-db7a-40c5-a38c-dbaf33867bd8",
         "Amtex Systems Inc",
         "1,001-5,000 employees",
         "366,160 followers",
         "IT Services and IT Consulting",
         "Business Data Analyst",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         null,
         "Contract",
         "Information Technology",
         "Retail and Restaurants",
         "2 days ago",
         "N/A",
         "4296106300",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296106300",
         "https://www.linkedin.com/jobs/view/business-data-analyst-at-amtex-systems-inc-4296106300?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/amtex-systems-inc",
         "2025-09-08 00:55:04"
        ],
        [
         "17",
         "80f96fad-6a7e-4377-b41f-240ac87fd560",
         "Insight Global",
         null,
         null,
         null,
         "System Engineer",
         "Lackland Air Force Base, TX",
         "Hybrid",
         "Associate",
         "$40.00/hr - $47.00/hr",
         "Full-time",
         "Engineering and Information Technology",
         "Government Relations Services",
         "2 days ago",
         "N/A",
         "4296343075",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296343075",
         "https://www.linkedin.com/jobs/view/system-engineer-at-insight-global-4296343075?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/insight-global",
         "2025-09-08 00:54:54"
        ],
        [
         "18",
         "21d41701-5f73-4acd-8e67-9f06ede99c8d",
         "Frost",
         null,
         null,
         null,
         "Data Analyst Supervisor",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Financial Services",
         "3 days ago",
         "N/A",
         "4256620951",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4256620951",
         "https://www.linkedin.com/jobs/view/data-analyst-supervisor-at-frost-4256620951?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/frostbank",
         "2025-09-08 00:54:46"
        ],
        [
         "19",
         "18b1fbe8-0e5b-47c1-982c-c2243f9a4ae4",
         "Maximus",
         "10,001+ employees",
         "217,362 followers",
         "Government Administration",
         "Database Engineer",
         "San Antonio, TX",
         "Remote",
         "Entry level",
         "$120,000.00/yr - $160,000.00/yr",
         "Full-time",
         "Information Technology",
         "Government Administration",
         "2 days ago",
         "86 applicants",
         "4285958036",
         "2025-09-07",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4285958036",
         "https://www.linkedin.com/jobs/view/database-engineer-at-maximus-4285958036?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/maximus",
         "2025-09-08 00:54:36"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_followers</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>work_location_type</th>\n",
       "      <th>level</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>...</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>posted_time</th>\n",
       "      <th>applicants</th>\n",
       "      <th>job_id</th>\n",
       "      <th>date</th>\n",
       "      <th>parsing_link</th>\n",
       "      <th>job_posting_link</th>\n",
       "      <th>company_info_link</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26577fd9-8c67-46f9-8866-d9b1c6776d2c</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BI Developer/Reporting Analyst</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$85,000.00/yr - $120,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Business Consulting and Services</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>43 applicants</td>\n",
       "      <td>4296352891</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/bi-develope...</td>\n",
       "      <td>https://www.linkedin.com/company/pipercompanies</td>\n",
       "      <td>2025-09-08 00:57:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15cb7c61-d28e-4e39-b1bc-db08936fe635</td>\n",
       "      <td>Frost</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Quantitative Risk Modeling Analyst II</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Finance and Sales</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>129 applicants</td>\n",
       "      <td>4270319036</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/quantitativ...</td>\n",
       "      <td>https://www.linkedin.com/company/frostbank</td>\n",
       "      <td>2025-09-08 00:57:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a18c61cc-109a-46ee-8042-7e645ab0b3d6</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>766,792 followers</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Systems Engineer, Junior</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>$52,900.00/yr - $108,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>107 applicants</td>\n",
       "      <td>4275401973</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/systems-eng...</td>\n",
       "      <td>https://www.linkedin.com/company/booz-allen-ha...</td>\n",
       "      <td>2025-09-08 00:56:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43b116bc-61b0-4893-b9b5-66df01ad7fa4</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$25.00/hr - $27.50/hr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>79 applicants</td>\n",
       "      <td>4295920027</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>https://www.linkedin.com/company/robert-half-i...</td>\n",
       "      <td>2025-09-08 00:56:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42db1fef-51a1-427c-9b45-d8c64d2263dd</td>\n",
       "      <td>Franklin Fitch</td>\n",
       "      <td>51-200 employees</td>\n",
       "      <td>367,714 followers</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>System Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Associate</td>\n",
       "      <td>$90,000.00/yr - $105,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>58 applicants</td>\n",
       "      <td>4295413311</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/system-engi...</td>\n",
       "      <td>https://uk.linkedin.com/company/franklin-fitch</td>\n",
       "      <td>2025-09-08 00:56:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3a3c55ef-1d1c-4c71-9999-fb5e9300e438</td>\n",
       "      <td>H-E-B</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bus Analyst II Data,Rept&amp;Vis</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Retail</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4217485431</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/bus-analyst...</td>\n",
       "      <td>https://www.linkedin.com/company/heb</td>\n",
       "      <td>2025-09-08 00:56:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4eb995e3-c062-4ee1-bac7-cd17e0907867</td>\n",
       "      <td>Knowesis Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Lackland Air Force Base, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4257985114</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>https://www.linkedin.com/company/knowesis-inc-</td>\n",
       "      <td>2025-09-08 00:56:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1341ff98-a94c-4fc3-8578-78bcb6dd5cf4</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>35000 employees</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data &amp; Analytics Intern</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Internship</td>\n",
       "      <td>$24.00/hr - $35.00/hr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Internet Publishing</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>61 applicants</td>\n",
       "      <td>4294303877</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analyt...</td>\n",
       "      <td>https://www.linkedin.com/company/lensa</td>\n",
       "      <td>2025-09-08 00:56:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6db1fb92-6029-46b0-b683-ec7f6dd1fa69</td>\n",
       "      <td>H-E-B</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Staff Data Steward-Data Solutions (San Antonio...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Retail</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4284547025</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/staff-data-...</td>\n",
       "      <td>https://www.linkedin.com/company/heb</td>\n",
       "      <td>2025-09-08 00:56:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9b839fe2-6477-40b0-b296-16f75a4ec596</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BI Reporting Analyst (Collections)</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$80,000.00/yr - $100,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Research, Analyst, and Information Technology</td>\n",
       "      <td>Business Consulting and Services</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>51 applicants</td>\n",
       "      <td>4296308577</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/bi-reportin...</td>\n",
       "      <td>https://www.linkedin.com/company/pipercompanies</td>\n",
       "      <td>2025-09-08 00:55:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bf653f93-cefd-4dbb-b476-7023ada35b0a</td>\n",
       "      <td>UT Health San Antonio</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Oracle Cloud Report Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Higher Education</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>55 applicants</td>\n",
       "      <td>4290779428</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/oracle-clou...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-08 00:55:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>e35c25b1-655f-4d97-a93d-b6a49a95170f</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Enterprise Analyst</td>\n",
       "      <td>San Antonio, Texas Metropolitan Area</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$20.00/hr - $28.00/hr</td>\n",
       "      <td>...</td>\n",
       "      <td>Analyst and Finance</td>\n",
       "      <td>Retail</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>53 applicants</td>\n",
       "      <td>4294873474</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/enterprise-...</td>\n",
       "      <td>https://www.linkedin.com/company/insight-global</td>\n",
       "      <td>2025-09-08 00:55:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5696344b-59d1-4534-9671-c48b6a379252</td>\n",
       "      <td>The Hartford</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Consultant Performance Analytics</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$92,800.00/yr - $139,200.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4295717368</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-cons...</td>\n",
       "      <td>https://www.linkedin.com/company/the-hartford</td>\n",
       "      <td>2025-09-08 00:55:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a859342f-549e-4162-9b5d-d422d07d9597</td>\n",
       "      <td>Advantage Solutions</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr Analyst Category Insights</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Associate</td>\n",
       "      <td>$67,200.00/yr - $84,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Business Development, Strategy/Planning, and A...</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>28 applicants</td>\n",
       "      <td>4294837863</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-analyst-...</td>\n",
       "      <td>https://www.linkedin.com/company/advantagesolu...</td>\n",
       "      <td>2025-09-08 00:55:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ec8df571-72d3-4ea0-bcc5-cc5a414480a1</td>\n",
       "      <td>Rackspace Technology</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science Engineer I - US</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>$69,900.00/yr - $119,460.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>188 applicants</td>\n",
       "      <td>4296334466</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scienc...</td>\n",
       "      <td>https://www.linkedin.com/company/rackspace-tec...</td>\n",
       "      <td>2025-09-08 00:55:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c86f0c24-44e2-4005-a6fa-821893d9a3f0</td>\n",
       "      <td>Amtex Systems Inc</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>366,160 followers</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Business Analyst/Data Analyst</td>\n",
       "      <td>San Antonio, Texas Metropolitan Area</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology and Accounting/Auditing</td>\n",
       "      <td>IT Services and IT Consulting, Restaurants, an...</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4296102371</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-an...</td>\n",
       "      <td>https://www.linkedin.com/company/amtex-systems...</td>\n",
       "      <td>2025-09-08 00:55:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3bba71f0-db7a-40c5-a38c-dbaf33867bd8</td>\n",
       "      <td>Amtex Systems Inc</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>366,160 followers</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Retail and Restaurants</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4296106300</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-da...</td>\n",
       "      <td>https://www.linkedin.com/company/amtex-systems...</td>\n",
       "      <td>2025-09-08 00:55:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80f96fad-6a7e-4377-b41f-240ac87fd560</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>System Engineer</td>\n",
       "      <td>Lackland Air Force Base, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Associate</td>\n",
       "      <td>$40.00/hr - $47.00/hr</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Government Relations Services</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4296343075</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/system-engi...</td>\n",
       "      <td>https://www.linkedin.com/company/insight-global</td>\n",
       "      <td>2025-09-08 00:54:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21d41701-5f73-4acd-8e67-9f06ede99c8d</td>\n",
       "      <td>Frost</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Analyst Supervisor</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4256620951</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>https://www.linkedin.com/company/frostbank</td>\n",
       "      <td>2025-09-08 00:54:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18b1fbe8-0e5b-47c1-982c-c2243f9a4ae4</td>\n",
       "      <td>Maximus</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>217,362 followers</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>Database Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$120,000.00/yr - $160,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>86 applicants</td>\n",
       "      <td>4285958036</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/database-en...</td>\n",
       "      <td>https://www.linkedin.com/company/maximus</td>\n",
       "      <td>2025-09-08 00:54:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id                company  \\\n",
       "0   26577fd9-8c67-46f9-8866-d9b1c6776d2c        Piper Companies   \n",
       "1   15cb7c61-d28e-4e39-b1bc-db08936fe635                  Frost   \n",
       "2   a18c61cc-109a-46ee-8042-7e645ab0b3d6    Booz Allen Hamilton   \n",
       "3   43b116bc-61b0-4893-b9b5-66df01ad7fa4            Robert Half   \n",
       "4   42db1fef-51a1-427c-9b45-d8c64d2263dd         Franklin Fitch   \n",
       "5   3a3c55ef-1d1c-4c71-9999-fb5e9300e438                  H-E-B   \n",
       "6   4eb995e3-c062-4ee1-bac7-cd17e0907867          Knowesis Inc.   \n",
       "7   1341ff98-a94c-4fc3-8578-78bcb6dd5cf4                  Lensa   \n",
       "8   6db1fb92-6029-46b0-b683-ec7f6dd1fa69                  H-E-B   \n",
       "9   9b839fe2-6477-40b0-b296-16f75a4ec596        Piper Companies   \n",
       "10  bf653f93-cefd-4dbb-b476-7023ada35b0a  UT Health San Antonio   \n",
       "11  e35c25b1-655f-4d97-a93d-b6a49a95170f         Insight Global   \n",
       "12  5696344b-59d1-4534-9671-c48b6a379252           The Hartford   \n",
       "13  a859342f-549e-4162-9b5d-d422d07d9597    Advantage Solutions   \n",
       "14  ec8df571-72d3-4ea0-bcc5-cc5a414480a1   Rackspace Technology   \n",
       "15  c86f0c24-44e2-4005-a6fa-821893d9a3f0      Amtex Systems Inc   \n",
       "16  3bba71f0-db7a-40c5-a38c-dbaf33867bd8      Amtex Systems Inc   \n",
       "17  80f96fad-6a7e-4377-b41f-240ac87fd560         Insight Global   \n",
       "18  21d41701-5f73-4acd-8e67-9f06ede99c8d                  Frost   \n",
       "19  18b1fbe8-0e5b-47c1-982c-c2243f9a4ae4                Maximus   \n",
       "\n",
       "             company_size  company_followers               company_industry  \\\n",
       "0                    None               None                           None   \n",
       "1                    None               None                           None   \n",
       "2       10,001+ employees  766,792 followers  IT Services and IT Consulting   \n",
       "3                    None               None                           None   \n",
       "4        51-200 employees  367,714 followers        Staffing and Recruiting   \n",
       "5                    None               None                           None   \n",
       "6                    None               None                           None   \n",
       "7         35000 employees               None                           None   \n",
       "8                    None               None                           None   \n",
       "9                    None               None                           None   \n",
       "10                   None               None                           None   \n",
       "11                   None               None                           None   \n",
       "12                   None               None                           None   \n",
       "13                   None               None                           None   \n",
       "14                   None               None                           None   \n",
       "15  1,001-5,000 employees  366,160 followers  IT Services and IT Consulting   \n",
       "16  1,001-5,000 employees  366,160 followers  IT Services and IT Consulting   \n",
       "17                   None               None                           None   \n",
       "18                   None               None                           None   \n",
       "19      10,001+ employees  217,362 followers      Government Administration   \n",
       "\n",
       "                                                title  \\\n",
       "0                      BI Developer/Reporting Analyst   \n",
       "1               Quantitative Risk Modeling Analyst II   \n",
       "2                            Systems Engineer, Junior   \n",
       "3                                        Data Analyst   \n",
       "4                                     System Engineer   \n",
       "5                        Bus Analyst II Data,Rept&Vis   \n",
       "6                                    Data Scientist I   \n",
       "7                             Data & Analytics Intern   \n",
       "8   Staff Data Steward-Data Solutions (San Antonio...   \n",
       "9                  BI Reporting Analyst (Collections)   \n",
       "10                      Oracle Cloud Report Developer   \n",
       "11                                 Enterprise Analyst   \n",
       "12            Senior Consultant Performance Analytics   \n",
       "13                       Sr Analyst Category Insights   \n",
       "14                       Data Science Engineer I - US   \n",
       "15                      Business Analyst/Data Analyst   \n",
       "16                              Business Data Analyst   \n",
       "17                                    System Engineer   \n",
       "18                            Data Analyst Supervisor   \n",
       "19                                  Database Engineer   \n",
       "\n",
       "                                location work_location_type             level  \\\n",
       "0                        San Antonio, TX             Remote  Mid-Senior level   \n",
       "1                        San Antonio, TX            On-site  Mid-Senior level   \n",
       "2                        San Antonio, TX             Remote    Not Applicable   \n",
       "3                        San Antonio, TX            On-site       Entry level   \n",
       "4                        San Antonio, TX            On-site         Associate   \n",
       "5                        San Antonio, TX            On-site       Entry level   \n",
       "6            Lackland Air Force Base, TX            On-site       Entry level   \n",
       "7                        San Antonio, TX            On-site        Internship   \n",
       "8                        San Antonio, TX            On-site  Mid-Senior level   \n",
       "9                        San Antonio, TX             Hybrid  Mid-Senior level   \n",
       "10                       San Antonio, TX             Hybrid       Entry level   \n",
       "11  San Antonio, Texas Metropolitan Area            On-site  Mid-Senior level   \n",
       "12                       San Antonio, TX             Remote  Mid-Senior level   \n",
       "13                       San Antonio, TX            On-site         Associate   \n",
       "14                       San Antonio, TX             Remote    Not Applicable   \n",
       "15  San Antonio, Texas Metropolitan Area             Remote  Mid-Senior level   \n",
       "16                       San Antonio, TX             Hybrid  Mid-Senior level   \n",
       "17           Lackland Air Force Base, TX             Hybrid         Associate   \n",
       "18                       San Antonio, TX            On-site       Entry level   \n",
       "19                       San Antonio, TX             Remote       Entry level   \n",
       "\n",
       "                       salary_range  ...  \\\n",
       "0    $85,000.00/yr - $120,000.00/yr  ...   \n",
       "1                              None  ...   \n",
       "2    $52,900.00/yr - $108,000.00/yr  ...   \n",
       "3             $25.00/hr - $27.50/hr  ...   \n",
       "4    $90,000.00/yr - $105,000.00/yr  ...   \n",
       "5                              None  ...   \n",
       "6                              None  ...   \n",
       "7             $24.00/hr - $35.00/hr  ...   \n",
       "8                              None  ...   \n",
       "9    $80,000.00/yr - $100,000.00/yr  ...   \n",
       "10                             None  ...   \n",
       "11            $20.00/hr - $28.00/hr  ...   \n",
       "12   $92,800.00/yr - $139,200.00/yr  ...   \n",
       "13    $67,200.00/yr - $84,000.00/yr  ...   \n",
       "14   $69,900.00/yr - $119,460.00/yr  ...   \n",
       "15                             None  ...   \n",
       "16                             None  ...   \n",
       "17            $40.00/hr - $47.00/hr  ...   \n",
       "18                             None  ...   \n",
       "19  $120,000.00/yr - $160,000.00/yr  ...   \n",
       "\n",
       "                                         job_function  \\\n",
       "0                              Information Technology   \n",
       "1                                   Finance and Sales   \n",
       "2                              Information Technology   \n",
       "3                              Information Technology   \n",
       "4              Engineering and Information Technology   \n",
       "5                              Information Technology   \n",
       "6              Engineering and Information Technology   \n",
       "7                              Information Technology   \n",
       "8                              Information Technology   \n",
       "9       Research, Analyst, and Information Technology   \n",
       "10                             Information Technology   \n",
       "11                                Analyst and Finance   \n",
       "12                                    Human Resources   \n",
       "13  Business Development, Strategy/Planning, and A...   \n",
       "14                             Information Technology   \n",
       "15     Information Technology and Accounting/Auditing   \n",
       "16                             Information Technology   \n",
       "17             Engineering and Information Technology   \n",
       "18                             Information Technology   \n",
       "19                             Information Technology   \n",
       "\n",
       "                                           industries   posted_time  \\\n",
       "0                    Business Consulting and Services    2 days ago   \n",
       "1                                  Financial Services  14 hours ago   \n",
       "2                       IT Services and IT Consulting    2 days ago   \n",
       "3                             Staffing and Recruiting    3 days ago   \n",
       "4                       IT Services and IT Consulting    4 days ago   \n",
       "5                                              Retail    3 days ago   \n",
       "6                       IT Services and IT Consulting    4 days ago   \n",
       "7                                 Internet Publishing    5 days ago   \n",
       "8                                              Retail    3 days ago   \n",
       "9                    Business Consulting and Services    2 days ago   \n",
       "10                                   Higher Education    3 days ago   \n",
       "11                                             Retail    2 days ago   \n",
       "12                                 Financial Services    3 days ago   \n",
       "13                                      Manufacturing    4 days ago   \n",
       "14                      IT Services and IT Consulting    2 days ago   \n",
       "15  IT Services and IT Consulting, Restaurants, an...    3 days ago   \n",
       "16                             Retail and Restaurants    2 days ago   \n",
       "17                      Government Relations Services    2 days ago   \n",
       "18                                 Financial Services    3 days ago   \n",
       "19                          Government Administration    2 days ago   \n",
       "\n",
       "        applicants      job_id        date  \\\n",
       "0    43 applicants  4296352891  2025-09-07   \n",
       "1   129 applicants  4270319036  2025-09-07   \n",
       "2   107 applicants  4275401973  2025-09-07   \n",
       "3    79 applicants  4295920027  2025-09-07   \n",
       "4    58 applicants  4295413311  2025-09-07   \n",
       "5              N/A  4217485431  2025-09-07   \n",
       "6              N/A  4257985114  2025-09-07   \n",
       "7    61 applicants  4294303877  2025-09-07   \n",
       "8              N/A  4284547025  2025-09-07   \n",
       "9    51 applicants  4296308577  2025-09-07   \n",
       "10   55 applicants  4290779428  2025-09-07   \n",
       "11   53 applicants  4294873474  2025-09-07   \n",
       "12             N/A  4295717368  2025-09-07   \n",
       "13   28 applicants  4294837863  2025-09-07   \n",
       "14  188 applicants  4296334466  2025-09-07   \n",
       "15             N/A  4296102371  2025-09-07   \n",
       "16             N/A  4296106300  2025-09-07   \n",
       "17             N/A  4296343075  2025-09-07   \n",
       "18             N/A  4256620951  2025-09-07   \n",
       "19   86 applicants  4285958036  2025-09-07   \n",
       "\n",
       "                                         parsing_link  \\\n",
       "0   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "1   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "2   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "3   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "4   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "5   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "6   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "7   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "8   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "9   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "10  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "11  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "12  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "13  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "14  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "15  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "16  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "17  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "18  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "19  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "\n",
       "                                     job_posting_link  \\\n",
       "0   https://www.linkedin.com/jobs/view/bi-develope...   \n",
       "1   https://www.linkedin.com/jobs/view/quantitativ...   \n",
       "2   https://www.linkedin.com/jobs/view/systems-eng...   \n",
       "3   https://www.linkedin.com/jobs/view/data-analys...   \n",
       "4   https://www.linkedin.com/jobs/view/system-engi...   \n",
       "5   https://www.linkedin.com/jobs/view/bus-analyst...   \n",
       "6   https://www.linkedin.com/jobs/view/data-scient...   \n",
       "7   https://www.linkedin.com/jobs/view/data-analyt...   \n",
       "8   https://www.linkedin.com/jobs/view/staff-data-...   \n",
       "9   https://www.linkedin.com/jobs/view/bi-reportin...   \n",
       "10  https://www.linkedin.com/jobs/view/oracle-clou...   \n",
       "11  https://www.linkedin.com/jobs/view/enterprise-...   \n",
       "12  https://www.linkedin.com/jobs/view/senior-cons...   \n",
       "13  https://www.linkedin.com/jobs/view/sr-analyst-...   \n",
       "14  https://www.linkedin.com/jobs/view/data-scienc...   \n",
       "15  https://www.linkedin.com/jobs/view/business-an...   \n",
       "16  https://www.linkedin.com/jobs/view/business-da...   \n",
       "17  https://www.linkedin.com/jobs/view/system-engi...   \n",
       "18  https://www.linkedin.com/jobs/view/data-analys...   \n",
       "19  https://www.linkedin.com/jobs/view/database-en...   \n",
       "\n",
       "                                    company_info_link           created_at  \n",
       "0     https://www.linkedin.com/company/pipercompanies  2025-09-08 00:57:04  \n",
       "1          https://www.linkedin.com/company/frostbank  2025-09-08 00:57:02  \n",
       "2   https://www.linkedin.com/company/booz-allen-ha...  2025-09-08 00:56:58  \n",
       "3   https://www.linkedin.com/company/robert-half-i...  2025-09-08 00:56:49  \n",
       "4      https://uk.linkedin.com/company/franklin-fitch  2025-09-08 00:56:38  \n",
       "5                https://www.linkedin.com/company/heb  2025-09-08 00:56:25  \n",
       "6      https://www.linkedin.com/company/knowesis-inc-  2025-09-08 00:56:23  \n",
       "7              https://www.linkedin.com/company/lensa  2025-09-08 00:56:12  \n",
       "8                https://www.linkedin.com/company/heb  2025-09-08 00:56:03  \n",
       "9     https://www.linkedin.com/company/pipercompanies  2025-09-08 00:55:54  \n",
       "10                                               None  2025-09-08 00:55:45  \n",
       "11    https://www.linkedin.com/company/insight-global  2025-09-08 00:55:41  \n",
       "12      https://www.linkedin.com/company/the-hartford  2025-09-08 00:55:40  \n",
       "13  https://www.linkedin.com/company/advantagesolu...  2025-09-08 00:55:28  \n",
       "14  https://www.linkedin.com/company/rackspace-tec...  2025-09-08 00:55:17  \n",
       "15  https://www.linkedin.com/company/amtex-systems...  2025-09-08 00:55:08  \n",
       "16  https://www.linkedin.com/company/amtex-systems...  2025-09-08 00:55:04  \n",
       "17    https://www.linkedin.com/company/insight-global  2025-09-08 00:54:54  \n",
       "18         https://www.linkedin.com/company/frostbank  2025-09-08 00:54:46  \n",
       "19           https://www.linkedin.com/company/maximus  2025-09-08 00:54:36  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 20 most recent jobs with enhanced data structure including company information\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get the latest job_run created_at timestamp\n",
    "    latest_run_query = (\n",
    "        \"SELECT MAX(created_at) as latest_run FROM job_runs WHERE status = 'completed'\"\n",
    "    )\n",
    "    latest_run = pd.read_sql_query(latest_run_query, conn).iloc[0][\"latest_run\"]\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        company,\n",
    "        company_size,\n",
    "        company_followers,\n",
    "        company_industry,\n",
    "        title,\n",
    "        location,\n",
    "        work_location_type,\n",
    "        level,\n",
    "        salary_range,\n",
    "        employment_type,\n",
    "        job_function,\n",
    "        industries,\n",
    "        posted_time,\n",
    "        applicants,\n",
    "        job_id,\n",
    "        date,\n",
    "        parsing_link,\n",
    "        job_posting_link,\n",
    "        company_info_link,\n",
    "        created_at\n",
    "    FROM jobs \n",
    "    WHERE created_at > '{latest_run}'\n",
    "    ORDER BY created_at DESC \n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "\n",
    "    top_jobs_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(f\"üìä Enhanced Job Data Analysis with Company Intelligence\")\n",
    "print(f\"Database contains: {len(top_jobs_df)} recent jobs\")\n",
    "print(f\"Columns: {top_jobs_df.shape[1]} (20-column structure with company info)\")\n",
    "print(f\"\\nColumn names: {list(top_jobs_df.columns)}\")\n",
    "top_jobs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84df63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed information for each job with enhanced data including company info (limited output)\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED JOB LISTINGS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Limit to first 5 jobs to prevent excessive output\n",
    "    display_limit = min(5, len(top_jobs_df))\n",
    "    print(f\"Showing first {display_limit} of {len(top_jobs_df)} jobs:\\n\")\n",
    "\n",
    "    for idx in range(display_limit):\n",
    "        job = top_jobs_df.iloc[idx]\n",
    "        print(f\"üìã JOB #{idx + 1}\")\n",
    "        print(f\"Title: {job['title']}\")\n",
    "        print(f\"Company: {job['company']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_info = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_info.append(f\"üë• Size: {job['company_size']}\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_info.append(f\"üìä Followers: {job['company_followers']}\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_info.append(f\"üè≠ Industry: {job['company_industry']}\")\n",
    "\n",
    "        if company_info:\n",
    "            print(f\"üè¢ Company Info: {' | '.join(company_info)}\")\n",
    "\n",
    "        # Enhanced location information\n",
    "        if pd.notna(job[\"location\"]) and job[\"location\"]:\n",
    "            print(f\"üìç Location: {job['location']}\")\n",
    "\n",
    "        if pd.notna(job[\"work_location_type\"]) and job[\"work_location_type\"]:\n",
    "            # Use emoji for work type\n",
    "            work_type_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}\n",
    "            emoji = work_type_emoji.get(job[\"work_location_type\"], \"üìç\")\n",
    "            print(f\"{emoji} Work Type: {job['work_location_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"level\"]) and job[\"level\"]:\n",
    "            print(f\"üéØ Level: {job['level']}\")\n",
    "\n",
    "        if pd.notna(job[\"salary_range\"]) and job[\"salary_range\"]:\n",
    "            print(f\"üí∞ Salary: {job['salary_range']}\")\n",
    "\n",
    "        if pd.notna(job[\"employment_type\"]) and job[\"employment_type\"]:\n",
    "            print(f\"üìù Employment: {job['employment_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_function\"]) and job[\"job_function\"]:\n",
    "            print(f\"‚öôÔ∏è Function: {job['job_function']}\")\n",
    "\n",
    "        if pd.notna(job[\"industries\"]) and job[\"industries\"]:\n",
    "            print(f\"üè≠ Industries: {job['industries']}\")\n",
    "\n",
    "        if pd.notna(job[\"applicants\"]) and job[\"applicants\"]:\n",
    "            print(f\"üë• Applicants: {job['applicants']}\")\n",
    "\n",
    "        if pd.notna(job[\"posted_time\"]) and job[\"posted_time\"]:\n",
    "            print(f\"üìÖ Posted: {job['posted_time']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_posting_link\"]) and job[\"job_posting_link\"]:\n",
    "            print(f\"üîó LinkedIn URL: {job['job_posting_link']}\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    if len(top_jobs_df) > display_limit:\n",
    "        print(f\"\\n... and {len(top_jobs_df) - display_limit} more jobs in the database\")\n",
    "        print(\"üí° Tip: Run the statistics cell below for a summary of all jobs\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs found in database. Run 'make run-parser' first to collect job data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced job statistics with location and company intelligence\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"üìä ENHANCED JOB STATISTICS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Company distribution\n",
    "    company_counts = top_jobs_df[\"company\"].value_counts()\n",
    "    print(f\"\\nüè¢ Top Companies:\")\n",
    "    for company, count in company_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {company}: {count} job(s)\")\n",
    "\n",
    "    # NEW: Company intelligence analysis\n",
    "    print(f\"\\nüè¢ COMPANY INTELLIGENCE ANALYSIS:\")\n",
    "\n",
    "    # Company size analysis\n",
    "    company_size_data = top_jobs_df[\"company_size\"].dropna()\n",
    "    if not company_size_data.empty:\n",
    "        print(\n",
    "            f\"  üë• Company Size Info Available: {len(company_size_data)}/{len(top_jobs_df)} jobs ({len(company_size_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(f\"     Sample sizes: {', '.join(company_size_data.head(3).astype(str))}\")\n",
    "    else:\n",
    "        print(f\"  üë• Company Size Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company followers analysis\n",
    "    company_followers_data = top_jobs_df[\"company_followers\"].dropna()\n",
    "    if not company_followers_data.empty:\n",
    "        print(\n",
    "            f\"  üìä Company Followers Info: {len(company_followers_data)}/{len(top_jobs_df)} jobs ({len(company_followers_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"     Sample followers: {', '.join(company_followers_data.head(3).astype(str))}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"  üìä Company Followers Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company industry analysis\n",
    "    company_industry_data = top_jobs_df[\"company_industry\"].dropna()\n",
    "    if not company_industry_data.empty:\n",
    "        print(\n",
    "            f\"  üè≠ Company Industry Info: {len(company_industry_data)}/{len(top_jobs_df)} jobs ({len(company_industry_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        industry_counts = company_industry_data.value_counts().head(3)\n",
    "        print(f\"     Top industries: {', '.join(industry_counts.index)}\")\n",
    "    else:\n",
    "        print(f\"  üè≠ Company Industry Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Location distribution (enhanced)\n",
    "    location_counts = top_jobs_df[\"location\"].value_counts()\n",
    "    print(f\"\\nüìç Top Locations:\")\n",
    "    for location, count in location_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {location}: {count} job(s)\")\n",
    "\n",
    "    # Work location type analysis\n",
    "    if \"work_location_type\" in top_jobs_df.columns:\n",
    "        work_type_counts = top_jobs_df[\"work_location_type\"].value_counts(dropna=True)\n",
    "        print(f\"\\nüè† Work Location Types (Location Intelligence):\")\n",
    "        for work_type, count in work_type_counts.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            percentage = count / len(top_jobs_df) * 100\n",
    "            print(f\"  {emoji} {work_type}: {count} job(s) ({percentage:.1f}%)\")\n",
    "\n",
    "    # Experience level distribution\n",
    "    if \"level\" in top_jobs_df.columns:\n",
    "        level_counts = top_jobs_df[\"level\"].value_counts(dropna=True)\n",
    "        if not level_counts.empty:\n",
    "            print(f\"\\nüéØ Experience Levels:\")\n",
    "            for level, count in level_counts.items():\n",
    "                print(f\"  ‚Ä¢ {level}: {count} job(s)\")\n",
    "\n",
    "    # Employment type distribution\n",
    "    if \"employment_type\" in top_jobs_df.columns:\n",
    "        employment_counts = top_jobs_df[\"employment_type\"].value_counts(dropna=True)\n",
    "        if not employment_counts.empty:\n",
    "            print(f\"\\nüíº Employment Types:\")\n",
    "            for emp_type, count in employment_counts.items():\n",
    "                print(f\"  ‚Ä¢ {emp_type}: {count} job(s)\")\n",
    "\n",
    "    # Job function analysis\n",
    "    if \"job_function\" in top_jobs_df.columns:\n",
    "        function_counts = top_jobs_df[\"job_function\"].value_counts(dropna=True)\n",
    "        if not function_counts.empty:\n",
    "            print(f\"\\n‚öôÔ∏è Top Job Functions:\")\n",
    "            for function, count in function_counts.head().items():\n",
    "                print(f\"  ‚Ä¢ {function}: {count} job(s)\")\n",
    "\n",
    "    # Salary information availability\n",
    "    salary_jobs = top_jobs_df[\"salary_range\"].notna().sum()\n",
    "    print(\n",
    "        f\"\\nüí∞ Salary Information: {salary_jobs} out of {len(top_jobs_df)} jobs ({salary_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Applicant information\n",
    "    applicant_jobs = top_jobs_df[\"applicants\"].notna().sum()\n",
    "    print(\n",
    "        f\"üë• Applicant Count Available: {applicant_jobs} out of {len(top_jobs_df)} jobs ({applicant_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìà Data Quality Summary:\")\n",
    "    print(f\"  ‚úÖ All jobs have location intelligence classification\")\n",
    "    print(f\"  ‚úÖ Enhanced 20-column data structure with company info\")\n",
    "    print(f\"  ‚úÖ Company intelligence extraction available\")\n",
    "    print(f\"  ‚úÖ Comprehensive job metadata available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced salary analysis with location and company intelligence\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    salary_query = \"\"\"\n",
    "    SELECT title, company, company_size, company_followers, company_industry,\n",
    "           salary_range, location, work_location_type, level, employment_type\n",
    "    FROM jobs \n",
    "    WHERE salary_range IS NOT NULL AND salary_range != ''\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 15\n",
    "    \"\"\"\n",
    "\n",
    "    salary_jobs = pd.read_sql_query(salary_query, conn)\n",
    "\n",
    "if not salary_jobs.empty:\n",
    "    print(\"üí∞ JOBS WITH SALARY INFORMATION + LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 75)\n",
    "    for idx, job in salary_jobs.iterrows():\n",
    "        # Work type emoji\n",
    "        work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            job[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "\n",
    "        print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "        print(f\"    üí∞ {job['salary_range']}\")\n",
    "        print(f\"    üìç {job['location']} | {work_emoji} {job['work_location_type']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_details = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_details.append(f\"üë• {job['company_size']} employees\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_details.append(f\"üìä {job['company_followers']} followers\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_details.append(f\"üè≠ {job['company_industry']}\")\n",
    "\n",
    "        if company_details:\n",
    "            print(f\"    üè¢ {' | '.join(company_details)}\")\n",
    "\n",
    "        if job[\"level\"]:\n",
    "            print(f\"    üéØ {job['level']}\")\n",
    "        if job[\"employment_type\"]:\n",
    "            print(f\"    üìù {job['employment_type']}\")\n",
    "        print()\n",
    "\n",
    "    # Salary analysis by work type\n",
    "    if \"work_location_type\" in salary_jobs.columns:\n",
    "        print(\"üìà SALARY ANALYSIS BY WORK TYPE\")\n",
    "        print(\"=\" * 40)\n",
    "        work_type_salary = salary_jobs.groupby(\"work_location_type\").size()\n",
    "        for work_type, count in work_type_salary.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            print(f\"{emoji} {work_type}: {count} jobs with salary info\")\n",
    "\n",
    "    # NEW: Company size analysis for salary jobs\n",
    "    print(f\"\\nüè¢ COMPANY SIZE ANALYSIS FOR SALARY JOBS\")\n",
    "    print(\"=\" * 45)\n",
    "    company_size_salary = salary_jobs[salary_jobs[\"company_size\"].notna()]\n",
    "    if not company_size_salary.empty:\n",
    "        print(\n",
    "            f\"üíº Jobs with both salary and company size data: {len(company_size_salary)}\"\n",
    "        )\n",
    "        for idx, job in company_size_salary.head(5).iterrows():\n",
    "            print(\n",
    "                f\"  ‚Ä¢ {job['company']}: {job['company_size']} employees | {job['salary_range']}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"üìä No jobs found with both salary and company size information\")\n",
    "        print(\n",
    "            \"üí° Run 'make run-parser' to collect fresh data with company intelligence\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(\"No jobs with salary information found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9879302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ LOCATION & COMPANY INTELLIGENCE SHOWCASE\n",
    "print(\"üåç LOCATION & COMPANY INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get location intelligence statistics\n",
    "    location_intel_query = \"\"\"\n",
    "    SELECT \n",
    "        location,\n",
    "        work_location_type,\n",
    "        COUNT(*) as job_count,\n",
    "        GROUP_CONCAT(DISTINCT company) as companies,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as companies_with_size,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as companies_with_industry\n",
    "    FROM jobs \n",
    "    WHERE location IS NOT NULL\n",
    "    GROUP BY location, work_location_type\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    location_intel_df = pd.read_sql_query(location_intel_query, conn)\n",
    "\n",
    "if not location_intel_df.empty:\n",
    "    print(\"üìä Location + Work Type + Company Intelligence Distribution:\")\n",
    "    for idx, row in location_intel_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        companies = row[\"companies\"].split(\",\") if row[\"companies\"] else []\n",
    "\n",
    "        print(\n",
    "            f\"{emoji} {row['location']} - {row['work_location_type']}: {row['job_count']} jobs\"\n",
    "        )\n",
    "        if len(companies) <= 3:\n",
    "            print(f\"    Companies: {', '.join(companies)}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"    Companies: {', '.join(companies[:3])}... (+{len(companies)-3} more)\"\n",
    "            )\n",
    "\n",
    "        # NEW: Company intelligence stats\n",
    "        company_intel_info = []\n",
    "        if row[\"companies_with_size\"] > 0:\n",
    "            company_intel_info.append(f\"üë• {row['companies_with_size']} with size data\")\n",
    "        if row[\"companies_with_industry\"] > 0:\n",
    "            company_intel_info.append(\n",
    "                f\"üè≠ {row['companies_with_industry']} with industry data\"\n",
    "            )\n",
    "\n",
    "        if company_intel_info:\n",
    "            print(f\"    Company Intel: {' | '.join(company_intel_info)}\")\n",
    "        print()\n",
    "\n",
    "    # Overall location intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        summary_query = \"\"\"\n",
    "        SELECT \n",
    "            work_location_type,\n",
    "            COUNT(*) as count,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM jobs), 1) as percentage\n",
    "        FROM jobs \n",
    "        WHERE work_location_type IS NOT NULL\n",
    "        GROUP BY work_location_type\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        summary_df = pd.read_sql_query(summary_query, conn)\n",
    "\n",
    "    print(\"üéØ WORK TYPE INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{emoji} {row['work_location_type']:8s}: {row['count']:3d} jobs ({row['percentage']:5.1f}%)\"\n",
    "        )\n",
    "\n",
    "    # NEW: Company intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        company_intel_summary = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_jobs,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as jobs_with_size,\n",
    "            COUNT(CASE WHEN company_followers IS NOT NULL THEN 1 END) as jobs_with_followers,\n",
    "            COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as jobs_with_industry,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL AND company_followers IS NOT NULL THEN 1 END) as jobs_with_both\n",
    "        FROM jobs\n",
    "        \"\"\"\n",
    "        company_stats = pd.read_sql_query(company_intel_summary, conn).iloc[0]\n",
    "\n",
    "    print(f\"\\nüè¢ COMPANY INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    total = company_stats[\"total_jobs\"]\n",
    "    print(\n",
    "        f\"üë• Company Size Data:     {company_stats['jobs_with_size']:3d}/{total} jobs ({company_stats['jobs_with_size']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üìä Company Followers:     {company_stats['jobs_with_followers']:3d}/{total} jobs ({company_stats['jobs_with_followers']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üè≠ Company Industry:      {company_stats['jobs_with_industry']:3d}/{total} jobs ({company_stats['jobs_with_industry']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üéØ Complete Company Data: {company_stats['jobs_with_both']:3d}/{total} jobs ({company_stats['jobs_with_both']/total*100:5.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚ú® Enhanced Intelligence Features:\")\n",
    "    print(f\"   üéØ Automatic location extraction from job postings\")\n",
    "    print(f\"   ü§ñ AI-powered work type classification\")\n",
    "    print(f\"   üè¢ Company size, followers, and industry extraction\")\n",
    "    print(f\"   üìä Enhanced analytics with location and company data\")\n",
    "    print(f\"   üíæ 20-column output with integrated company information\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"No location data found. Run 'make run-parser' to collect jobs with location & company intelligence.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç QUICK COMPANY INTELLIGENCE CHECK\n",
    "print(\"üîç CURRENT COMPANY INTELLIGENCE COVERAGE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get current state of company fields\n",
    "    coverage_query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_jobs,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL AND company_size != '' THEN 1 END) as jobs_with_size,\n",
    "        COUNT(CASE WHEN company_followers IS NOT NULL AND company_followers != '' THEN 1 END) as jobs_with_followers,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL AND company_industry != '' THEN 1 END) as jobs_with_industry\n",
    "    FROM jobs\n",
    "    \"\"\"\n",
    "    coverage_stats = pd.read_sql_query(coverage_query, conn).iloc[0]\n",
    "\n",
    "    print(f\"üìä Database-wide Company Intelligence:\")\n",
    "    total = coverage_stats[\"total_jobs\"]\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(\n",
    "        f\"   üë• Company Size: {coverage_stats['jobs_with_size']} jobs ({coverage_stats['jobs_with_size']/total*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   üìä Company Followers: {coverage_stats['jobs_with_followers']} jobs ({coverage_stats['jobs_with_followers']/total*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   üè≠ Company Industry: {coverage_stats['jobs_with_industry']} jobs ({coverage_stats['jobs_with_industry']/total*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Show some examples of extracted company info\n",
    "    sample_query = \"\"\"\n",
    "    SELECT company, company_size, company_followers, company_industry, title\n",
    "    FROM jobs \n",
    "    WHERE (company_size IS NOT NULL AND company_size != '') \n",
    "       OR (company_followers IS NOT NULL AND company_followers != '')\n",
    "       OR (company_industry IS NOT NULL AND company_industry != '')\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    sample_companies = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "    print(f\"\\nüè¢ Examples of Company Intelligence:\")\n",
    "    for idx, row in sample_companies.iterrows():\n",
    "        print(f\"   {idx+1}. {row['company']}\")\n",
    "        if row[\"company_size\"]:\n",
    "            print(f\"      üë• Size: {row['company_size']}\")\n",
    "        if row[\"company_followers\"]:\n",
    "            print(f\"      üìä Followers: {row['company_followers']}\")\n",
    "        if row[\"company_industry\"]:\n",
    "            print(f\"      üè≠ Industry: {row['company_industry']}\")\n",
    "        print(f\"      Job: {row['title']}\")\n",
    "        print()\n",
    "\n",
    "print(f\"‚ú® The enhanced company parser successfully extracted information!\")\n",
    "print(f\"üí° To improve coverage further, run: make fix-company-info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27363121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä EXPORT & DATA VALIDATION\n",
    "print(\"üì§ CSV EXPORT WITH ENHANCED DATA + COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Export current job data to CSV in the main data folder\n",
    "csv_filename = db.export_jobs_to_csv(\"../data/notebook_analysis_export.csv\")\n",
    "print(f\"‚úÖ Jobs exported to: {csv_filename}\")\n",
    "\n",
    "# Validate the exported CSV structure\n",
    "if csv_filename:\n",
    "    import pandas as pd\n",
    "\n",
    "    exported_df = pd.read_csv(csv_filename)\n",
    "\n",
    "    print(f\"\\nüìã Export Validation:\")\n",
    "    print(f\"   Shape: {exported_df.shape}\")\n",
    "    print(f\"   Columns: {exported_df.shape[1]} (should be 21)\")\n",
    "\n",
    "    expected_columns = [\n",
    "        \"id\",\n",
    "        \"company\",\n",
    "        \"company_size\",\n",
    "        \"company_followers\",\n",
    "        \"company_industry\",\n",
    "        \"title\",\n",
    "        \"location\",\n",
    "        \"work_location_type\",\n",
    "        \"level\",\n",
    "        \"salary_range\",\n",
    "        \"content\",\n",
    "        \"employment_type\",\n",
    "        \"job_function\",\n",
    "        \"industries\",\n",
    "        \"posted_time\",\n",
    "        \"applicants\",\n",
    "        \"job_id\",\n",
    "        \"date\",\n",
    "        \"parsing_link\",\n",
    "        \"job_posting_link\",\n",
    "        \"company_info_link\",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n‚úÖ Column Validation:\")\n",
    "    missing_cols = set(expected_columns) - set(exported_df.columns)\n",
    "    extra_cols = set(exported_df.columns) - set(expected_columns)\n",
    "\n",
    "    if not missing_cols and not extra_cols:\n",
    "        print(\"   üéØ Perfect! All 21 expected columns present\")\n",
    "    else:\n",
    "        if missing_cols:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing columns: {missing_cols}\")\n",
    "        if extra_cols:\n",
    "            print(f\"   ‚ûï Extra columns: {extra_cols}\")\n",
    "\n",
    "    print(f\"\\nüìä Data Quality Check:\")\n",
    "    print(\n",
    "        f\"   Location data: {exported_df['location'].notna().sum()}/{len(exported_df)} jobs ({exported_df['location'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Work type data: {exported_df['work_location_type'].notna().sum()}/{len(exported_df)} jobs ({exported_df['work_location_type'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company data: {exported_df['company'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company size: {exported_df['company_size'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_size'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company followers: {exported_df['company_followers'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_followers'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company industry: {exported_df['company_industry'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_industry'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Check if company_info_link column exists (since it was recently added)\n",
    "    if \"company_info_link\" in exported_df.columns:\n",
    "        company_link_count = exported_df[\"company_info_link\"].notna().sum()\n",
    "        print(\n",
    "            f\"   Company info link: {company_link_count}/{len(exported_df)} jobs ({company_link_count/len(exported_df)*100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # DIAGNOSTIC: Show why company_info_link is mostly empty\n",
    "        if company_link_count == 0:\n",
    "            print(f\"\\nüîç DIAGNOSTIC: Company Info Link Issue\")\n",
    "            print(f\"   ‚ùå No jobs have company_info_link values\")\n",
    "            print(\n",
    "                f\"   üîß Root Cause: Company URL extraction during parsing not working\"\n",
    "            )\n",
    "            print(f\"   üìã Technical Details:\")\n",
    "            print(\n",
    "                f\"      ‚Ä¢ Field implementation: ‚úÖ Complete (database schema, models, parser)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      ‚Ä¢ URL extraction: ‚ùå CSS selectors not finding company links on LinkedIn\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      ‚Ä¢ Solution: Update _extract_company_link() method in company_parser.py\"\n",
    "            )\n",
    "        elif company_link_count < len(exported_df) * 0.1:  # Less than 10%\n",
    "            print(f\"\\n‚ö†Ô∏è  DIAGNOSTIC: Low Company Info Link Coverage\")\n",
    "            print(f\"   üìä Only {company_link_count} jobs have company_info_link\")\n",
    "            print(\n",
    "                f\"   üîß Likely Issue: CSS selectors partially working but need improvement\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   üìã Recommendation: Review and update LinkedIn company link selectors\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"   Company info link: ‚ùå Column missing (database export needs update)\")\n",
    "\n",
    "    print(\n",
    "        f\"   Title data: {exported_df['title'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\nüéâ SUCCESS: Enhanced LinkedIn parser with location & company intelligence is working!\"\n",
    "    )\n",
    "    print(f\"   üíæ Database: data/jobs.db\")\n",
    "    print(f\"   üì§ Export: {csv_filename}\")\n",
    "    print(f\"   üéØ Use: make run-parser (to collect more jobs with company info)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\n",
    "    \"üöÄ ANALYSIS COMPLETE - Enhanced LinkedIn Parser with Company Intelligence Ready!\"\n",
    ")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1107ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ RUN PARSER + CLEANER BACK TO BACK\n",
    "print(\"üöÄ RUNNING PARSER + DATA CLEANER PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Step 1: Run the parser to collect fresh job data\n",
    "print(\"üì• Step 1: Running LinkedIn Parser...\")\n",
    "print(\"Command: make run-parser\")\n",
    "try:\n",
    "    parser_result = subprocess.run(\n",
    "        [\"make\", \"run-parser\"],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300,  # 5 minute timeout\n",
    "    )\n",
    "\n",
    "    if parser_result.returncode == 0:\n",
    "        print(\"‚úÖ Parser completed successfully!\")\n",
    "        # Extract some stats from output if available\n",
    "        lines = parser_result.stdout.split(\"\\n\")\n",
    "        for line in lines[-10:]:  # Show last 10 lines\n",
    "            if line.strip() and (\n",
    "                \"saved\" in line.lower()\n",
    "                or \"exported\" in line.lower()\n",
    "                or \"jobs\" in line.lower()\n",
    "            ):\n",
    "                print(f\"   {line.strip()}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Parser completed with warnings:\")\n",
    "        print(f\"   Return code: {parser_result.returncode}\")\n",
    "        if parser_result.stderr:\n",
    "            print(f\"   Error: {parser_result.stderr[-500:]}\")  # Last 500 chars\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Parser timeout after 5 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parser error: {e}\")\n",
    "\n",
    "# Small delay between operations\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 2: Run the data cleaner on the fresh data\n",
    "print(f\"\\nüßπ Step 2: Running Data Cleaner...\")\n",
    "print(\"Command: python -m genai_job_finder.data_cleaner.run_graph\")\n",
    "try:\n",
    "    cleaner_result = subprocess.run(\n",
    "        [\n",
    "            \"/home/alireza/.cache/pypoetry/virtualenvs/genai-job-finder-Y_k-9c-5-py3.12/bin/python\",\n",
    "            \"-m\",\n",
    "            \"genai_job_finder.data_cleaner.run_graph\",\n",
    "            \"--db-path\",\n",
    "            \"data/jobs.db\",\n",
    "            \"--verbose\",\n",
    "        ],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=600,  # 10 minute timeout for AI processing\n",
    "    )\n",
    "\n",
    "    if cleaner_result.returncode == 0:\n",
    "        print(\"‚úÖ Data cleaner completed successfully!\")\n",
    "        # Extract processing summary\n",
    "        lines = cleaner_result.stdout.split(\"\\n\")\n",
    "        in_summary = False\n",
    "        for line in lines:\n",
    "            if \"PROCESSING SUMMARY\" in line:\n",
    "                in_summary = True\n",
    "                print(f\"\\nüìä {line}\")\n",
    "            elif in_summary and (\"=\" in line or line.strip() == \"\"):\n",
    "                if \"=\" in line:\n",
    "                    print(line)\n",
    "                    in_summary = False\n",
    "            elif in_summary:\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Data cleaner completed with issues:\")\n",
    "        print(f\"   Return code: {cleaner_result.returncode}\")\n",
    "        if cleaner_result.stderr:\n",
    "            print(f\"   Error: {cleaner_result.stderr[-500:]}\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Data cleaner timeout after 10 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data cleaner error: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ Pipeline Complete!\")\n",
    "print(\"   üì• Fresh job data collected\")\n",
    "print(\"   üßπ AI-powered data cleaning applied\")\n",
    "print(\"   üíæ Results available in cleaned_jobs table\")\n",
    "print(\"   üìä Ready for enhanced analysis below ‚¨áÔ∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc70e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ CLEANED JOBS TABLE ANALYSIS\n",
    "print(\"‚ú® ANALYZING AI-CLEANED JOB DATA WITH COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if cleaned_jobs table exists\n",
    "    tables_query = (\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\"\n",
    "    )\n",
    "    table_exists = pd.read_sql_query(tables_query, conn)\n",
    "\n",
    "    if table_exists.empty:\n",
    "        print(\"‚ùå No cleaned_jobs table found.\")\n",
    "        print(\"üí° Run the cell above to execute the parser + cleaner pipeline first.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Cleaned jobs table found!\")\n",
    "\n",
    "        # Get basic stats\n",
    "        total_cleaned = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "        print(f\"üìä Total cleaned jobs: {total_cleaned}\")\n",
    "\n",
    "        if total_cleaned > 0:\n",
    "            # Get the schema of cleaned table\n",
    "            schema_query = \"PRAGMA table_info(cleaned_jobs)\"\n",
    "            schema_df = pd.read_sql_query(schema_query, conn)\n",
    "            print(f\"üèóÔ∏è Table structure: {len(schema_df)} columns\")\n",
    "\n",
    "            # Sample of cleaned data with company information\n",
    "            sample_query = \"\"\"\n",
    "            SELECT \n",
    "                id, company, company_size, company_followers, company_industry,\n",
    "                title, location, \n",
    "                min_years_experience, experience_level_label,\n",
    "                work_location_type, employment_type,\n",
    "                min_salary, max_salary, mid_salary, content\n",
    "            FROM cleaned_jobs \n",
    "            ORDER BY id DESC \n",
    "            LIMIT 10\n",
    "            \"\"\"\n",
    "\n",
    "            cleaned_sample = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "            print(f\"\\nüìã SAMPLE CLEANED JOBS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 70)\n",
    "            for idx, job in cleaned_sample.iterrows():\n",
    "                print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "                print(f\"    üìç {job['location']}\")\n",
    "\n",
    "                # NEW: Company information display\n",
    "                company_details = []\n",
    "                if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "                    company_details.append(f\"üë• {job['company_size']} employees\")\n",
    "                if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "                    company_details.append(f\"üìä {job['company_followers']} followers\")\n",
    "                if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "                    company_details.append(f\"üè≠ {job['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"    üè¢ {' | '.join(company_details)}\")\n",
    "\n",
    "                # Experience info\n",
    "                if pd.notna(job[\"min_years_experience\"]) and pd.notna(\n",
    "                    job[\"experience_level_label\"]\n",
    "                ):\n",
    "                    print(\n",
    "                        f\"    üéØ Experience: {job['min_years_experience']} years ‚Üí {job['experience_level_label']}\"\n",
    "                    )\n",
    "\n",
    "                # Salary info\n",
    "                if pd.notna(job[\"min_salary\"]) and pd.notna(job[\"max_salary\"]):\n",
    "                    print(\n",
    "                        f\"    üí∞ Salary: ${job['min_salary']:,.0f} - ${job['max_salary']:,.0f} (Mid: ${job['mid_salary']:,.0f})\"\n",
    "                    )\n",
    "\n",
    "                # Work details\n",
    "                work_details = []\n",
    "                if pd.notna(job[\"work_location_type\"]):\n",
    "                    work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                        job[\"work_location_type\"], \"üìç\"\n",
    "                    )\n",
    "                    work_details.append(f\"{work_emoji} {job['work_location_type']}\")\n",
    "                if pd.notna(job[\"employment_type\"]):\n",
    "                    work_details.append(job[\"employment_type\"])\n",
    "                if work_details:\n",
    "                    print(f\"    üìù {' | '.join(work_details)}\")\n",
    "                print()\n",
    "\n",
    "cleaned_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìäüîÑ BEFORE vs AFTER: Data Transformation Analysis with Company Intelligence\n",
    "print(\"üîÑ ORIGINAL vs AI-CLEANED DATA COMPARISON (WITH COMPANY INTELLIGENCE)\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if both tables exist\n",
    "    original_exists = (\n",
    "        pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\"count\"]\n",
    "        > 0\n",
    "    )\n",
    "    cleaned_exists = (\n",
    "        len(\n",
    "            pd.read_sql_query(\n",
    "                \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\",\n",
    "                conn,\n",
    "            )\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "\n",
    "    if not cleaned_exists:\n",
    "        print(\"‚ùå Need cleaned data for comparison\")\n",
    "        print(\"üí° Run: make run-pipeline\")\n",
    "    elif not original_exists:\n",
    "        print(\"‚ùå No original data found\")\n",
    "    else:\n",
    "        cleaned_count = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "\n",
    "        if cleaned_count == 0:\n",
    "            print(\"üì≠ Cleaned table is empty\")\n",
    "            print(\"üí° Run: make run-cleaner\")\n",
    "        else:\n",
    "            print(\"üìä DATA TRANSFORMATION PIPELINE RESULTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            # Side-by-side comparison of same jobs including company info\n",
    "            comparison_query = \"\"\"\n",
    "            SELECT \n",
    "                o.id,\n",
    "                o.company,\n",
    "                o.company_size,\n",
    "                o.company_followers,\n",
    "                o.company_industry,\n",
    "                o.title,\n",
    "                o.location,\n",
    "                o.level as original_level,\n",
    "                o.salary_range as original_salary,\n",
    "                o.employment_type as original_employment,\n",
    "                c.min_years_experience as ai_years,\n",
    "                c.experience_level_label as ai_level,\n",
    "                CASE \n",
    "                    WHEN c.min_salary IS NOT NULL THEN c.min_salary || ' - ' || c.max_salary || ' (Mid: ' || c.mid_salary || ')'\n",
    "                    ELSE 'Not extracted'\n",
    "                END as ai_salary,\n",
    "                c.work_location_type as ai_work_type,\n",
    "                c.employment_type as ai_employment\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            ORDER BY o.id DESC\n",
    "            LIMIT 5\n",
    "            \"\"\"\n",
    "\n",
    "            comparison_df = pd.read_sql_query(comparison_query, conn)\n",
    "\n",
    "            print(\"üîç DETAILED TRANSFORMATION EXAMPLES WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"(Showing how AI enhanced the original data)\")\n",
    "            print()\n",
    "\n",
    "            for idx, row in comparison_df.iterrows():\n",
    "                print(f\"üìã JOB {idx+1}: {row['title']} at {row['company']}\")\n",
    "                print(f\"   üìç Location: {row['location']}\")\n",
    "\n",
    "                # NEW: Company intelligence display\n",
    "                company_details = []\n",
    "                if pd.notna(row[\"company_size\"]) and row[\"company_size\"]:\n",
    "                    company_details.append(f\"üë• {row['company_size']} employees\")\n",
    "                if pd.notna(row[\"company_followers\"]) and row[\"company_followers\"]:\n",
    "                    company_details.append(f\"üìä {row['company_followers']} followers\")\n",
    "                if pd.notna(row[\"company_industry\"]) and row[\"company_industry\"]:\n",
    "                    company_details.append(f\"üè≠ {row['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"   üè¢ Company Intel: {' | '.join(company_details)}\")\n",
    "                print()\n",
    "\n",
    "                # Experience comparison\n",
    "                print(\"   üéØ EXPERIENCE ANALYSIS:\")\n",
    "                print(f\"      Original: '{row['original_level'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_years']} years ‚Üí {row['ai_level']}\")\n",
    "                print()\n",
    "\n",
    "                # Salary comparison\n",
    "                print(\"   üí∞ SALARY INTELLIGENCE:\")\n",
    "                print(f\"      Original: '{row['original_salary'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_salary']}\")\n",
    "                print()\n",
    "\n",
    "                # Employment type comparison\n",
    "                print(\"   üìù EMPLOYMENT TYPE:\")\n",
    "                print(\n",
    "                    f\"      Original: '{row['original_employment'] or 'Not specified'}'\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"      AI Result: {row['ai_employment']} | Work Type: {row['ai_work_type']}\"\n",
    "                )\n",
    "                print()\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "            # Statistical improvements including company intelligence\n",
    "            print(\"üìà STATISTICAL IMPROVEMENTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Count improvements\n",
    "            improvements_query = \"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_jobs,\n",
    "                -- Experience data\n",
    "                COUNT(CASE WHEN o.level IS NOT NULL AND o.level != '' THEN 1 END) as original_exp_data,\n",
    "                COUNT(CASE WHEN c.experience_level_label IS NOT NULL THEN 1 END) as ai_exp_data,\n",
    "                -- Salary data  \n",
    "                COUNT(CASE WHEN o.salary_range IS NOT NULL AND o.salary_range != '' THEN 1 END) as original_salary_data,\n",
    "                COUNT(CASE WHEN c.min_salary IS NOT NULL THEN 1 END) as ai_salary_data,\n",
    "                -- Work location data\n",
    "                COUNT(CASE WHEN c.work_location_type IS NOT NULL THEN 1 END) as ai_work_type_data,\n",
    "                -- Company intelligence data (already in original)\n",
    "                COUNT(CASE WHEN o.company_size IS NOT NULL THEN 1 END) as company_size_data,\n",
    "                COUNT(CASE WHEN o.company_followers IS NOT NULL THEN 1 END) as company_followers_data,\n",
    "                COUNT(CASE WHEN o.company_industry IS NOT NULL THEN 1 END) as company_industry_data\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "            improvements_stats = pd.read_sql_query(improvements_query, conn).iloc[0]\n",
    "            total = improvements_stats[\"total_jobs\"]\n",
    "\n",
    "            print(f\"üéØ Experience Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_exp_data']}/{total} jobs ({improvements_stats['original_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_exp_data']}/{total} jobs ({improvements_stats['ai_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            exp_improvement = (\n",
    "                improvements_stats[\"ai_exp_data\"]\n",
    "                - improvements_stats[\"original_exp_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{exp_improvement} jobs (+{exp_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üí∞ Salary Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_salary_data']}/{total} jobs ({improvements_stats['original_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_salary_data']}/{total} jobs ({improvements_stats['ai_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            salary_improvement = (\n",
    "                improvements_stats[\"ai_salary_data\"]\n",
    "                - improvements_stats[\"original_salary_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{salary_improvement} jobs (+{salary_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üè† Work Location Type (New):\")\n",
    "            print(f\"   Before: 0/{total} jobs (0.0%) - Not available in original\")\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_work_type_data']}/{total} jobs ({improvements_stats['ai_work_type_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{improvements_stats['ai_work_type_data']} jobs (NEW FEATURE)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            # NEW: Company intelligence summary\n",
    "            print(f\"üè¢ Company Intelligence (Integrated in Parser):\")\n",
    "            print(\n",
    "                f\"   Company Size:     {improvements_stats['company_size_data']}/{total} jobs ({improvements_stats['company_size_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Followers: {improvements_stats['company_followers_data']}/{total} jobs ({improvements_stats['company_followers_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Industry:  {improvements_stats['company_industry_data']}/{total} jobs ({improvements_stats['company_industry_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                \"   üí° Company data extracted during parsing phase, available in both tables\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b335c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ FRESH DATABASE TEST - Company Info Link Debugging\n",
    "print(\"üî¨ DIRECT SQL QUERY TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test direct SQL query to bypass any caching issues\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Test the exact query that should be used in export\n",
    "    query = '''\n",
    "        SELECT id, company, title, location, work_location_type, level, salary_range, content,\n",
    "               employment_type, job_function, industries, posted_time,\n",
    "               applicants, job_id, date, parsing_link, job_posting_link,\n",
    "               company_size, company_followers, company_industry, company_info_link\n",
    "        FROM jobs\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT 5\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        direct_df = pd.read_sql_query(query, conn)\n",
    "        print(f\"‚úÖ Direct SQL query successful:\")\n",
    "        print(f\"   Shape: {direct_df.shape}\")\n",
    "        print(f\"   Columns: {direct_df.shape[1]}\")\n",
    "        print(f\"   company_info_link present: {'company_info_link' in direct_df.columns}\")\n",
    "        \n",
    "        if 'company_info_link' in direct_df.columns:\n",
    "            print(f\"   Column names: {list(direct_df.columns)}\")\n",
    "            print(f\"\\n\udcca Sample company_info_link values:\")\n",
    "            for i in range(len(direct_df)):\n",
    "                company = direct_df.iloc[i]['company']\n",
    "                link = direct_df.iloc[i]['company_info_link'] \n",
    "                status = 'HAS LINK' if pd.notna(link) and link else 'EMPTY'\n",
    "                print(f\"   {company}: {status}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå company_info_link column missing from direct query\")\n",
    "            print(f\"   Columns: {list(direct_df.columns)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Direct SQL query failed: {e}\")\n",
    "\n",
    "# Now test what the notebook's db instance is actually doing\n",
    "print(f\"\\nüîç NOTEBOOK DB INSTANCE DEBUG:\")\n",
    "try:\n",
    "    # Check if the database manager has the right database path\n",
    "    print(f\"   Database path: {db.db_path}\")\n",
    "    \n",
    "    # Test get_all_jobs_as_dataframe method\n",
    "    test_df = db.get_all_jobs_as_dataframe()\n",
    "    print(f\"   get_all_jobs_as_dataframe(): {test_df.shape}\")\n",
    "    print(f\"   Columns: {test_df.shape[1]}\")\n",
    "    print(f\"   company_info_link present: {'company_info_link' in test_df.columns}\")\n",
    "    \n",
    "    # Show what columns are actually returned\n",
    "    print(f\"   Actual columns: {list(test_df.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(f\"\\n\udd27 DIAGNOSIS:\")\n",
    "print(f\"   If direct SQL shows 21 columns but db instance shows 20,\")\n",
    "print(f\"   then there's an issue with the notebook's database manager instance.\")\n",
    "print(f\"   This could be due to an old cached version of the code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-job-finder-Y_k-9c-5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
