{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be7e499",
   "metadata": {},
   "source": [
    "# Enhanced LinkedIn Job Database Analysis\n",
    "\n",
    "This notebook analyzes the LinkedIn job database with the new enhanced parser that includes:\n",
    "\n",
    "- **17-column output structure** (matching legacy format)\n",
    "- **Location intelligence** with automatic extraction\n",
    "- **Work type classification** (Remote/Hybrid/On-site)\n",
    "- **Enhanced data model** with comprehensive job information\n",
    "\n",
    "Run `make run-parser` first to collect fresh job data with location intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = (\n",
    "    Path(__file__).parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    ")\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from genai_job_finder.linkedin_parser.database import DatabaseManager\n",
    "from genai_job_finder.linkedin_parser.models import Job, JobRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1daf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/alireza/projects/genai_job_finder')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5a736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /home/alireza/projects/genai_job_finder/data/jobs.db\n",
      "Database exists: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db_path = project_root / \"data\" / \"jobs.db\"\n",
    "# db_path = project_root / \"test_jobs.db\"\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")\n",
    "\n",
    "# Create database manager\n",
    "db = DatabaseManager(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b1a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in database: 199\n",
      "Total job runs: 16\n",
      "\n",
      "Recent job runs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "search_query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location_filter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "faf8d5db-862a-41d3-b173-be0df7e0354a",
       "rows": [
        [
         "0",
         "16",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-08-24 17:35:39"
        ],
        [
         "1",
         "15",
         "data scientist",
         "San Antonio",
         "completed",
         "10",
         "2025-08-24 05:20:24"
        ],
        [
         "2",
         "14",
         "data scientist",
         "San Antonio",
         "pending",
         "0",
         "2025-08-22 20:53:14"
        ],
        [
         "3",
         "13",
         "data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-08-22 20:43:51"
        ],
        [
         "4",
         "12",
         "data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-08-22 02:51:16"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>location_filter</th>\n",
       "      <th>status</th>\n",
       "      <th>job_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-08-24 17:35:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-08-24 05:20:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>pending</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-22 20:53:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-08-22 20:43:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-08-22 02:51:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    search_query location_filter     status  job_count  \\\n",
       "0  16  data scientist     San Antonio  completed          9   \n",
       "1  15  data scientist     San Antonio  completed         10   \n",
       "2  14  data scientist     San Antonio    pending          0   \n",
       "3  13  data scientist     San Antonio  completed         20   \n",
       "4  12  data scientist     San Antonio  completed         20   \n",
       "\n",
       "            created_at  \n",
       "0  2025-08-24 17:35:39  \n",
       "1  2025-08-24 05:20:24  \n",
       "2  2025-08-22 20:53:14  \n",
       "3  2025-08-22 20:43:51  \n",
       "4  2025-08-22 02:51:16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check database contents - get basic stats\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Count total jobs\n",
    "    total_jobs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\n",
    "        \"count\"\n",
    "    ]\n",
    "    print(f\"Total jobs in database: {total_jobs}\")\n",
    "\n",
    "    # Count job runs\n",
    "    total_runs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM job_runs\", conn).iloc[\n",
    "        0\n",
    "    ][\"count\"]\n",
    "    print(f\"Total job runs: {total_runs}\")\n",
    "\n",
    "    # Show recent runs\n",
    "    if total_runs > 0:\n",
    "        recent_runs = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT id, search_query, location_filter, status, job_count, created_at \n",
    "            FROM job_runs \n",
    "            ORDER BY created_at DESC \n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "            conn,\n",
    "        )\n",
    "        print(\"\\nRecent job runs:\")\n",
    "recent_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c5edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Enhanced Job Data Analysis\n",
      "Database contains: 20 recent jobs\n",
      "Columns: 17 (17-column structure)\n",
      "\n",
      "Column names: ['id', 'company', 'title', 'location', 'work_location_type', 'level', 'salary_range', 'employment_type', 'job_function', 'industries', 'posted_time', 'applicants', 'job_id', 'date', 'parsing_link', 'job_posting_link', 'created_at']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "work_location_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_range",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industries",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "posted_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicants",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parsing_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_posting_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "41fa4cc2-225c-47d8-b78a-5bed0eb8674c",
       "rows": [
        [
         "0",
         "77378205-0eb0-424a-a80a-7cf03d4148c4",
         "Enlighten",
         "Platform Engineer (Hybrid) - 23372",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         "$97,097.00/yr - $135,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "3 hours ago",
         "N/A",
         "4240397674",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4240397674",
         "https://www.linkedin.com/jobs/view/platform-engineer-hybrid-23372-at-enlighten-4240397674?trk=public_jobs_topcard-title",
         "2025-08-24 17:36:04"
        ],
        [
         "1",
         "4a7e217a-cc5c-4694-a8ec-5eb5e682ee5b",
         "Tata Consultancy Services",
         "TeamCenter Developer",
         "Universal City, TX",
         "On-site",
         "Entry level",
         "$110,000.00/yr - $150,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "IT Services and IT Consulting",
         "7 hours ago",
         "N/A",
         "4278190133",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278190133",
         "https://www.linkedin.com/jobs/view/teamcenter-developer-at-tata-consultancy-services-4278190133?trk=public_jobs_topcard-title",
         "2025-08-24 17:36:02"
        ],
        [
         "2",
         "f9a2ea18-179b-4820-8454-47c2f3af5d01",
         "ClearanceJobs",
         "Tier 3 Level EM Packaging Support Services with Security Clearance",
         "San Antonio, TX",
         "Hybrid",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Defense and Space Manufacturing",
         "1 day ago",
         "N/A",
         "4287660267",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4287660267",
         "https://www.linkedin.com/jobs/view/tier-3-level-em-packaging-support-services-with-security-clearance-at-clearancejobs-4287660267?trk=public_jobs_topcard-title",
         "2025-08-24 17:36:01"
        ],
        [
         "3",
         "fed4c5db-5b12-47cd-9d27-c20aeae7c907",
         "Lensa",
         "Biostatistician I",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         null,
         "Full-time",
         "Research, Analyst, and Information Technology",
         "Internet Publishing",
         "6 hours ago",
         "N/A",
         "4290466358",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290466358",
         "https://www.linkedin.com/jobs/view/biostatistician-i-at-lensa-4290466358?trk=public_jobs_topcard-title",
         "2025-08-24 17:35:58"
        ],
        [
         "4",
         "6636f3cb-859b-4546-a122-454f63250570",
         "Shrive Technologies",
         "Snowflake Developer with SQL, Python, DBT",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "21 hours ago",
         "N/A",
         "4290423063",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290423063",
         "https://www.linkedin.com/jobs/view/snowflake-developer-with-sql-python-dbt-at-shrive-technologies-4290423063?trk=public_jobs_topcard-title",
         "2025-08-24 17:35:55"
        ],
        [
         "5",
         "991a78ff-17de-472b-9b7e-55208654bd4f",
         "Jobs via Dice",
         "Senior Full Stack Developer",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         "$92,000.00/yr - $153,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "5 hours ago",
         "N/A",
         "4290174501",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290174501",
         "https://www.linkedin.com/jobs/view/senior-full-stack-developer-at-jobs-via-dice-4290174501?trk=public_jobs_topcard-title",
         "2025-08-24 17:35:52"
        ],
        [
         "6",
         "e25a75e4-4132-48c0-8658-e23a5a9cca9e",
         "Aha!",
         "Sr. Security Engineer (Ruby on Rails experience required)",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "5 hours ago",
         "N/A",
         "4290465339",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290465339",
         "https://www.linkedin.com/jobs/view/sr-security-engineer-ruby-on-rails-experience-required-at-aha%21-4290465339?trk=public_jobs_topcard-title",
         "2025-08-24 17:35:49"
        ],
        [
         "7",
         "d2da9874-e953-4c98-919c-1a6e84efe453",
         "Lensa",
         "Internships in Computer Science or Software Engineering",
         "San Antonio, TX",
         "Remote",
         "Internship",
         null,
         "Internship",
         "Engineering and Information Technology",
         "Internet Publishing",
         "6 hours ago",
         "N/A",
         "4290467346",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290467346",
         "https://www.linkedin.com/jobs/view/internships-in-computer-science-or-software-engineering-at-lensa-4290467346?trk=public_jobs_topcard-title",
         "2025-08-24 17:35:47"
        ],
        [
         "8",
         "614c7411-bc60-43a6-98f7-b35c9ba4502a",
         "Aha!",
         "Sr. Platform Engineer",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "5 hours ago",
         "N/A",
         "4290467247",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290467247",
         "https://www.linkedin.com/jobs/view/sr-platform-engineer-at-aha%21-4290467247?trk=public_jobs_topcard-title",
         "2025-08-24 17:35:44"
        ],
        [
         "9",
         "e2763d13-9861-4da5-881e-618a3bb9d022",
         "Enlighten",
         "DevOps Engineer - 23884",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         "$97,097.00/yr - $130,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "15 hours ago",
         "110 applicants",
         "4265158800",
         "2025-08-24",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4265158800",
         "https://www.linkedin.com/jobs/view/devops-engineer-23884-at-enlighten-4265158800?trk=public_jobs_topcard-title",
         "2025-08-24 05:20:48"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>work_location_type</th>\n",
       "      <th>level</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>posted_time</th>\n",
       "      <th>applicants</th>\n",
       "      <th>job_id</th>\n",
       "      <th>date</th>\n",
       "      <th>parsing_link</th>\n",
       "      <th>job_posting_link</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77378205-0eb0-424a-a80a-7cf03d4148c4</td>\n",
       "      <td>Enlighten</td>\n",
       "      <td>Platform Engineer (Hybrid) - 23372</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$97,097.00/yr - $135,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4240397674</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/platform-en...</td>\n",
       "      <td>2025-08-24 17:36:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a7e217a-cc5c-4694-a8ec-5eb5e682ee5b</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>TeamCenter Developer</td>\n",
       "      <td>Universal City, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$110,000.00/yr - $150,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4278190133</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/teamcenter-...</td>\n",
       "      <td>2025-08-24 17:36:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f9a2ea18-179b-4820-8454-47c2f3af5d01</td>\n",
       "      <td>ClearanceJobs</td>\n",
       "      <td>Tier 3 Level EM Packaging Support Services wit...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Defense and Space Manufacturing</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4287660267</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/tier-3-leve...</td>\n",
       "      <td>2025-08-24 17:36:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fed4c5db-5b12-47cd-9d27-c20aeae7c907</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Biostatistician I</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Research, Analyst, and Information Technology</td>\n",
       "      <td>Internet Publishing</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290466358</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/biostatisti...</td>\n",
       "      <td>2025-08-24 17:35:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6636f3cb-859b-4546-a122-454f63250570</td>\n",
       "      <td>Shrive Technologies</td>\n",
       "      <td>Snowflake Developer with SQL, Python, DBT</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290423063</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/snowflake-d...</td>\n",
       "      <td>2025-08-24 17:35:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>991a78ff-17de-472b-9b7e-55208654bd4f</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>Senior Full Stack Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$92,000.00/yr - $153,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290174501</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-full...</td>\n",
       "      <td>2025-08-24 17:35:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e25a75e4-4132-48c0-8658-e23a5a9cca9e</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>Sr. Security Engineer (Ruby on Rails experienc...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290465339</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-security...</td>\n",
       "      <td>2025-08-24 17:35:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d2da9874-e953-4c98-919c-1a6e84efe453</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Internships in Computer Science or Software En...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Internship</td>\n",
       "      <td>None</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Internet Publishing</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290467346</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/internships...</td>\n",
       "      <td>2025-08-24 17:35:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>614c7411-bc60-43a6-98f7-b35c9ba4502a</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>Sr. Platform Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4290467247</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-platform...</td>\n",
       "      <td>2025-08-24 17:35:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e2763d13-9861-4da5-881e-618a3bb9d022</td>\n",
       "      <td>Enlighten</td>\n",
       "      <td>DevOps Engineer - 23884</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$97,097.00/yr - $130,000.00/yr</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>110 applicants</td>\n",
       "      <td>4265158800</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/devops-engi...</td>\n",
       "      <td>2025-08-24 05:20:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                    company  \\\n",
       "0  77378205-0eb0-424a-a80a-7cf03d4148c4                  Enlighten   \n",
       "1  4a7e217a-cc5c-4694-a8ec-5eb5e682ee5b  Tata Consultancy Services   \n",
       "2  f9a2ea18-179b-4820-8454-47c2f3af5d01              ClearanceJobs   \n",
       "3  fed4c5db-5b12-47cd-9d27-c20aeae7c907                      Lensa   \n",
       "4  6636f3cb-859b-4546-a122-454f63250570        Shrive Technologies   \n",
       "5  991a78ff-17de-472b-9b7e-55208654bd4f              Jobs via Dice   \n",
       "6  e25a75e4-4132-48c0-8658-e23a5a9cca9e                       Aha!   \n",
       "7  d2da9874-e953-4c98-919c-1a6e84efe453                      Lensa   \n",
       "8  614c7411-bc60-43a6-98f7-b35c9ba4502a                       Aha!   \n",
       "9  e2763d13-9861-4da5-881e-618a3bb9d022                  Enlighten   \n",
       "\n",
       "                                               title            location  \\\n",
       "0                 Platform Engineer (Hybrid) - 23372     San Antonio, TX   \n",
       "1                               TeamCenter Developer  Universal City, TX   \n",
       "2  Tier 3 Level EM Packaging Support Services wit...     San Antonio, TX   \n",
       "3                                  Biostatistician I     San Antonio, TX   \n",
       "4          Snowflake Developer with SQL, Python, DBT     San Antonio, TX   \n",
       "5                        Senior Full Stack Developer     San Antonio, TX   \n",
       "6  Sr. Security Engineer (Ruby on Rails experienc...     San Antonio, TX   \n",
       "7  Internships in Computer Science or Software En...     San Antonio, TX   \n",
       "8                              Sr. Platform Engineer     San Antonio, TX   \n",
       "9                            DevOps Engineer - 23884     San Antonio, TX   \n",
       "\n",
       "  work_location_type             level                     salary_range  \\\n",
       "0             Hybrid  Mid-Senior level   $97,097.00/yr - $135,000.00/yr   \n",
       "1            On-site       Entry level  $110,000.00/yr - $150,000.00/yr   \n",
       "2             Hybrid       Entry level                             None   \n",
       "3             Hybrid  Mid-Senior level                             None   \n",
       "4            On-site       Entry level                             None   \n",
       "5             Remote  Mid-Senior level   $92,000.00/yr - $153,000.00/yr   \n",
       "6             Remote  Mid-Senior level                             None   \n",
       "7             Remote        Internship                             None   \n",
       "8             Remote  Mid-Senior level                             None   \n",
       "9             Hybrid  Mid-Senior level   $97,097.00/yr - $130,000.00/yr   \n",
       "\n",
       "  employment_type                                   job_function  \\\n",
       "0       Full-time         Engineering and Information Technology   \n",
       "1       Full-time         Engineering and Information Technology   \n",
       "2       Full-time                         Information Technology   \n",
       "3       Full-time  Research, Analyst, and Information Technology   \n",
       "4       Full-time                         Information Technology   \n",
       "5       Full-time         Engineering and Information Technology   \n",
       "6       Full-time                         Information Technology   \n",
       "7      Internship         Engineering and Information Technology   \n",
       "8       Full-time         Engineering and Information Technology   \n",
       "9       Full-time         Engineering and Information Technology   \n",
       "\n",
       "                        industries   posted_time      applicants      job_id  \\\n",
       "0             Software Development   3 hours ago             N/A  4240397674   \n",
       "1    IT Services and IT Consulting   7 hours ago             N/A  4278190133   \n",
       "2  Defense and Space Manufacturing     1 day ago             N/A  4287660267   \n",
       "3              Internet Publishing   6 hours ago             N/A  4290466358   \n",
       "4    IT Services and IT Consulting  21 hours ago             N/A  4290423063   \n",
       "5             Software Development   5 hours ago             N/A  4290174501   \n",
       "6             Software Development   5 hours ago             N/A  4290465339   \n",
       "7              Internet Publishing   6 hours ago             N/A  4290467346   \n",
       "8             Software Development   5 hours ago             N/A  4290467247   \n",
       "9             Software Development  15 hours ago  110 applicants  4265158800   \n",
       "\n",
       "         date                                       parsing_link  \\\n",
       "0  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "1  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "2  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "3  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "4  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "5  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "6  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "7  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "8  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "9  2025-08-24  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "\n",
       "                                    job_posting_link           created_at  \n",
       "0  https://www.linkedin.com/jobs/view/platform-en...  2025-08-24 17:36:04  \n",
       "1  https://www.linkedin.com/jobs/view/teamcenter-...  2025-08-24 17:36:02  \n",
       "2  https://www.linkedin.com/jobs/view/tier-3-leve...  2025-08-24 17:36:01  \n",
       "3  https://www.linkedin.com/jobs/view/biostatisti...  2025-08-24 17:35:58  \n",
       "4  https://www.linkedin.com/jobs/view/snowflake-d...  2025-08-24 17:35:55  \n",
       "5  https://www.linkedin.com/jobs/view/senior-full...  2025-08-24 17:35:52  \n",
       "6  https://www.linkedin.com/jobs/view/sr-security...  2025-08-24 17:35:49  \n",
       "7  https://www.linkedin.com/jobs/view/internships...  2025-08-24 17:35:47  \n",
       "8  https://www.linkedin.com/jobs/view/sr-platform...  2025-08-24 17:35:44  \n",
       "9  https://www.linkedin.com/jobs/view/devops-engi...  2025-08-24 05:20:48  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 20 most recent jobs with enhanced data structure\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        company,\n",
    "        title,\n",
    "        location,\n",
    "        work_location_type,\n",
    "        level,\n",
    "        salary_range,\n",
    "        employment_type,\n",
    "        job_function,\n",
    "        industries,\n",
    "        posted_time,\n",
    "        applicants,\n",
    "        job_id,\n",
    "        date,\n",
    "        parsing_link,\n",
    "        job_posting_link,\n",
    "        created_at\n",
    "    FROM jobs \n",
    "    ORDER BY created_at DESC \n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "\n",
    "    top_jobs_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(f\"üìä Enhanced Job Data Analysis\")\n",
    "print(f\"Database contains: {len(top_jobs_df)} recent jobs\")\n",
    "print(f\"Columns: {top_jobs_df.shape[1]} (17-column structure)\")\n",
    "print(f\"\\nColumn names: {list(top_jobs_df.columns)}\")\n",
    "top_jobs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f84df63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENHANCED JOB LISTINGS WITH LOCATION INTELLIGENCE\n",
      "================================================================================\n",
      "Showing first 5 of 20 jobs:\n",
      "\n",
      "üìã JOB #1\n",
      "Title: Platform Engineer (Hybrid) - 23372\n",
      "Company: Enlighten\n",
      "üìç Location: San Antonio, TX\n",
      "üîÑ Work Type: Hybrid\n",
      "üéØ Level: Mid-Senior level\n",
      "üí∞ Salary: $97,097.00/yr - $135,000.00/yr\n",
      "üìù Employment: Full-time\n",
      "‚öôÔ∏è Function: Engineering and Information Technology\n",
      "üè≠ Industries: Software Development\n",
      "üë• Applicants: N/A\n",
      "üìÖ Posted: 3 hours ago\n",
      "üîó LinkedIn URL: https://www.linkedin.com/jobs/view/platform-engineer-hybrid-23372-at-enlighten-4240397674?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "üìã JOB #2\n",
      "Title: TeamCenter Developer\n",
      "Company: Tata Consultancy Services\n",
      "üìç Location: Universal City, TX\n",
      "üè¢ Work Type: On-site\n",
      "üéØ Level: Entry level\n",
      "üí∞ Salary: $110,000.00/yr - $150,000.00/yr\n",
      "üìù Employment: Full-time\n",
      "‚öôÔ∏è Function: Engineering and Information Technology\n",
      "üè≠ Industries: IT Services and IT Consulting\n",
      "üë• Applicants: N/A\n",
      "üìÖ Posted: 7 hours ago\n",
      "üîó LinkedIn URL: https://www.linkedin.com/jobs/view/teamcenter-developer-at-tata-consultancy-services-4278190133?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "üìã JOB #3\n",
      "Title: Tier 3 Level EM Packaging Support Services with Security Clearance\n",
      "Company: ClearanceJobs\n",
      "üìç Location: San Antonio, TX\n",
      "üîÑ Work Type: Hybrid\n",
      "üéØ Level: Entry level\n",
      "üìù Employment: Full-time\n",
      "‚öôÔ∏è Function: Information Technology\n",
      "üè≠ Industries: Defense and Space Manufacturing\n",
      "üë• Applicants: N/A\n",
      "üìÖ Posted: 1 day ago\n",
      "üîó LinkedIn URL: https://www.linkedin.com/jobs/view/tier-3-level-em-packaging-support-services-with-security-clearance-at-clearancejobs-4287660267?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "üìã JOB #4\n",
      "Title: Biostatistician I\n",
      "Company: Lensa\n",
      "üìç Location: San Antonio, TX\n",
      "üîÑ Work Type: Hybrid\n",
      "üéØ Level: Mid-Senior level\n",
      "üìù Employment: Full-time\n",
      "‚öôÔ∏è Function: Research, Analyst, and Information Technology\n",
      "üè≠ Industries: Internet Publishing\n",
      "üë• Applicants: N/A\n",
      "üìÖ Posted: 6 hours ago\n",
      "üîó LinkedIn URL: https://www.linkedin.com/jobs/view/biostatistician-i-at-lensa-4290466358?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "üìã JOB #5\n",
      "Title: Snowflake Developer with SQL, Python, DBT\n",
      "Company: Shrive Technologies\n",
      "üìç Location: San Antonio, TX\n",
      "üè¢ Work Type: On-site\n",
      "üéØ Level: Entry level\n",
      "üìù Employment: Full-time\n",
      "‚öôÔ∏è Function: Information Technology\n",
      "üè≠ Industries: IT Services and IT Consulting\n",
      "üë• Applicants: N/A\n",
      "üìÖ Posted: 21 hours ago\n",
      "üîó LinkedIn URL: https://www.linkedin.com/jobs/view/snowflake-developer-with-sql-python-dbt-at-shrive-technologies-4290423063?trk=public_jobs_topcard-title\n",
      "------------------------------------------------------------\n",
      "\n",
      "... and 15 more jobs in the database\n",
      "üí° Tip: Run the statistics cell below for a summary of all jobs\n"
     ]
    }
   ],
   "source": [
    "# Display detailed information for each job with enhanced data (limited output)\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED JOB LISTINGS WITH LOCATION INTELLIGENCE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Limit to first 5 jobs to prevent excessive output\n",
    "    display_limit = min(5, len(top_jobs_df))\n",
    "    print(f\"Showing first {display_limit} of {len(top_jobs_df)} jobs:\\n\")\n",
    "\n",
    "    for idx in range(display_limit):\n",
    "        job = top_jobs_df.iloc[idx]\n",
    "        print(f\"üìã JOB #{idx + 1}\")\n",
    "        print(f\"Title: {job['title']}\")\n",
    "        print(f\"Company: {job['company']}\")\n",
    "\n",
    "        # Enhanced location information\n",
    "        if pd.notna(job[\"location\"]) and job[\"location\"]:\n",
    "            print(f\"üìç Location: {job['location']}\")\n",
    "\n",
    "        if pd.notna(job[\"work_location_type\"]) and job[\"work_location_type\"]:\n",
    "            # Use emoji for work type\n",
    "            work_type_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}\n",
    "            emoji = work_type_emoji.get(job[\"work_location_type\"], \"üìç\")\n",
    "            print(f\"{emoji} Work Type: {job['work_location_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"level\"]) and job[\"level\"]:\n",
    "            print(f\"üéØ Level: {job['level']}\")\n",
    "\n",
    "        if pd.notna(job[\"salary_range\"]) and job[\"salary_range\"]:\n",
    "            print(f\"üí∞ Salary: {job['salary_range']}\")\n",
    "\n",
    "        if pd.notna(job[\"employment_type\"]) and job[\"employment_type\"]:\n",
    "            print(f\"üìù Employment: {job['employment_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_function\"]) and job[\"job_function\"]:\n",
    "            print(f\"‚öôÔ∏è Function: {job['job_function']}\")\n",
    "\n",
    "        if pd.notna(job[\"industries\"]) and job[\"industries\"]:\n",
    "            print(f\"üè≠ Industries: {job['industries']}\")\n",
    "\n",
    "        if pd.notna(job[\"applicants\"]) and job[\"applicants\"]:\n",
    "            print(f\"üë• Applicants: {job['applicants']}\")\n",
    "\n",
    "        if pd.notna(job[\"posted_time\"]) and job[\"posted_time\"]:\n",
    "            print(f\"üìÖ Posted: {job['posted_time']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_posting_link\"]) and job[\"job_posting_link\"]:\n",
    "            print(f\"üîó LinkedIn URL: {job['job_posting_link']}\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    if len(top_jobs_df) > display_limit:\n",
    "        print(f\"\\n... and {len(top_jobs_df) - display_limit} more jobs in the database\")\n",
    "        print(\"üí° Tip: Run the statistics cell below for a summary of all jobs\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs found in database. Run 'make run-parser' first to collect job data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05cc1bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ENHANCED JOB STATISTICS WITH LOCATION INTELLIGENCE\n",
      "============================================================\n",
      "\n",
      "üè¢ Top Companies:\n",
      "  ‚Ä¢ ClearanceJobs: 3 job(s)\n",
      "  ‚Ä¢ Enlighten: 2 job(s)\n",
      "  ‚Ä¢ Lensa: 2 job(s)\n",
      "  ‚Ä¢ Shrive Technologies: 2 job(s)\n",
      "  ‚Ä¢ Aha!: 2 job(s)\n",
      "\n",
      "üìç Top Locations:\n",
      "  ‚Ä¢ San Antonio, TX: 17 job(s)\n",
      "  ‚Ä¢ Universal City, TX: 1 job(s)\n",
      "  ‚Ä¢ San Antonio, Texas Metropolitan Area: 1 job(s)\n",
      "  ‚Ä¢ Texas, United States: 1 job(s)\n",
      "\n",
      "üè† Work Location Types (Location Intelligence):\n",
      "  üîÑ Hybrid: 7 job(s) (35.0%)\n",
      "  üè† Remote: 7 job(s) (35.0%)\n",
      "  üè¢ On-site: 6 job(s) (30.0%)\n",
      "\n",
      "üéØ Experience Levels:\n",
      "  ‚Ä¢ Mid-Senior level: 9 job(s)\n",
      "  ‚Ä¢ Entry level: 6 job(s)\n",
      "  ‚Ä¢ Not Applicable: 3 job(s)\n",
      "  ‚Ä¢ Internship: 1 job(s)\n",
      "  ‚Ä¢ Associate: 1 job(s)\n",
      "\n",
      "üíº Employment Types:\n",
      "  ‚Ä¢ Full-time: 19 job(s)\n",
      "  ‚Ä¢ Internship: 1 job(s)\n",
      "\n",
      "‚öôÔ∏è Top Job Functions:\n",
      "  ‚Ä¢ Engineering and Information Technology: 11 job(s)\n",
      "  ‚Ä¢ Information Technology: 6 job(s)\n",
      "  ‚Ä¢ Research, Analyst, and Information Technology: 2 job(s)\n",
      "  ‚Ä¢ Information Technology, Consulting, and Engineering: 1 job(s)\n",
      "\n",
      "üí∞ Salary Information: 7 out of 20 jobs (35.0%)\n",
      "üë• Applicant Count Available: 20 out of 20 jobs (100.0%)\n",
      "\n",
      "üìà Data Quality Summary:\n",
      "  ‚úÖ All jobs have location intelligence classification\n",
      "  ‚úÖ Enhanced 17-column data structure\n",
      "  ‚úÖ Comprehensive job metadata available\n"
     ]
    }
   ],
   "source": [
    "# Enhanced job statistics with location intelligence\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"üìä ENHANCED JOB STATISTICS WITH LOCATION INTELLIGENCE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Company distribution\n",
    "    company_counts = top_jobs_df[\"company\"].value_counts()\n",
    "    print(f\"\\nüè¢ Top Companies:\")\n",
    "    for company, count in company_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {company}: {count} job(s)\")\n",
    "\n",
    "    # Location distribution (enhanced)\n",
    "    location_counts = top_jobs_df[\"location\"].value_counts()\n",
    "    print(f\"\\nüìç Top Locations:\")\n",
    "    for location, count in location_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {location}: {count} job(s)\")\n",
    "\n",
    "    # NEW: Work location type analysis\n",
    "    if \"work_location_type\" in top_jobs_df.columns:\n",
    "        work_type_counts = top_jobs_df[\"work_location_type\"].value_counts(dropna=True)\n",
    "        print(f\"\\nüè† Work Location Types (Location Intelligence):\")\n",
    "        for work_type, count in work_type_counts.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            percentage = count / len(top_jobs_df) * 100\n",
    "            print(f\"  {emoji} {work_type}: {count} job(s) ({percentage:.1f}%)\")\n",
    "\n",
    "    # Experience level distribution\n",
    "    if \"level\" in top_jobs_df.columns:\n",
    "        level_counts = top_jobs_df[\"level\"].value_counts(dropna=True)\n",
    "        if not level_counts.empty:\n",
    "            print(f\"\\nüéØ Experience Levels:\")\n",
    "            for level, count in level_counts.items():\n",
    "                print(f\"  ‚Ä¢ {level}: {count} job(s)\")\n",
    "\n",
    "    # Employment type distribution\n",
    "    if \"employment_type\" in top_jobs_df.columns:\n",
    "        employment_counts = top_jobs_df[\"employment_type\"].value_counts(dropna=True)\n",
    "        if not employment_counts.empty:\n",
    "            print(f\"\\nüíº Employment Types:\")\n",
    "            for emp_type, count in employment_counts.items():\n",
    "                print(f\"  ‚Ä¢ {emp_type}: {count} job(s)\")\n",
    "\n",
    "    # Job function analysis\n",
    "    if \"job_function\" in top_jobs_df.columns:\n",
    "        function_counts = top_jobs_df[\"job_function\"].value_counts(dropna=True)\n",
    "        if not function_counts.empty:\n",
    "            print(f\"\\n‚öôÔ∏è Top Job Functions:\")\n",
    "            for function, count in function_counts.head().items():\n",
    "                print(f\"  ‚Ä¢ {function}: {count} job(s)\")\n",
    "\n",
    "    # Salary information availability\n",
    "    salary_jobs = top_jobs_df[\"salary_range\"].notna().sum()\n",
    "    print(\n",
    "        f\"\\nüí∞ Salary Information: {salary_jobs} out of {len(top_jobs_df)} jobs ({salary_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Applicant information\n",
    "    applicant_jobs = top_jobs_df[\"applicants\"].notna().sum()\n",
    "    print(\n",
    "        f\"üë• Applicant Count Available: {applicant_jobs} out of {len(top_jobs_df)} jobs ({applicant_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìà Data Quality Summary:\")\n",
    "    print(f\"  ‚úÖ All jobs have location intelligence classification\")\n",
    "    print(f\"  ‚úÖ Enhanced 17-column data structure\")\n",
    "    print(f\"  ‚úÖ Comprehensive job metadata available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7613ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ JOBS WITH SALARY INFORMATION + LOCATION INTELLIGENCE\n",
      "=================================================================\n",
      " 1. Platform Engineer (Hybrid) - 23372 at Enlighten\n",
      "    üí∞ $97,097.00/yr - $135,000.00/yr\n",
      "    üìç San Antonio, TX | üîÑ Hybrid\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      " 2. TeamCenter Developer at Tata Consultancy Services\n",
      "    üí∞ $110,000.00/yr - $150,000.00/yr\n",
      "    üìç Universal City, TX | üè¢ On-site\n",
      "    üéØ Entry level\n",
      "    üìù Full-time\n",
      "\n",
      " 3. Senior Full Stack Developer at Jobs via Dice\n",
      "    üí∞ $92,000.00/yr - $153,000.00/yr\n",
      "    üìç San Antonio, TX | üè† Remote\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      " 4. DevOps Engineer - 23884 at Enlighten\n",
      "    üí∞ $97,097.00/yr - $130,000.00/yr\n",
      "    üìç San Antonio, TX | üîÑ Hybrid\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      " 5. Systems Engineer at Booz Allen Hamilton\n",
      "    üí∞ $52,900.00/yr - $108,000.00/yr\n",
      "    üìç San Antonio, TX | üè† Remote\n",
      "    üéØ Not Applicable\n",
      "    üìù Full-time\n",
      "\n",
      " 6. AI Data Scientist, Manager at Deloitte\n",
      "    üí∞ $103,320.00/yr - $235,170.00/yr\n",
      "    üìç San Antonio, TX | üîÑ Hybrid\n",
      "    üéØ Not Applicable\n",
      "    üìù Full-time\n",
      "\n",
      " 7. Platform Engineer (Hybrid) - 23372 at Mission Technologies, a division of HII\n",
      "    üí∞ $97,097.00/yr - $135,000.00/yr\n",
      "    üìç San Antonio, Texas Metropolitan Area | üè† Remote\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      " 8. Senior ML Engineer at Launch Potato\n",
      "    üí∞ $160,000.00/yr - $220,000.00/yr\n",
      "    üìç San Antonio, TX | üè† Remote\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      " 9. DevOps Engineer - 23859 at Enlighten\n",
      "    üí∞ $119,574.00/yr - $170,000.00/yr\n",
      "    üìç San Antonio, TX | üîÑ Hybrid\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      "10. Lead ML Engineer at Launch Potato\n",
      "    üí∞ $130,000.00/yr - $250,000.00/yr\n",
      "    üìç San Antonio, TX | üè¢ On-site\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      "11. BI Reporting Analyst (Collections) at Piper Companies\n",
      "    üí∞ $80,000.00/yr - $100,000.00/yr\n",
      "    üìç San Antonio, TX | üîÑ Hybrid\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      "12. SAP - SuccessFactors Compensation - Senior - Location OPEN at EY\n",
      "    üí∞ $102,500.00/yr - $187,900.00/yr\n",
      "    üìç San Antonio, TX | üè† Remote\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      "13. Lead Data Scientist at Deloitte\n",
      "    üí∞ $97,600.00/yr - $179,900.00/yr\n",
      "    üìç San Antonio, TX | üè¢ On-site\n",
      "    üéØ Not Applicable\n",
      "    üìù Full-time\n",
      "\n",
      "14. Senior Full Stack Developer at Jobs via Dice\n",
      "    üí∞ $92,000.00/yr - $153,000.00/yr\n",
      "    üìç San Antonio, TX | üè† Remote\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      "15. Decision Science Analyst Senior - Claims Analytics at USAA\n",
      "    üí∞ $114,080.00/yr - $205,340.00/yr\n",
      "    üìç San Antonio, TX | üîÑ Hybrid\n",
      "    üéØ Mid-Senior level\n",
      "    üìù Full-time\n",
      "\n",
      "üìà SALARY ANALYSIS BY WORK TYPE\n",
      "========================================\n",
      "üîÑ Hybrid: 6 jobs with salary info\n",
      "üè¢ On-site: 3 jobs with salary info\n",
      "üè† Remote: 6 jobs with salary info\n"
     ]
    }
   ],
   "source": [
    "# Enhanced salary analysis with location intelligence\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    salary_query = \"\"\"\n",
    "    SELECT title, company, salary_range, location, work_location_type, level, employment_type\n",
    "    FROM jobs \n",
    "    WHERE salary_range IS NOT NULL AND salary_range != ''\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 15\n",
    "    \"\"\"\n",
    "\n",
    "    salary_jobs = pd.read_sql_query(salary_query, conn)\n",
    "\n",
    "if not salary_jobs.empty:\n",
    "    print(\"üí∞ JOBS WITH SALARY INFORMATION + LOCATION INTELLIGENCE\")\n",
    "    print(\"=\" * 65)\n",
    "    for idx, job in salary_jobs.iterrows():\n",
    "        # Work type emoji\n",
    "        work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            job[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "\n",
    "        print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "        print(f\"    üí∞ {job['salary_range']}\")\n",
    "        print(f\"    üìç {job['location']} | {work_emoji} {job['work_location_type']}\")\n",
    "\n",
    "        if job[\"level\"]:\n",
    "            print(f\"    üéØ {job['level']}\")\n",
    "        if job[\"employment_type\"]:\n",
    "            print(f\"    üìù {job['employment_type']}\")\n",
    "        print()\n",
    "\n",
    "    # Salary analysis by work type\n",
    "    if \"work_location_type\" in salary_jobs.columns:\n",
    "        print(\"üìà SALARY ANALYSIS BY WORK TYPE\")\n",
    "        print(\"=\" * 40)\n",
    "        work_type_salary = salary_jobs.groupby(\"work_location_type\").size()\n",
    "        for work_type, count in work_type_salary.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            print(f\"{emoji} {work_type}: {count} jobs with salary info\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs with salary information found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9879302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç LOCATION INTELLIGENCE ANALYSIS\n",
      "==================================================\n",
      "üìä Location + Work Type Distribution:\n",
      "üè¢ San Antonio, TX - On-site: 65 jobs\n",
      "    Companies: VETROMAC, Inherent Technologies, SwRI Structural Geology & Geomechanics... (+10 more)\n",
      "\n",
      "üîÑ San Antonio, TX - Hybrid: 55 jobs\n",
      "    Companies: GovCIO, USAA, Modern Technology Solutions... (+9 more)\n",
      "\n",
      "üè† San Antonio, TX - Remote: 49 jobs\n",
      "    Companies: Raft, Mindrift, Lensa... (+7 more)\n",
      "\n",
      "üè¢ San Antonio, Texas Metropolitan Area - On-site: 11 jobs\n",
      "    Companies: Oteemo Inc., Mission Technologies,  a division of HII\n",
      "\n",
      "üè† San Antonio, Texas Metropolitan Area - Remote: 4 jobs\n",
      "    Companies: Compri Consulting, Mission Technologies,  a division of HII\n",
      "\n",
      "üè¢ Lackland Air Force Base, TX - On-site: 3 jobs\n",
      "    Companies: Knowesis Inc.\n",
      "\n",
      "üè¢ Texas, United States - On-site: 1 jobs\n",
      "    Companies: Frost\n",
      "\n",
      "üè¢ Universal City, TX - On-site: 1 jobs\n",
      "    Companies: Tata Consultancy Services\n",
      "\n",
      "üéØ WORK TYPE INTELLIGENCE SUMMARY:\n",
      "----------------------------------------\n",
      "üè¢ On-site :  81 jobs ( 40.7%)\n",
      "üîÑ Hybrid  :  55 jobs ( 27.6%)\n",
      "üè† Remote  :  53 jobs ( 26.6%)\n",
      "\n",
      "‚ú® Location Intelligence Features:\n",
      "   üéØ Automatic location extraction from job postings\n",
      "   ü§ñ AI-powered work type classification\n",
      "   üìä Enhanced analytics with location data\n",
      "   üíæ 17-column output maintaining legacy compatibility\n"
     ]
    }
   ],
   "source": [
    "# üéØ LOCATION INTELLIGENCE SHOWCASE\n",
    "print(\"üåç LOCATION INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get location intelligence statistics\n",
    "    location_intel_query = \"\"\"\n",
    "    SELECT \n",
    "        location,\n",
    "        work_location_type,\n",
    "        COUNT(*) as job_count,\n",
    "        GROUP_CONCAT(DISTINCT company) as companies\n",
    "    FROM jobs \n",
    "    WHERE location IS NOT NULL\n",
    "    GROUP BY location, work_location_type\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    location_intel_df = pd.read_sql_query(location_intel_query, conn)\n",
    "\n",
    "if not location_intel_df.empty:\n",
    "    print(\"üìä Location + Work Type Distribution:\")\n",
    "    for idx, row in location_intel_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        companies = row[\"companies\"].split(\",\") if row[\"companies\"] else []\n",
    "        company_preview = (\n",
    "            f\" (Companies: {', '.join(companies[:3])}\"\n",
    "            + (\"...\" if len(companies) > 3 else \"\")\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{emoji} {row['location']} - {row['work_location_type']}: {row['job_count']} jobs\"\n",
    "        )\n",
    "        if len(companies) <= 3:\n",
    "            print(f\"    Companies: {', '.join(companies)}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"    Companies: {', '.join(companies[:3])}... (+{len(companies)-3} more)\"\n",
    "            )\n",
    "        print()\n",
    "\n",
    "    # Overall location intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        summary_query = \"\"\"\n",
    "        SELECT \n",
    "            work_location_type,\n",
    "            COUNT(*) as count,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM jobs), 1) as percentage\n",
    "        FROM jobs \n",
    "        WHERE work_location_type IS NOT NULL\n",
    "        GROUP BY work_location_type\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        summary_df = pd.read_sql_query(summary_query, conn)\n",
    "\n",
    "    print(\"üéØ WORK TYPE INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{emoji} {row['work_location_type']:8s}: {row['count']:3d} jobs ({row['percentage']:5.1f}%)\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n‚ú® Location Intelligence Features:\")\n",
    "    print(f\"   üéØ Automatic location extraction from job postings\")\n",
    "    print(f\"   ü§ñ AI-powered work type classification\")\n",
    "    print(f\"   üìä Enhanced analytics with location data\")\n",
    "    print(f\"   üíæ 17-column output maintaining legacy compatibility\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"No location data found. Run 'make run-parser' to collect jobs with location intelligence.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27363121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ CSV EXPORT WITH ENHANCED DATA\n",
      "========================================\n",
      "‚úÖ Jobs exported to: ../data/notebook_analysis_export.csv\n",
      "\n",
      "üìã Export Validation:\n",
      "   Shape: (199, 17)\n",
      "   Columns: 17 (should be 17)\n",
      "\n",
      "‚úÖ Column Validation:\n",
      "   üéØ Perfect! All 17 expected columns present\n",
      "\n",
      "üìä Data Quality Check:\n",
      "   Location data: 189/199 jobs (95.0%)\n",
      "   Work type data: 189/199 jobs (95.0%)\n",
      "   Company data: 199/199 jobs\n",
      "   Title data: 199/199 jobs\n",
      "\n",
      "üéâ SUCCESS: Enhanced LinkedIn parser with location intelligence is working perfectly!\n",
      "   üíæ Database: data/jobs.db\n",
      "   üì§ Export: ../data/notebook_analysis_export.csv\n",
      "   üéØ Use: make run-parser (to collect more jobs)\n",
      "\n",
      "==================================================\n",
      "üöÄ ANALYSIS COMPLETE - Enhanced LinkedIn Parser Ready!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# üìä EXPORT & DATA VALIDATION\n",
    "print(\"üì§ CSV EXPORT WITH ENHANCED DATA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Export current job data to CSV in the main data folder\n",
    "csv_filename = db.export_jobs_to_csv(\"../data/notebook_analysis_export.csv\")\n",
    "print(f\"‚úÖ Jobs exported to: {csv_filename}\")\n",
    "\n",
    "# Validate the exported CSV structure\n",
    "if csv_filename:\n",
    "    import pandas as pd\n",
    "\n",
    "    exported_df = pd.read_csv(csv_filename)\n",
    "\n",
    "    print(f\"\\nüìã Export Validation:\")\n",
    "    print(f\"   Shape: {exported_df.shape}\")\n",
    "    print(f\"   Columns: {exported_df.shape[1]} (should be 17)\")\n",
    "\n",
    "    expected_columns = [\n",
    "        \"id\",\n",
    "        \"company\",\n",
    "        \"title\",\n",
    "        \"location\",\n",
    "        \"work_location_type\",\n",
    "        \"level\",\n",
    "        \"salary_range\",\n",
    "        \"content\",\n",
    "        \"employment_type\",\n",
    "        \"job_function\",\n",
    "        \"industries\",\n",
    "        \"posted_time\",\n",
    "        \"applicants\",\n",
    "        \"job_id\",\n",
    "        \"date\",\n",
    "        \"parsing_link\",\n",
    "        \"job_posting_link\",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n‚úÖ Column Validation:\")\n",
    "    missing_cols = set(expected_columns) - set(exported_df.columns)\n",
    "    extra_cols = set(exported_df.columns) - set(expected_columns)\n",
    "\n",
    "    if not missing_cols and not extra_cols:\n",
    "        print(\"   üéØ Perfect! All 17 expected columns present\")\n",
    "    else:\n",
    "        if missing_cols:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing columns: {missing_cols}\")\n",
    "        if extra_cols:\n",
    "            print(f\"   ‚ûï Extra columns: {extra_cols}\")\n",
    "\n",
    "    print(f\"\\nüìä Data Quality Check:\")\n",
    "    print(\n",
    "        f\"   Location data: {exported_df['location'].notna().sum()}/{len(exported_df)} jobs ({exported_df['location'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Work type data: {exported_df['work_location_type'].notna().sum()}/{len(exported_df)} jobs ({exported_df['work_location_type'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company data: {exported_df['company'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Title data: {exported_df['title'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\nüéâ SUCCESS: Enhanced LinkedIn parser with location intelligence is working perfectly!\"\n",
    "    )\n",
    "    print(f\"   üíæ Database: data/jobs.db\")\n",
    "    print(f\"   üì§ Export: {csv_filename}\")\n",
    "    print(f\"   üéØ Use: make run-parser (to collect more jobs)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"üöÄ ANALYSIS COMPLETE - Enhanced LinkedIn Parser Ready!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1107ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ RUNNING PARSER + DATA CLEANER PIPELINE\n",
      "==================================================\n",
      "üì• Step 1: Running LinkedIn Parser...\n",
      "Command: make run-parser\n",
      "‚úÖ Parser completed successfully!\n",
      "   ‚úÖ Successfully parsed 9 jobs\n",
      "   üìä Jobs exported to: data/jobs_export.csv\n",
      "‚úÖ Parser completed successfully!\n",
      "   ‚úÖ Successfully parsed 9 jobs\n",
      "   üìä Jobs exported to: data/jobs_export.csv\n",
      "\n",
      "üßπ Step 2: Running Data Cleaner...\n",
      "Command: python -m genai_job_finder.data_cleaner.run_graph\n",
      "\n",
      "üßπ Step 2: Running Data Cleaner...\n",
      "Command: python -m genai_job_finder.data_cleaner.run_graph\n",
      "‚úÖ Data cleaner completed successfully!\n",
      "\n",
      "üìä PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "üéØ Pipeline Complete!\n",
      "   üì• Fresh job data collected\n",
      "   üßπ AI-powered data cleaning applied\n",
      "   üíæ Results available in cleaned_jobs table\n",
      "   üìä Ready for enhanced analysis below ‚¨áÔ∏è\n",
      "‚úÖ Data cleaner completed successfully!\n",
      "\n",
      "üìä PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "üéØ Pipeline Complete!\n",
      "   üì• Fresh job data collected\n",
      "   üßπ AI-powered data cleaning applied\n",
      "   üíæ Results available in cleaned_jobs table\n",
      "   üìä Ready for enhanced analysis below ‚¨áÔ∏è\n"
     ]
    }
   ],
   "source": [
    "# üîÑ RUN PARSER + CLEANER BACK TO BACK\n",
    "print(\"üöÄ RUNNING PARSER + DATA CLEANER PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Step 1: Run the parser to collect fresh job data\n",
    "print(\"üì• Step 1: Running LinkedIn Parser...\")\n",
    "print(\"Command: make run-parser\")\n",
    "try:\n",
    "    parser_result = subprocess.run(\n",
    "        [\"make\", \"run-parser\"],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300,  # 5 minute timeout\n",
    "    )\n",
    "\n",
    "    if parser_result.returncode == 0:\n",
    "        print(\"‚úÖ Parser completed successfully!\")\n",
    "        # Extract some stats from output if available\n",
    "        lines = parser_result.stdout.split(\"\\n\")\n",
    "        for line in lines[-10:]:  # Show last 10 lines\n",
    "            if line.strip() and (\n",
    "                \"saved\" in line.lower()\n",
    "                or \"exported\" in line.lower()\n",
    "                or \"jobs\" in line.lower()\n",
    "            ):\n",
    "                print(f\"   {line.strip()}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Parser completed with warnings:\")\n",
    "        print(f\"   Return code: {parser_result.returncode}\")\n",
    "        if parser_result.stderr:\n",
    "            print(f\"   Error: {parser_result.stderr[-500:]}\")  # Last 500 chars\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Parser timeout after 5 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parser error: {e}\")\n",
    "\n",
    "# Small delay between operations\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 2: Run the data cleaner on the fresh data\n",
    "print(f\"\\nüßπ Step 2: Running Data Cleaner...\")\n",
    "print(\"Command: python -m genai_job_finder.data_cleaner.run_graph\")\n",
    "try:\n",
    "    cleaner_result = subprocess.run(\n",
    "        [\n",
    "            \"/home/alireza/.cache/pypoetry/virtualenvs/genai-job-finder-Y_k-9c-5-py3.12/bin/python\",\n",
    "            \"-m\",\n",
    "            \"genai_job_finder.data_cleaner.run_graph\",\n",
    "            \"--db-path\",\n",
    "            \"data/jobs.db\",\n",
    "            \"--verbose\",\n",
    "        ],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=600,  # 10 minute timeout for AI processing\n",
    "    )\n",
    "\n",
    "    if cleaner_result.returncode == 0:\n",
    "        print(\"‚úÖ Data cleaner completed successfully!\")\n",
    "        # Extract processing summary\n",
    "        lines = cleaner_result.stdout.split(\"\\n\")\n",
    "        in_summary = False\n",
    "        for line in lines:\n",
    "            if \"PROCESSING SUMMARY\" in line:\n",
    "                in_summary = True\n",
    "                print(f\"\\nüìä {line}\")\n",
    "            elif in_summary and (\"=\" in line or line.strip() == \"\"):\n",
    "                if \"=\" in line:\n",
    "                    print(line)\n",
    "                    in_summary = False\n",
    "            elif in_summary:\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Data cleaner completed with issues:\")\n",
    "        print(f\"   Return code: {cleaner_result.returncode}\")\n",
    "        if cleaner_result.stderr:\n",
    "            print(f\"   Error: {cleaner_result.stderr[-500:]}\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Data cleaner timeout after 10 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data cleaner error: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ Pipeline Complete!\")\n",
    "print(\"   üì• Fresh job data collected\")\n",
    "print(\"   üßπ AI-powered data cleaning applied\")\n",
    "print(\"   üíæ Results available in cleaned_jobs table\")\n",
    "print(\"   üìä Ready for enhanced analysis below ‚¨áÔ∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc70e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® ANALYZING AI-CLEANED JOB DATA\n",
      "==================================================\n",
      "‚úÖ Cleaned jobs table found!\n",
      "üìä Total cleaned jobs: 208\n",
      "üèóÔ∏è Table structure: 33 columns\n",
      "\n",
      "üìã SAMPLE CLEANED JOBS:\n",
      "------------------------------------------------------------\n",
      " 1. Biostatistician I at Lensa\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 75 years ‚Üí Director / Executive\n",
      "    üìù üîÑ Hybrid | Internship\n",
      "\n",
      " 2. Sr. Security Engineer (Ruby on Rails experience required) at Aha!\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 0 years ‚Üí Intern\n",
      "    üí∞ Salary: $110,000 - $190,000 (Mid: $150,000)\n",
      "    üìù üè† Remote | Internship\n",
      "\n",
      " 3. SAP - SuccessFactors Compensation - Senior - Location OPEN at EY\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 3 years ‚Üí Early-career / Associate\n",
      "    üí∞ Salary: $102,500 - $187,900 (Mid: $145,200)\n",
      "    üìù üîÑ Hybrid | Contract\n",
      "\n",
      " 4. Senior Data Scientist at Compri Consulting\n",
      "    üìç None\n",
      "    üéØ Experience: 8 years ‚Üí Senior\n",
      "    üí∞ Salary: $140,000 - $150,000 (Mid: $145,000)\n",
      "    üìù üè† Remote | Contract\n",
      "\n",
      " 5. Platform Engineer (Hybrid) - 22394 at Enlighten\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 9 years ‚Üí Staff / Principal\n",
      "    üí∞ Salary: $119,574 - $170,000 (Mid: $144,787)\n",
      "    üìù üîÑ Hybrid | Internship\n",
      "\n",
      " 6. Principal AI Engineer at CPS Energy\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 0 years ‚Üí Intern\n",
      "    üìù üè¢ On-site | Internship\n",
      "\n",
      " 7. Tier 3 Level EM Packaging Support Services with Security Clearance at ClearanceJobs\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 5 years ‚Üí Mid\n",
      "    üìù üîÑ Hybrid | Contract\n",
      "\n",
      " 8. AI/Data Engineer ‚Äì Software Supply Chain Security at Oteemo Inc.\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 10 years ‚Üí Staff / Principal\n",
      "    üìù üè† Remote | Contract\n",
      "\n",
      " 9. AI & Machine Learning Engineer - Manager - Consulting - Open Location at EY\n",
      "    üìç San Antonio, TX\n",
      "    üéØ Experience: 4 years ‚Üí Mid\n",
      "    üí∞ Salary: $124,300 - $227,900 (Mid: $176,100)\n",
      "    üìù üîÑ Hybrid | Full-time\n",
      "\n",
      "10. Data Scientist II at Knowesis Inc.\n",
      "    üìç Lackland Air Force Base, TX\n",
      "    üéØ Experience: 10 years ‚Üí Staff / Principal\n",
      "    üìù üè¢ On-site | Contract\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "min_years_experience",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experience_level_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "work_location_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "min_salary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_salary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mid_salary",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "57e99b1a-0941-4665-be18-7c25bff35c88",
       "rows": [
        [
         "0",
         "fed4c5db-5b12-47cd-9d27-c20aeae7c907",
         "Lensa",
         "Biostatistician I",
         "San Antonio, TX",
         "75",
         "Director / Executive",
         "Hybrid",
         "Internship",
         null,
         null,
         null
        ],
        [
         "1",
         "fd74d3db-df43-4621-a7b6-170e3e3377ae",
         "Aha!",
         "Sr. Security Engineer (Ruby on Rails experience required)",
         "San Antonio, TX",
         "0",
         "Intern",
         "Remote",
         "Internship",
         "110000.0",
         "190000.0",
         "150000.0"
        ],
        [
         "2",
         "fd538431-f4ee-4571-926d-8c0e85884d9c",
         "EY",
         "SAP - SuccessFactors Compensation - Senior - Location OPEN",
         "San Antonio, TX",
         "3",
         "Early-career / Associate",
         "Hybrid",
         "Contract",
         "102500.0",
         "187900.0",
         "145200.0"
        ],
        [
         "3",
         "fd40ad0b-7cea-4894-8077-a436a8161808",
         "Compri Consulting",
         "Senior Data Scientist",
         null,
         "8",
         "Senior",
         "Remote",
         "Contract",
         "140000.0",
         "150000.0",
         "145000.0"
        ],
        [
         "4",
         "fcad93bd-df3f-4293-b905-160293294c10",
         "Enlighten",
         "Platform Engineer (Hybrid) - 22394",
         "San Antonio, TX",
         "9",
         "Staff / Principal",
         "Hybrid",
         "Internship",
         "119574.0",
         "170000.0",
         "144787.0"
        ],
        [
         "5",
         "fac83792-4c20-4206-bdc3-37eb1fafa69d",
         "CPS Energy",
         "Principal AI Engineer",
         "San Antonio, TX",
         "0",
         "Intern",
         "On-site",
         "Internship",
         null,
         null,
         null
        ],
        [
         "6",
         "f9a2ea18-179b-4820-8454-47c2f3af5d01",
         "ClearanceJobs",
         "Tier 3 Level EM Packaging Support Services with Security Clearance",
         "San Antonio, TX",
         "5",
         "Mid",
         "Hybrid",
         "Contract",
         null,
         null,
         null
        ],
        [
         "7",
         "f96ab951-0a17-4c8b-ab0f-9a73aeccb58d",
         "Oteemo Inc.",
         "AI/Data Engineer ‚Äì Software Supply Chain Security",
         "San Antonio, TX",
         "10",
         "Staff / Principal",
         "Remote",
         "Contract",
         null,
         null,
         null
        ],
        [
         "8",
         "f71d1f48-f76f-4be5-a53d-ffbcbaf12446",
         "EY",
         "AI & Machine Learning Engineer - Manager - Consulting - Open Location",
         "San Antonio, TX",
         "4",
         "Mid",
         "Hybrid",
         "Full-time",
         "124300.0",
         "227900.0",
         "176100.0"
        ],
        [
         "9",
         "f5868598-dd34-44bf-a5b0-51cd81dd1221",
         "Knowesis Inc.",
         "Data Scientist II",
         "Lackland Air Force Base, TX",
         "10",
         "Staff / Principal",
         "On-site",
         "Contract",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>min_years_experience</th>\n",
       "      <th>experience_level_label</th>\n",
       "      <th>work_location_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>mid_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fed4c5db-5b12-47cd-9d27-c20aeae7c907</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Biostatistician I</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>75</td>\n",
       "      <td>Director / Executive</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd74d3db-df43-4621-a7b6-170e3e3377ae</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>Sr. Security Engineer (Ruby on Rails experienc...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>0</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Internship</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd538431-f4ee-4571-926d-8c0e85884d9c</td>\n",
       "      <td>EY</td>\n",
       "      <td>SAP - SuccessFactors Compensation - Senior - L...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>3</td>\n",
       "      <td>Early-career / Associate</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Contract</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>187900.0</td>\n",
       "      <td>145200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fd40ad0b-7cea-4894-8077-a436a8161808</td>\n",
       "      <td>Compri Consulting</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Contract</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>145000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fcad93bd-df3f-4293-b905-160293294c10</td>\n",
       "      <td>Enlighten</td>\n",
       "      <td>Platform Engineer (Hybrid) - 22394</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>9</td>\n",
       "      <td>Staff / Principal</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Internship</td>\n",
       "      <td>119574.0</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>144787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fac83792-4c20-4206-bdc3-37eb1fafa69d</td>\n",
       "      <td>CPS Energy</td>\n",
       "      <td>Principal AI Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>0</td>\n",
       "      <td>Intern</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f9a2ea18-179b-4820-8454-47c2f3af5d01</td>\n",
       "      <td>ClearanceJobs</td>\n",
       "      <td>Tier 3 Level EM Packaging Support Services wit...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>5</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f96ab951-0a17-4c8b-ab0f-9a73aeccb58d</td>\n",
       "      <td>Oteemo Inc.</td>\n",
       "      <td>AI/Data Engineer ‚Äì Software Supply Chain Security</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>10</td>\n",
       "      <td>Staff / Principal</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f71d1f48-f76f-4be5-a53d-ffbcbaf12446</td>\n",
       "      <td>EY</td>\n",
       "      <td>AI &amp; Machine Learning Engineer - Manager - Con...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>4</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>124300.0</td>\n",
       "      <td>227900.0</td>\n",
       "      <td>176100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f5868598-dd34-44bf-a5b0-51cd81dd1221</td>\n",
       "      <td>Knowesis Inc.</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Lackland Air Force Base, TX</td>\n",
       "      <td>10</td>\n",
       "      <td>Staff / Principal</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id            company  \\\n",
       "0  fed4c5db-5b12-47cd-9d27-c20aeae7c907              Lensa   \n",
       "1  fd74d3db-df43-4621-a7b6-170e3e3377ae               Aha!   \n",
       "2  fd538431-f4ee-4571-926d-8c0e85884d9c                 EY   \n",
       "3  fd40ad0b-7cea-4894-8077-a436a8161808  Compri Consulting   \n",
       "4  fcad93bd-df3f-4293-b905-160293294c10          Enlighten   \n",
       "5  fac83792-4c20-4206-bdc3-37eb1fafa69d         CPS Energy   \n",
       "6  f9a2ea18-179b-4820-8454-47c2f3af5d01      ClearanceJobs   \n",
       "7  f96ab951-0a17-4c8b-ab0f-9a73aeccb58d        Oteemo Inc.   \n",
       "8  f71d1f48-f76f-4be5-a53d-ffbcbaf12446                 EY   \n",
       "9  f5868598-dd34-44bf-a5b0-51cd81dd1221      Knowesis Inc.   \n",
       "\n",
       "                                               title  \\\n",
       "0                                  Biostatistician I   \n",
       "1  Sr. Security Engineer (Ruby on Rails experienc...   \n",
       "2  SAP - SuccessFactors Compensation - Senior - L...   \n",
       "3                              Senior Data Scientist   \n",
       "4                 Platform Engineer (Hybrid) - 22394   \n",
       "5                              Principal AI Engineer   \n",
       "6  Tier 3 Level EM Packaging Support Services wit...   \n",
       "7  AI/Data Engineer ‚Äì Software Supply Chain Security   \n",
       "8  AI & Machine Learning Engineer - Manager - Con...   \n",
       "9                                  Data Scientist II   \n",
       "\n",
       "                      location  min_years_experience  \\\n",
       "0              San Antonio, TX                    75   \n",
       "1              San Antonio, TX                     0   \n",
       "2              San Antonio, TX                     3   \n",
       "3                         None                     8   \n",
       "4              San Antonio, TX                     9   \n",
       "5              San Antonio, TX                     0   \n",
       "6              San Antonio, TX                     5   \n",
       "7              San Antonio, TX                    10   \n",
       "8              San Antonio, TX                     4   \n",
       "9  Lackland Air Force Base, TX                    10   \n",
       "\n",
       "     experience_level_label work_location_type employment_type  min_salary  \\\n",
       "0      Director / Executive             Hybrid      Internship         NaN   \n",
       "1                    Intern             Remote      Internship    110000.0   \n",
       "2  Early-career / Associate             Hybrid        Contract    102500.0   \n",
       "3                    Senior             Remote        Contract    140000.0   \n",
       "4         Staff / Principal             Hybrid      Internship    119574.0   \n",
       "5                    Intern            On-site      Internship         NaN   \n",
       "6                       Mid             Hybrid        Contract         NaN   \n",
       "7         Staff / Principal             Remote        Contract         NaN   \n",
       "8                       Mid             Hybrid       Full-time    124300.0   \n",
       "9         Staff / Principal            On-site        Contract         NaN   \n",
       "\n",
       "   max_salary  mid_salary  \n",
       "0         NaN         NaN  \n",
       "1    190000.0    150000.0  \n",
       "2    187900.0    145200.0  \n",
       "3    150000.0    145000.0  \n",
       "4    170000.0    144787.0  \n",
       "5         NaN         NaN  \n",
       "6         NaN         NaN  \n",
       "7         NaN         NaN  \n",
       "8    227900.0    176100.0  \n",
       "9         NaN         NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üßπ CLEANED JOBS TABLE ANALYSIS\n",
    "print(\"‚ú® ANALYZING AI-CLEANED JOB DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if cleaned_jobs table exists\n",
    "    tables_query = (\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\"\n",
    "    )\n",
    "    table_exists = pd.read_sql_query(tables_query, conn)\n",
    "\n",
    "    if table_exists.empty:\n",
    "        print(\"‚ùå No cleaned_jobs table found.\")\n",
    "        print(\"üí° Run the cell above to execute the parser + cleaner pipeline first.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Cleaned jobs table found!\")\n",
    "\n",
    "        # Get basic stats\n",
    "        total_cleaned = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "        print(f\"üìä Total cleaned jobs: {total_cleaned}\")\n",
    "\n",
    "        if total_cleaned > 0:\n",
    "            # Get the schema of cleaned table\n",
    "            schema_query = \"PRAGMA table_info(cleaned_jobs)\"\n",
    "            schema_df = pd.read_sql_query(schema_query, conn)\n",
    "            print(f\"üèóÔ∏è Table structure: {len(schema_df)} columns\")\n",
    "\n",
    "            # Sample of cleaned data\n",
    "            sample_query = \"\"\"\n",
    "            SELECT \n",
    "                id, company, title, location, \n",
    "                min_years_experience, experience_level_label,\n",
    "                work_location_type, employment_type,\n",
    "                min_salary, max_salary, mid_salary\n",
    "            FROM cleaned_jobs \n",
    "            ORDER BY id DESC \n",
    "            LIMIT 10\n",
    "            \"\"\"\n",
    "\n",
    "            cleaned_sample = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "            print(f\"\\nüìã SAMPLE CLEANED JOBS:\")\n",
    "            print(\"-\" * 60)\n",
    "            for idx, job in cleaned_sample.iterrows():\n",
    "                print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "                print(f\"    üìç {job['location']}\")\n",
    "\n",
    "                # Experience info\n",
    "                if pd.notna(job[\"min_years_experience\"]) and pd.notna(\n",
    "                    job[\"experience_level_label\"]\n",
    "                ):\n",
    "                    print(\n",
    "                        f\"    üéØ Experience: {job['min_years_experience']} years ‚Üí {job['experience_level_label']}\"\n",
    "                    )\n",
    "\n",
    "                # Salary info\n",
    "                if pd.notna(job[\"min_salary\"]) and pd.notna(job[\"max_salary\"]):\n",
    "                    print(\n",
    "                        f\"    üí∞ Salary: ${job['min_salary']:,.0f} - ${job['max_salary']:,.0f} (Mid: ${job['mid_salary']:,.0f})\"\n",
    "                    )\n",
    "\n",
    "                # Work details\n",
    "                work_details = []\n",
    "                if pd.notna(job[\"work_location_type\"]):\n",
    "                    work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                        job[\"work_location_type\"], \"üìç\"\n",
    "                    )\n",
    "                    work_details.append(f\"{work_emoji} {job['work_location_type']}\")\n",
    "                if pd.notna(job[\"employment_type\"]):\n",
    "                    work_details.append(job[\"employment_type\"])\n",
    "                if work_details:\n",
    "                    print(f\"    üìù {' | '.join(work_details)}\")\n",
    "                print()\n",
    "\n",
    "cleaned_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ ORIGINAL vs AI-CLEANED DATA COMPARISON\n",
      "============================================================\n",
      "üìä DATA TRANSFORMATION PIPELINE RESULTS:\n",
      "----------------------------------------\n",
      "üîç DETAILED TRANSFORMATION EXAMPLES:\n",
      "(Showing how AI enhanced the original data)\n",
      "\n",
      "üìã JOB 1: Biostatistician I at Lensa\n",
      "   üìç Location: San Antonio, TX\n",
      "\n",
      "   üéØ EXPERIENCE ANALYSIS:\n",
      "      Original: 'Mid-Senior level'\n",
      "      AI Result: 75 years ‚Üí Director / Executive\n",
      "\n",
      "   üí∞ SALARY INTELLIGENCE:\n",
      "      Original: 'Not specified'\n",
      "      AI Result: Not extracted\n",
      "\n",
      "   üìù EMPLOYMENT TYPE:\n",
      "      Original: 'Full-time'\n",
      "      AI Result: Internship | Work Type: Hybrid\n",
      "\n",
      "--------------------------------------------------\n",
      "üìã JOB 2: Sr. Security Engineer (Ruby on Rails experience required) at Aha!\n",
      "   üìç Location: San Antonio, TX\n",
      "\n",
      "   üéØ EXPERIENCE ANALYSIS:\n",
      "      Original: 'Mid-Senior level'\n",
      "      AI Result: 0 years ‚Üí Intern\n",
      "\n",
      "   üí∞ SALARY INTELLIGENCE:\n",
      "      Original: 'Not specified'\n",
      "      AI Result: 110000.0 - 190000.0 (Mid: 150000.0)\n",
      "\n",
      "   üìù EMPLOYMENT TYPE:\n",
      "      Original: 'Full-time'\n",
      "      AI Result: Internship | Work Type: Remote\n",
      "\n",
      "--------------------------------------------------\n",
      "üìã JOB 3: SAP - SuccessFactors Compensation - Senior - Location OPEN at EY\n",
      "   üìç Location: San Antonio, TX\n",
      "\n",
      "   üéØ EXPERIENCE ANALYSIS:\n",
      "      Original: 'Mid-Senior level'\n",
      "      AI Result: 3 years ‚Üí Early-career / Associate\n",
      "\n",
      "   üí∞ SALARY INTELLIGENCE:\n",
      "      Original: '$102,500.00/yr - $187,900.00/yr'\n",
      "      AI Result: 102500.0 - 187900.0 (Mid: 145200.0)\n",
      "\n",
      "   üìù EMPLOYMENT TYPE:\n",
      "      Original: 'Full-time'\n",
      "      AI Result: Contract | Work Type: Hybrid\n",
      "\n",
      "--------------------------------------------------\n",
      "üìã JOB 4: Senior Data Scientist at Compri Consulting\n",
      "   üìç Location: None\n",
      "\n",
      "   üéØ EXPERIENCE ANALYSIS:\n",
      "      Original: 'Mid-Senior level'\n",
      "      AI Result: 8 years ‚Üí Senior\n",
      "\n",
      "   üí∞ SALARY INTELLIGENCE:\n",
      "      Original: '$140,000.00/yr - $150,000.00/yr'\n",
      "      AI Result: 140000.0 - 150000.0 (Mid: 145000.0)\n",
      "\n",
      "   üìù EMPLOYMENT TYPE:\n",
      "      Original: 'Full-time'\n",
      "      AI Result: Contract | Work Type: Remote\n",
      "\n",
      "--------------------------------------------------\n",
      "üìã JOB 5: Platform Engineer (Hybrid) - 22394 at Enlighten\n",
      "   üìç Location: San Antonio, TX\n",
      "\n",
      "   üéØ EXPERIENCE ANALYSIS:\n",
      "      Original: 'Mid-Senior level'\n",
      "      AI Result: 9 years ‚Üí Staff / Principal\n",
      "\n",
      "   üí∞ SALARY INTELLIGENCE:\n",
      "      Original: '$119,574.00/yr - $170,000.00/yr'\n",
      "      AI Result: 119574.0 - 170000.0 (Mid: 144787.0)\n",
      "\n",
      "   üìù EMPLOYMENT TYPE:\n",
      "      Original: 'Full-time'\n",
      "      AI Result: Internship | Work Type: Hybrid\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà STATISTICAL IMPROVEMENTS:\n",
      "------------------------------\n",
      "üéØ Experience Data:\n",
      "   Before: 208/208 jobs (100.0%)\n",
      "   After:  208/208 jobs (100.0%)\n",
      "   Gain:   +0 jobs (+0.0%)\n",
      "\n",
      "üí∞ Salary Data:\n",
      "   Before: 79/208 jobs (38.0%)\n",
      "   After:  80/208 jobs (38.5%)\n",
      "   Gain:   +1 jobs (+0.5%)\n",
      "\n",
      "üè† Work Location Type (New):\n",
      "   Before: 0/208 jobs (0.0%) - Not available in original\n",
      "   After:  208/208 jobs (100.0%)\n",
      "   Gain:   +208 jobs (NEW FEATURE)\n",
      "\n",
      "‚ú® AI ENHANCEMENT SUMMARY:\n",
      "   üß† LLM-powered intelligent extraction\n",
      "   üéØ Experience level standardization (7-tier system)\n",
      "   üí∞ Salary range parsing and normalization\n",
      "   üè† Work location type classification (Remote/Hybrid/On-site)\n",
      "   üìù Employment type validation and correction\n",
      "   üîÑ Keyword fallbacks for robustness\n",
      "   üìä Comprehensive data quality improvements\n"
     ]
    }
   ],
   "source": [
    "# üìäüîÑ BEFORE vs AFTER: Data Transformation Analysis\n",
    "print(\"üîÑ ORIGINAL vs AI-CLEANED DATA COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if both tables exist\n",
    "    original_exists = (\n",
    "        pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\"count\"]\n",
    "        > 0\n",
    "    )\n",
    "    cleaned_exists = (\n",
    "        len(\n",
    "            pd.read_sql_query(\n",
    "                \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\",\n",
    "                conn,\n",
    "            )\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "\n",
    "    if not cleaned_exists:\n",
    "        print(\"‚ùå Need cleaned data for comparison\")\n",
    "        print(\"üí° Run: make run-pipeline\")\n",
    "    elif not original_exists:\n",
    "        print(\"‚ùå No original data found\")\n",
    "    else:\n",
    "        cleaned_count = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "\n",
    "        if cleaned_count == 0:\n",
    "            print(\"üì≠ Cleaned table is empty\")\n",
    "            print(\"üí° Run: make run-cleaner\")\n",
    "        else:\n",
    "            print(\"üìä DATA TRANSFORMATION PIPELINE RESULTS:\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            # Side-by-side comparison of same jobs\n",
    "            comparison_query = \"\"\"\n",
    "            SELECT \n",
    "                o.id,\n",
    "                o.company,\n",
    "                o.title,\n",
    "                o.location,\n",
    "                o.level as original_level,\n",
    "                o.salary_range as original_salary,\n",
    "                o.employment_type as original_employment,\n",
    "                c.min_years_experience as ai_years,\n",
    "                c.experience_level_label as ai_level,\n",
    "                CASE \n",
    "                    WHEN c.min_salary IS NOT NULL THEN c.min_salary || ' - ' || c.max_salary || ' (Mid: ' || c.mid_salary || ')'\n",
    "                    ELSE 'Not extracted'\n",
    "                END as ai_salary,\n",
    "                c.work_location_type as ai_work_type,\n",
    "                c.employment_type as ai_employment\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            ORDER BY o.id DESC\n",
    "            LIMIT 5\n",
    "            \"\"\"\n",
    "\n",
    "            comparison_df = pd.read_sql_query(comparison_query, conn)\n",
    "\n",
    "            print(\"üîç DETAILED TRANSFORMATION EXAMPLES:\")\n",
    "            print(\"(Showing how AI enhanced the original data)\")\n",
    "            print()\n",
    "\n",
    "            for idx, row in comparison_df.iterrows():\n",
    "                print(f\"üìã JOB {idx+1}: {row['title']} at {row['company']}\")\n",
    "                print(f\"   üìç Location: {row['location']}\")\n",
    "                print()\n",
    "\n",
    "                # Experience comparison\n",
    "                print(\"   üéØ EXPERIENCE ANALYSIS:\")\n",
    "                print(f\"      Original: '{row['original_level'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_years']} years ‚Üí {row['ai_level']}\")\n",
    "                print()\n",
    "\n",
    "                # Salary comparison\n",
    "                print(\"   üí∞ SALARY INTELLIGENCE:\")\n",
    "                print(f\"      Original: '{row['original_salary'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_salary']}\")\n",
    "                print()\n",
    "\n",
    "                # Employment type comparison\n",
    "                print(\"   üìù EMPLOYMENT TYPE:\")\n",
    "                print(\n",
    "                    f\"      Original: '{row['original_employment'] or 'Not specified'}'\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"      AI Result: {row['ai_employment']} | Work Type: {row['ai_work_type']}\"\n",
    "                )\n",
    "                print()\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "            # Statistical improvements\n",
    "            print(\"üìà STATISTICAL IMPROVEMENTS:\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Count improvements\n",
    "            improvements_query = \"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_jobs,\n",
    "                -- Experience data\n",
    "                COUNT(CASE WHEN o.level IS NOT NULL AND o.level != '' THEN 1 END) as original_exp_data,\n",
    "                COUNT(CASE WHEN c.experience_level_label IS NOT NULL THEN 1 END) as ai_exp_data,\n",
    "                -- Salary data  \n",
    "                COUNT(CASE WHEN o.salary_range IS NOT NULL AND o.salary_range != '' THEN 1 END) as original_salary_data,\n",
    "                COUNT(CASE WHEN c.min_salary IS NOT NULL THEN 1 END) as ai_salary_data,\n",
    "                -- Work location data\n",
    "                COUNT(CASE WHEN c.work_location_type IS NOT NULL THEN 1 END) as ai_work_type_data\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "            improvements_stats = pd.read_sql_query(improvements_query, conn).iloc[0]\n",
    "            total = improvements_stats[\"total_jobs\"]\n",
    "\n",
    "            print(f\"üéØ Experience Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_exp_data']}/{total} jobs ({improvements_stats['original_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_exp_data']}/{total} jobs ({improvements_stats['ai_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            exp_improvement = (\n",
    "                improvements_stats[\"ai_exp_data\"]\n",
    "                - improvements_stats[\"original_exp_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{exp_improvement} jobs (+{exp_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üí∞ Salary Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_salary_data']}/{total} jobs ({improvements_stats['original_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_salary_data']}/{total} jobs ({improvements_stats['ai_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            salary_improvement = (\n",
    "                improvements_stats[\"ai_salary_data\"]\n",
    "                - improvements_stats[\"original_salary_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{salary_improvement} jobs (+{salary_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üè† Work Location Type (New):\")\n",
    "            print(f\"   Before: 0/{total} jobs (0.0%) - Not available in original\")\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_work_type_data']}/{total} jobs ({improvements_stats['ai_work_type_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{improvements_stats['ai_work_type_data']} jobs (NEW FEATURE)\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-job-finder-Y_k-9c-5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
