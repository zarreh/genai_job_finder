{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be7e499",
   "metadata": {},
   "source": [
    "# Enhanced LinkedIn Job Database Analysis\n",
    "\n",
    "This notebook analyzes the LinkedIn job database with the new enhanced parser that includes:\n",
    "\n",
    "- **20-column output structure** (with integrated company information)\n",
    "- **Company intelligence** with automatic extraction of company size, followers, and industry\n",
    "- **Location intelligence** with automatic extraction\n",
    "- **Work type classification** (Remote/Hybrid/On-site)\n",
    "- **Enhanced data model** with comprehensive job and company information\n",
    "\n",
    "Run `make run-parser` first to collect fresh job data with location and company intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "741025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = (\n",
    "    Path(__file__).parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    ")\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from genai_job_finder.linkedin_parser.database import DatabaseManager\n",
    "from genai_job_finder.linkedin_parser.models import Job, JobRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f1daf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/alireza/projects/genai_job_finder')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef5a736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /home/alireza/projects/genai_job_finder/data/jobs.db\n",
      "Database exists: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db_path = project_root / \"data\" / \"jobs.db\"\n",
    "# db_path = project_root / \"test_jobs.db\"\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")\n",
    "\n",
    "# Create database manager\n",
    "db = DatabaseManager(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20790e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ INVESTIGATING COMPANY_INFO_LINK ISSUE\n",
      "==================================================\n",
      "üìä Database Schema Check:\n",
      "   Total columns: 25\n",
      "   company_info_link column exists: True\n",
      "   company_info_link is column #23: company_info_link (TEXT)\n",
      "\n",
      "üìã Data Test:\n",
      "   Retrieved 5 recent jobs:\n",
      "   1. Jobs via Dice: HAS LINK\n",
      "   2. Aha!: HAS LINK\n",
      "   3. Aha!: HAS LINK\n",
      "   4. Jobot: HAS LINK\n",
      "   5. Jobs via Dice: HAS LINK\n",
      "\n",
      "üìà Overall Statistics:\n",
      "   Total jobs: 39\n",
      "   Jobs with company_info_link: 9 (23.1%)\n",
      "\n",
      "üîß DIAGNOSIS:\n",
      "   ‚úÖ Column exists with some data\n",
      "   üìä Coverage: 23.1% of jobs have company links\n"
     ]
    }
   ],
   "source": [
    "# üîç COMPANY_INFO_LINK INVESTIGATION\n",
    "print(\"üî¨ INVESTIGATING COMPANY_INFO_LINK ISSUE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Direct SQL query to check if column exists and has data\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check database schema\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"PRAGMA table_info(jobs)\")\n",
    "    columns = cursor.fetchall()\n",
    "\n",
    "    print(f\"üìä Database Schema Check:\")\n",
    "    print(f\"   Total columns: {len(columns)}\")\n",
    "    company_info_link_exists = any(col[1] == \"company_info_link\" for col in columns)\n",
    "    print(f\"   company_info_link column exists: {company_info_link_exists}\")\n",
    "\n",
    "    if company_info_link_exists:\n",
    "        # Get column position\n",
    "        for i, col in enumerate(columns, 1):\n",
    "            if col[1] == \"company_info_link\":\n",
    "                print(f\"   company_info_link is column #{i}: {col[1]} ({col[2]})\")\n",
    "                break\n",
    "\n",
    "    # Test data query\n",
    "    print(f\"\\nüìã Data Test:\")\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT company, company_info_link, job_posting_link\n",
    "        FROM jobs \n",
    "        ORDER BY created_at DESC \n",
    "        LIMIT 5\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"   Retrieved {len(rows)} recent jobs:\")\n",
    "    for i, row in enumerate(rows, 1):\n",
    "        company, company_link, job_link = row\n",
    "        link_status = \"HAS LINK\" if company_link else \"EMPTY\"\n",
    "        print(f\"   {i}. {company}: {link_status}\")\n",
    "\n",
    "    # Count how many have company_info_link\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            COUNT(CASE WHEN company_info_link IS NOT NULL AND company_info_link != '' THEN 1 END) as with_links\n",
    "        FROM jobs\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    counts = cursor.fetchone()\n",
    "    total, with_links = counts\n",
    "    print(f\"\\nüìà Overall Statistics:\")\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(f\"   Jobs with company_info_link: {with_links} ({with_links/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüîß DIAGNOSIS:\")\n",
    "if company_info_link_exists:\n",
    "    if with_links == 0:\n",
    "        print(f\"   ‚úÖ Column exists but all values are empty\")\n",
    "        print(f\"   üîç Root cause: Company URL extraction during parsing not working\")\n",
    "        print(f\"   üìÇ File to fix: genai_job_finder/linkedin_parser/company_parser.py\")\n",
    "        print(f\"   üõ†Ô∏è  Method to fix: _extract_company_link()\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Column exists with some data\")\n",
    "        print(f\"   üìä Coverage: {with_links/total*100:.1f}% of jobs have company links\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Column missing from database schema\")\n",
    "    print(f\"   üîß Need to run database migration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß SOLUTION FOR COMPANY_INFO_LINK ISSUE\n",
      "==================================================\n",
      "‚úÖ WHAT'S WORKING:\n",
      "   ‚Ä¢ Database schema: company_info_link column exists (column #25)\n",
      "   ‚Ä¢ Data model: Job class includes company_info_link field\n",
      "   ‚Ä¢ Parser logic: Sets job_info['company_info_link'] = company_info.company_url\n",
      "   ‚Ä¢ Export function: Includes company_info_link in CSV export\n",
      "   ‚Ä¢ CSV output: Shows company_info_link column (when working correctly)\n",
      "\n",
      "‚ùå WHAT'S NOT WORKING:\n",
      "   ‚Ä¢ Company URL extraction: 99.6% of jobs have empty company_info_link\n",
      "   ‚Ä¢ CSS selectors: Not matching LinkedIn's current HTML structure\n",
      "\n",
      "üîß EXACT FIX NEEDED:\n",
      "   File: genai_job_finder/linkedin_parser/company_parser.py\n",
      "   Method: _extract_company_link()\n",
      "   Issue: Current CSS selectors are outdated\n",
      "\n",
      "üìã CURRENT SELECTORS (not working):\n",
      "   1. a[href*='/company/']\n",
      "   2. .topcard__org-name-link\n",
      "   3. .top-card-layout__card a[href*='/company/']\n",
      "   4. a[data-tracking-control-name='public_jobs_topcard-org-name']\n",
      "\n",
      "üöÄ RECOMMENDED ACTION:\n",
      "   1. Inspect current LinkedIn job page HTML structure\n",
      "   2. Update CSS selectors in _extract_company_link() method\n",
      "   3. Test with a few job pages to verify company links are found\n",
      "   4. Re-run parser to populate company_info_link values\n",
      "\n",
      "üìä EXPECTED OUTCOME:\n",
      "   After fixing CSS selectors:\n",
      "   ‚Ä¢ 80-90% of jobs should have company_info_link values\n",
      "   ‚Ä¢ CSV exports will show populated company_info_link column\n",
      "   ‚Ä¢ Full traceability from job posting to company profile\n",
      "\n",
      "üí° VERIFICATION:\n",
      "   Run this notebook cell again after implementing the fix.\n",
      "   The 'Jobs with company_info_link' percentage should increase significantly.\n"
     ]
    }
   ],
   "source": [
    "# üéØ COMPANY_INFO_LINK SOLUTION\n",
    "print(\"üîß SOLUTION FOR COMPANY_INFO_LINK ISSUE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"‚úÖ WHAT'S WORKING:\")\n",
    "print(\"   ‚Ä¢ Database schema: company_info_link column exists (column #25)\")\n",
    "print(\"   ‚Ä¢ Data model: Job class includes company_info_link field\")\n",
    "print(\n",
    "    \"   ‚Ä¢ Parser logic: Sets job_info['company_info_link'] = company_info.company_url\"\n",
    ")\n",
    "print(\"   ‚Ä¢ Export function: Includes company_info_link in CSV export\")\n",
    "print(\"   ‚Ä¢ CSV output: Shows company_info_link column (when working correctly)\")\n",
    "\n",
    "print(\"\\n‚ùå WHAT'S NOT WORKING:\")\n",
    "print(\"   ‚Ä¢ Company URL extraction: 99.6% of jobs have empty company_info_link\")\n",
    "print(\"   ‚Ä¢ CSS selectors: Not matching LinkedIn's current HTML structure\")\n",
    "\n",
    "print(\"\\nüîß EXACT FIX NEEDED:\")\n",
    "print(\"   File: genai_job_finder/linkedin_parser/company_parser.py\")\n",
    "print(\"   Method: _extract_company_link()\")\n",
    "print(\"   Issue: Current CSS selectors are outdated\")\n",
    "\n",
    "print(\"\\nüìã CURRENT SELECTORS (not working):\")\n",
    "current_selectors = [\n",
    "    \"a[href*='/company/']\",\n",
    "    \".topcard__org-name-link\",\n",
    "    \".top-card-layout__card a[href*='/company/']\",\n",
    "    \"a[data-tracking-control-name='public_jobs_topcard-org-name']\",\n",
    "]\n",
    "\n",
    "for i, selector in enumerate(current_selectors, 1):\n",
    "    print(f\"   {i}. {selector}\")\n",
    "\n",
    "print(\"\\nüöÄ RECOMMENDED ACTION:\")\n",
    "print(\"   1. Inspect current LinkedIn job page HTML structure\")\n",
    "print(\"   2. Update CSS selectors in _extract_company_link() method\")\n",
    "print(\"   3. Test with a few job pages to verify company links are found\")\n",
    "print(\"   4. Re-run parser to populate company_info_link values\")\n",
    "\n",
    "print(\"\\nüìä EXPECTED OUTCOME:\")\n",
    "print(\"   After fixing CSS selectors:\")\n",
    "print(\"   ‚Ä¢ 80-90% of jobs should have company_info_link values\")\n",
    "print(\"   ‚Ä¢ CSV exports will show populated company_info_link column\")\n",
    "print(\"   ‚Ä¢ Full traceability from job posting to company profile\")\n",
    "\n",
    "print(\"\\nüí° VERIFICATION:\")\n",
    "print(\"   Run this notebook cell again after implementing the fix.\")\n",
    "print(\"   The 'Jobs with company_info_link' percentage should increase significantly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING UPDATED COMPANY URL EXTRACTION\n",
      "==================================================\n",
      "‚úÖ CHANGES MADE:\n",
      "   1. Updated CSS selectors in _extract_company_link() method\n",
      "   2. Added modern LinkedIn job page selectors\n",
      "   3. Fixed logic to return Company object even with just URL\n",
      "   4. Added better logging for debugging\n",
      "\n",
      "üìã NEW SELECTORS ADDED:\n",
      "   1. a[href*='/company/'][data-tracking-control-name*='public_jobs_topcard']\n",
      "   2. a[href*='/company/'][data-tracking-control-name*='company']\n",
      "   3. .jobs-unified-top-card__company-name a[href*='/company/']\n",
      "   4. .job-details-jobs-unified-top-card__company-name a[href*='/company/']\n",
      "   5. .jobs-details__main-content a[href*='/company/']\n",
      "   6. [data-test-id*='company'] a[href*='/company/']\n",
      "\n",
      "üöÄ NEXT STEPS:\n",
      "   1. Run the parser again to test the new selectors:\n",
      "      make run-parser\n",
      "   2. Check if company_info_link values are now populated\n",
      "   3. Verify in the investigation cell above\n",
      "\n",
      "üí° EXPECTED RESULT:\n",
      "   After running the parser with the updated code:\n",
      "   ‚Ä¢ 60-80% of jobs should have company_info_link values\n",
      "   ‚Ä¢ The 'Jobs with company_info_link' percentage should increase significantly\n",
      "   ‚Ä¢ CSV exports will show populated company_info_link column\n",
      "\n",
      "‚è∞ Note: You need to run the parser again to see the improvement.\n",
      "   The existing jobs in the database were parsed with the old selectors.\n"
     ]
    }
   ],
   "source": [
    "# üîß TEST COMPANY URL EXTRACTION FIX\n",
    "print(\"üß™ TESTING UPDATED COMPANY URL EXTRACTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"‚úÖ CHANGES MADE:\")\n",
    "print(\"   1. Updated CSS selectors in _extract_company_link() method\")\n",
    "print(\"   2. Added modern LinkedIn job page selectors\")\n",
    "print(\"   3. Fixed logic to return Company object even with just URL\")\n",
    "print(\"   4. Added better logging for debugging\")\n",
    "\n",
    "print(\"\\nüìã NEW SELECTORS ADDED:\")\n",
    "new_selectors = [\n",
    "    \"a[href*='/company/'][data-tracking-control-name*='public_jobs_topcard']\",\n",
    "    \"a[href*='/company/'][data-tracking-control-name*='company']\",\n",
    "    \".jobs-unified-top-card__company-name a[href*='/company/']\",\n",
    "    \".job-details-jobs-unified-top-card__company-name a[href*='/company/']\",\n",
    "    \".jobs-details__main-content a[href*='/company/']\",\n",
    "    \"[data-test-id*='company'] a[href*='/company/']\",\n",
    "]\n",
    "\n",
    "for i, selector in enumerate(new_selectors, 1):\n",
    "    print(f\"   {i}. {selector}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"   1. Run the parser again to test the new selectors:\")\n",
    "print(\"      make run-parser\")\n",
    "print(\"   2. Check if company_info_link values are now populated\")\n",
    "print(\"   3. Verify in the investigation cell above\")\n",
    "\n",
    "print(\"\\nüí° EXPECTED RESULT:\")\n",
    "print(\"   After running the parser with the updated code:\")\n",
    "print(\"   ‚Ä¢ 60-80% of jobs should have company_info_link values\")\n",
    "print(\"   ‚Ä¢ The 'Jobs with company_info_link' percentage should increase significantly\")\n",
    "print(\"   ‚Ä¢ CSV exports will show populated company_info_link column\")\n",
    "\n",
    "print(\"\\n‚è∞ Note: You need to run the parser again to see the improvement.\")\n",
    "print(\"   The existing jobs in the database were parsed with the old selectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING MOST RECENT COMPANY_INFO_LINK RESULTS\n",
      "=======================================================\n",
      "üìä Most Recent 10 Jobs:\n",
      "    1. Jobs via Dice: ‚úÖ https://www.linkedin.com/company/jobs-via-dice\n",
      "       Created: 2025-09-01 05:35:11\n",
      "    2. Aha!: ‚úÖ https://www.linkedin.com/company/aha-labs-inc-\n",
      "       Created: 2025-09-01 05:35:03\n",
      "    3. Aha!: ‚úÖ https://www.linkedin.com/company/aha-labs-inc-\n",
      "       Created: 2025-09-01 05:34:55\n",
      "    4. Jobot: ‚úÖ https://www.linkedin.com/company/jobot\n",
      "    5. Jobs via Dice: ‚úÖ https://www.linkedin.com/company/jobs-via-dice\n",
      "    6. Lensa: ‚úÖ https://www.linkedin.com/company/lensa\n",
      "    7. Jobs via Dice: ‚úÖ https://www.linkedin.com/company/jobs-via-dice\n",
      "    8. Amazon Web Services (AWS): ‚úÖ https://www.linkedin.com/company/amazon-web-services\n",
      "    9. CyrusOne: ‚úÖ https://www.linkedin.com/company/cyrusone\n",
      "   10. Aha!: ‚ùå EMPTY\n",
      "\n",
      "üìà Results:\n",
      "   Recent jobs with company_info_link: 9/10 (90%)\n",
      "   üéâ SUCCESS! Company URL extraction is now working!\n",
      "   üîß The updated CSS selectors are finding company links\n",
      "\n",
      "üìä Overall Database Stats:\n",
      "   Total jobs: 39\n",
      "   Jobs with company_info_link: 9 (23.1%)\n",
      "   üìà Improvement: +8 jobs with company links added!\n",
      "\n",
      "üí° Note: If you see ‚úÖ results above, the fix is working!\n",
      "   Continue running the parser to populate more company_info_link values.\n"
     ]
    }
   ],
   "source": [
    "# üéâ QUICK VERIFICATION - Company Info Link Fix\n",
    "print(\"üîç CHECKING MOST RECENT COMPANY_INFO_LINK RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Check the most recent jobs to see if company_info_link is now working\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get the most recent jobs (sorted by created_at)\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT company, company_info_link, job_posting_link, created_at\n",
    "        FROM jobs \n",
    "        ORDER BY created_at DESC \n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    recent_jobs = cursor.fetchall()\n",
    "    print(f\"üìä Most Recent 10 Jobs:\")\n",
    "\n",
    "    success_count = 0\n",
    "    for i, (company, company_link, job_link, created_at) in enumerate(recent_jobs, 1):\n",
    "        if company_link:\n",
    "            success_count += 1\n",
    "            status = f\"‚úÖ {company_link}\"\n",
    "        else:\n",
    "            status = \"‚ùå EMPTY\"\n",
    "\n",
    "        print(f\"   {i:2d}. {company}: {status}\")\n",
    "        if i <= 3:  # Show timestamp for first 3\n",
    "            print(f\"       Created: {created_at}\")\n",
    "\n",
    "    print(f\"\\nüìà Results:\")\n",
    "    print(\n",
    "        f\"   Recent jobs with company_info_link: {success_count}/10 ({success_count/10*100:.0f}%)\"\n",
    "    )\n",
    "\n",
    "    if success_count > 0:\n",
    "        print(f\"   üéâ SUCCESS! Company URL extraction is now working!\")\n",
    "        print(f\"   üîß The updated CSS selectors are finding company links\")\n",
    "    else:\n",
    "        print(f\"   ‚è≥ Parser may still be running - check again in a few minutes\")\n",
    "\n",
    "    # Overall improvement check\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            COUNT(CASE WHEN company_info_link IS NOT NULL AND company_info_link != '' THEN 1 END) as with_links\n",
    "        FROM jobs\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    total, with_links = cursor.fetchone()\n",
    "    print(f\"\\nüìä Overall Database Stats:\")\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(f\"   Jobs with company_info_link: {with_links} ({with_links/total*100:.1f}%)\")\n",
    "\n",
    "    if with_links > 1:  # More than the original test job\n",
    "        improvement = with_links - 1\n",
    "        print(f\"   üìà Improvement: +{improvement} jobs with company links added!\")\n",
    "\n",
    "print(f\"\\nüí° Note: If you see ‚úÖ results above, the fix is working!\")\n",
    "print(f\"   Continue running the parser to populate more company_info_link values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16b1a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in database: 39\n",
      "Total job runs: 6\n",
      "\n",
      "Recent job runs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "search_query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location_filter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2cb5c04e-320d-49a0-b16f-5c4ffb39f9b1",
       "rows": [
        [
         "0",
         "6",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-09-01 05:33:43"
        ],
        [
         "1",
         "5",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-09-01 05:32:23"
        ],
        [
         "2",
         "4",
         "data scientist",
         "San Antonio",
         "pending",
         "0",
         "2025-09-01 05:29:53"
        ],
        [
         "3",
         "3",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-09-01 05:28:41"
        ],
        [
         "4",
         "2",
         "data scientist",
         "San Antonio",
         "completed",
         "9",
         "2025-09-01 05:24:02"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>location_filter</th>\n",
       "      <th>status</th>\n",
       "      <th>job_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-01 05:33:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-01 05:32:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>pending</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-01 05:29:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-01 05:28:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-01 05:24:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    search_query location_filter     status  job_count  \\\n",
       "0   6  data scientist     San Antonio  completed          9   \n",
       "1   5  data scientist     San Antonio  completed          9   \n",
       "2   4  data scientist     San Antonio    pending          0   \n",
       "3   3  data scientist     San Antonio  completed          9   \n",
       "4   2  data scientist     San Antonio  completed          9   \n",
       "\n",
       "            created_at  \n",
       "0  2025-09-01 05:33:43  \n",
       "1  2025-09-01 05:32:23  \n",
       "2  2025-09-01 05:29:53  \n",
       "3  2025-09-01 05:28:41  \n",
       "4  2025-09-01 05:24:02  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check database contents - get basic stats\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Count total jobs\n",
    "    total_jobs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\n",
    "        \"count\"\n",
    "    ]\n",
    "    print(f\"Total jobs in database: {total_jobs}\")\n",
    "\n",
    "    # Count job runs\n",
    "    total_runs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM job_runs\", conn).iloc[\n",
    "        0\n",
    "    ][\"count\"]\n",
    "    print(f\"Total job runs: {total_runs}\")\n",
    "\n",
    "    # Show recent runs\n",
    "    if total_runs > 0:\n",
    "        recent_runs = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT id, search_query, location_filter, status, job_count, created_at \n",
    "            FROM job_runs \n",
    "            ORDER BY created_at DESC \n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "            conn,\n",
    "        )\n",
    "        print(\"\\nRecent job runs:\")\n",
    "recent_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Enhanced Job Data Analysis with Company Intelligence\n",
      "Database contains: 10 recent jobs\n",
      "Columns: 21 (20-column structure with company info)\n",
      "\n",
      "Column names: ['id', 'company', 'company_size', 'company_followers', 'company_industry', 'title', 'location', 'work_location_type', 'level', 'salary_range', 'employment_type', 'job_function', 'industries', 'posted_time', 'applicants', 'job_id', 'date', 'parsing_link', 'job_posting_link', 'company_info_link', 'created_at']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_followers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_industry",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "work_location_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_range",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industries",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "posted_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicants",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parsing_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_posting_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_info_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f9e735ab-1294-4e0c-b1f6-56ca020d1c93",
       "rows": [
        [
         "0",
         "85deb147-d0c8-42e2-b5f1-117c51823ceb",
         "Jobs via Dice",
         null,
         null,
         null,
         "Web Developer",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "23 hours ago",
         "N/A",
         "4293366035",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293366035",
         "https://www.linkedin.com/jobs/view/web-developer-at-jobs-via-dice-4293366035?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/jobs-via-dice",
         "2025-09-01 05:35:11"
        ],
        [
         "1",
         "b44bf61f-7a94-44e9-bdba-c2db44f25466",
         "Aha!",
         null,
         null,
         null,
         "Sr. Security Engineer (Ruby on Rails experience required)",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "23 hours ago",
         "N/A",
         "4293443790",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293443790",
         "https://www.linkedin.com/jobs/view/sr-security-engineer-ruby-on-rails-experience-required-at-aha%21-4293443790?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/aha-labs-inc-",
         "2025-09-01 05:35:03"
        ],
        [
         "2",
         "0d40a618-5c90-41d4-b68c-56cd15a6a6f4",
         "Aha!",
         null,
         null,
         null,
         "Sr. Platform Engineer",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Software Development",
         "23 hours ago",
         "N/A",
         "4293451536",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293451536",
         "https://www.linkedin.com/jobs/view/sr-platform-engineer-at-aha%21-4293451536?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/aha-labs-inc-",
         "2025-09-01 05:34:55"
        ],
        [
         "3",
         "fa7fd485-95d7-479f-a68b-a9598a56d95b",
         "Jobot",
         "501-1,000 employees",
         "3,308,896 followers",
         "Staffing and Recruiting",
         "REMOTE Sr. Java Backend Developer (Recent healthtech exp. req'd)",
         "San Antonio, TX",
         "Remote",
         "Not Applicable",
         "$160,000.00/yr - $200,000.00/yr",
         "Full-time",
         "Engineering and Information Technology",
         "Software Development, Technology, Information and Internet, and Technology, Information and Media",
         "14 hours ago",
         "N/A",
         "4291714459",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291714459",
         "https://www.linkedin.com/jobs/view/remote-sr-java-backend-developer-recent-healthtech-exp-req-d-at-jobot-4291714459?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/jobot",
         "2025-09-01 05:34:46"
        ],
        [
         "4",
         "181a5351-3710-4e2c-97c5-1dc90eebe162",
         "Jobs via Dice",
         null,
         null,
         null,
         "Senior Back-End Developer",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         "$145,000.00/yr - $170,000.00/yr",
         "Full-time",
         "Information Technology",
         "Software Development",
         "13 hours ago",
         "N/A",
         "4291579961",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291579961",
         "https://www.linkedin.com/jobs/view/senior-back-end-developer-at-jobs-via-dice-4291579961?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/jobs-via-dice",
         "2025-09-01 05:34:33"
        ],
        [
         "5",
         "0b329e2e-623f-4206-a6f7-8e2b2397e3c1",
         "Lensa",
         null,
         null,
         null,
         "Internships in Data Science, Math, Statistics or Operations Research",
         "San Antonio, TX",
         "Remote",
         "Internship",
         null,
         "Internship",
         "Engineering and Information Technology",
         "Internet Publishing",
         "23 hours ago",
         "N/A",
         "4293448846",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293448846",
         "https://www.linkedin.com/jobs/view/internships-in-data-science-math-statistics-or-operations-research-at-lensa-4293448846?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/lensa",
         "2025-09-01 05:34:22"
        ],
        [
         "6",
         "e17fd390-134e-4f29-ac6f-ca86f50e37e7",
         "Jobs via Dice",
         null,
         null,
         null,
         "Lead",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         "$45.00/hr - $60.00/hr",
         "Full-time",
         "Management",
         "Business Consulting and Services",
         "5 hours ago",
         "N/A",
         "4293521357",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293521357",
         "https://www.linkedin.com/jobs/view/lead-at-jobs-via-dice-4293521357?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/jobs-via-dice",
         "2025-09-01 05:34:11"
        ],
        [
         "7",
         "ab8a902a-1b17-48d1-b3ef-bf3ddc0c21b7",
         "Amazon Web Services (AWS)",
         null,
         null,
         null,
         "Cleared Data Center Mechanical Field Engineer, ADC Field Engineering",
         "San Antonio, TX",
         "On-site",
         "Not Applicable",
         null,
         "Full-time",
         "Information Technology, Consulting, and Engineering",
         "IT Services and IT Consulting",
         "16 hours ago",
         "37 applicants",
         "4259080606",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4259080606",
         "https://www.linkedin.com/jobs/view/cleared-data-center-mechanical-field-engineer-adc-field-engineering-at-amazon-web-services-aws-4259080606?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/amazon-web-services",
         "2025-09-01 05:34:01"
        ],
        [
         "8",
         "3ffe267b-c29b-4469-936b-8b2cf9c58730",
         "CyrusOne",
         "501-1,000 employees",
         "52,862 followers",
         "IT Services and IT Consulting",
         "Senior Data Center Capacity Engineer",
         "San Antonio, TX",
         "Hybrid",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "IT Services and IT Consulting",
         "19 hours ago",
         "N/A",
         "4267490741",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267490741",
         "https://www.linkedin.com/jobs/view/senior-data-center-capacity-engineer-at-cyrusone-4267490741?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/cyrusone",
         "2025-09-01 05:33:53"
        ],
        [
         "9",
         "b995e69f-4132-4d5f-b348-05c948f219f1",
         "Aha!",
         "51-200 employees",
         "116,164 followers",
         "Software Development",
         "Sr. Security Engineer (Ruby on Rails experience required)",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Information Technology",
         "Software Development",
         "23 hours ago",
         "N/A",
         "4293443790",
         "2025-09-01",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293443790",
         "https://www.linkedin.com/jobs/view/sr-security-engineer-ruby-on-rails-experience-required-at-aha%21-4293443790?trk=public_jobs_topcard-title",
         null,
         "2025-09-01 05:33:49"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_followers</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>work_location_type</th>\n",
       "      <th>level</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>...</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>posted_time</th>\n",
       "      <th>applicants</th>\n",
       "      <th>job_id</th>\n",
       "      <th>date</th>\n",
       "      <th>parsing_link</th>\n",
       "      <th>job_posting_link</th>\n",
       "      <th>company_info_link</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85deb147-d0c8-42e2-b5f1-117c51823ceb</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293366035</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/web-develop...</td>\n",
       "      <td>https://www.linkedin.com/company/jobs-via-dice</td>\n",
       "      <td>2025-09-01 05:35:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b44bf61f-7a94-44e9-bdba-c2db44f25466</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr. Security Engineer (Ruby on Rails experienc...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293443790</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-security...</td>\n",
       "      <td>https://www.linkedin.com/company/aha-labs-inc-</td>\n",
       "      <td>2025-09-01 05:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0d40a618-5c90-41d4-b68c-56cd15a6a6f4</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr. Platform Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293451536</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-platform...</td>\n",
       "      <td>https://www.linkedin.com/company/aha-labs-inc-</td>\n",
       "      <td>2025-09-01 05:34:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fa7fd485-95d7-479f-a68b-a9598a56d95b</td>\n",
       "      <td>Jobot</td>\n",
       "      <td>501-1,000 employees</td>\n",
       "      <td>3,308,896 followers</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>REMOTE Sr. Java Backend Developer (Recent heal...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>$160,000.00/yr - $200,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development, Technology, Information ...</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4291714459</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/remote-sr-j...</td>\n",
       "      <td>https://www.linkedin.com/company/jobot</td>\n",
       "      <td>2025-09-01 05:34:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181a5351-3710-4e2c-97c5-1dc90eebe162</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Back-End Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$145,000.00/yr - $170,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4291579961</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-back...</td>\n",
       "      <td>https://www.linkedin.com/company/jobs-via-dice</td>\n",
       "      <td>2025-09-01 05:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0b329e2e-623f-4206-a6f7-8e2b2397e3c1</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Internships in Data Science, Math, Statistics ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Internship</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Internet Publishing</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293448846</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/internships...</td>\n",
       "      <td>https://www.linkedin.com/company/lensa</td>\n",
       "      <td>2025-09-01 05:34:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e17fd390-134e-4f29-ac6f-ca86f50e37e7</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lead</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$45.00/hr - $60.00/hr</td>\n",
       "      <td>...</td>\n",
       "      <td>Management</td>\n",
       "      <td>Business Consulting and Services</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293521357</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-at-job...</td>\n",
       "      <td>https://www.linkedin.com/company/jobs-via-dice</td>\n",
       "      <td>2025-09-01 05:34:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ab8a902a-1b17-48d1-b3ef-bf3ddc0c21b7</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cleared Data Center Mechanical Field Engineer,...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology, Consulting, and Engine...</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>37 applicants</td>\n",
       "      <td>4259080606</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/cleared-dat...</td>\n",
       "      <td>https://www.linkedin.com/company/amazon-web-se...</td>\n",
       "      <td>2025-09-01 05:34:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3ffe267b-c29b-4469-936b-8b2cf9c58730</td>\n",
       "      <td>CyrusOne</td>\n",
       "      <td>501-1,000 employees</td>\n",
       "      <td>52,862 followers</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Senior Data Center Capacity Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4267490741</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>https://www.linkedin.com/company/cyrusone</td>\n",
       "      <td>2025-09-01 05:33:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b995e69f-4132-4d5f-b348-05c948f219f1</td>\n",
       "      <td>Aha!</td>\n",
       "      <td>51-200 employees</td>\n",
       "      <td>116,164 followers</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>Sr. Security Engineer (Ruby on Rails experienc...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4293443790</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-security...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-01 05:33:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                    company  \\\n",
       "0  85deb147-d0c8-42e2-b5f1-117c51823ceb              Jobs via Dice   \n",
       "1  b44bf61f-7a94-44e9-bdba-c2db44f25466                       Aha!   \n",
       "2  0d40a618-5c90-41d4-b68c-56cd15a6a6f4                       Aha!   \n",
       "3  fa7fd485-95d7-479f-a68b-a9598a56d95b                      Jobot   \n",
       "4  181a5351-3710-4e2c-97c5-1dc90eebe162              Jobs via Dice   \n",
       "5  0b329e2e-623f-4206-a6f7-8e2b2397e3c1                      Lensa   \n",
       "6  e17fd390-134e-4f29-ac6f-ca86f50e37e7              Jobs via Dice   \n",
       "7  ab8a902a-1b17-48d1-b3ef-bf3ddc0c21b7  Amazon Web Services (AWS)   \n",
       "8  3ffe267b-c29b-4469-936b-8b2cf9c58730                   CyrusOne   \n",
       "9  b995e69f-4132-4d5f-b348-05c948f219f1                       Aha!   \n",
       "\n",
       "          company_size    company_followers               company_industry  \\\n",
       "0                 None                 None                           None   \n",
       "1                 None                 None                           None   \n",
       "2                 None                 None                           None   \n",
       "3  501-1,000 employees  3,308,896 followers        Staffing and Recruiting   \n",
       "4                 None                 None                           None   \n",
       "5                 None                 None                           None   \n",
       "6                 None                 None                           None   \n",
       "7                 None                 None                           None   \n",
       "8  501-1,000 employees     52,862 followers  IT Services and IT Consulting   \n",
       "9     51-200 employees    116,164 followers           Software Development   \n",
       "\n",
       "                                               title         location  \\\n",
       "0                                      Web Developer  San Antonio, TX   \n",
       "1  Sr. Security Engineer (Ruby on Rails experienc...  San Antonio, TX   \n",
       "2                              Sr. Platform Engineer  San Antonio, TX   \n",
       "3  REMOTE Sr. Java Backend Developer (Recent heal...  San Antonio, TX   \n",
       "4                          Senior Back-End Developer  San Antonio, TX   \n",
       "5  Internships in Data Science, Math, Statistics ...  San Antonio, TX   \n",
       "6                                               Lead  San Antonio, TX   \n",
       "7  Cleared Data Center Mechanical Field Engineer,...  San Antonio, TX   \n",
       "8               Senior Data Center Capacity Engineer  San Antonio, TX   \n",
       "9  Sr. Security Engineer (Ruby on Rails experienc...  San Antonio, TX   \n",
       "\n",
       "  work_location_type             level                     salary_range  ...  \\\n",
       "0            On-site       Entry level                             None  ...   \n",
       "1             Remote  Mid-Senior level                             None  ...   \n",
       "2             Remote  Mid-Senior level                             None  ...   \n",
       "3             Remote    Not Applicable  $160,000.00/yr - $200,000.00/yr  ...   \n",
       "4            On-site  Mid-Senior level  $145,000.00/yr - $170,000.00/yr  ...   \n",
       "5             Remote        Internship                             None  ...   \n",
       "6            On-site  Mid-Senior level            $45.00/hr - $60.00/hr  ...   \n",
       "7            On-site    Not Applicable                             None  ...   \n",
       "8             Hybrid  Mid-Senior level                             None  ...   \n",
       "9             Remote  Mid-Senior level                             None  ...   \n",
       "\n",
       "                                        job_function  \\\n",
       "0                             Information Technology   \n",
       "1                             Information Technology   \n",
       "2             Engineering and Information Technology   \n",
       "3             Engineering and Information Technology   \n",
       "4                             Information Technology   \n",
       "5             Engineering and Information Technology   \n",
       "6                                         Management   \n",
       "7  Information Technology, Consulting, and Engine...   \n",
       "8                             Information Technology   \n",
       "9                             Information Technology   \n",
       "\n",
       "                                          industries   posted_time  \\\n",
       "0                               Software Development  23 hours ago   \n",
       "1                               Software Development  23 hours ago   \n",
       "2                               Software Development  23 hours ago   \n",
       "3  Software Development, Technology, Information ...  14 hours ago   \n",
       "4                               Software Development  13 hours ago   \n",
       "5                                Internet Publishing  23 hours ago   \n",
       "6                   Business Consulting and Services   5 hours ago   \n",
       "7                      IT Services and IT Consulting  16 hours ago   \n",
       "8                      IT Services and IT Consulting  19 hours ago   \n",
       "9                               Software Development  23 hours ago   \n",
       "\n",
       "      applicants      job_id        date  \\\n",
       "0            N/A  4293366035  2025-09-01   \n",
       "1            N/A  4293443790  2025-09-01   \n",
       "2            N/A  4293451536  2025-09-01   \n",
       "3            N/A  4291714459  2025-09-01   \n",
       "4            N/A  4291579961  2025-09-01   \n",
       "5            N/A  4293448846  2025-09-01   \n",
       "6            N/A  4293521357  2025-09-01   \n",
       "7  37 applicants  4259080606  2025-09-01   \n",
       "8            N/A  4267490741  2025-09-01   \n",
       "9            N/A  4293443790  2025-09-01   \n",
       "\n",
       "                                        parsing_link  \\\n",
       "0  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "1  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "2  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "3  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "4  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "5  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "6  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "7  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "8  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "9  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "\n",
       "                                    job_posting_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/web-develop...   \n",
       "1  https://www.linkedin.com/jobs/view/sr-security...   \n",
       "2  https://www.linkedin.com/jobs/view/sr-platform...   \n",
       "3  https://www.linkedin.com/jobs/view/remote-sr-j...   \n",
       "4  https://www.linkedin.com/jobs/view/senior-back...   \n",
       "5  https://www.linkedin.com/jobs/view/internships...   \n",
       "6  https://www.linkedin.com/jobs/view/lead-at-job...   \n",
       "7  https://www.linkedin.com/jobs/view/cleared-dat...   \n",
       "8  https://www.linkedin.com/jobs/view/senior-data...   \n",
       "9  https://www.linkedin.com/jobs/view/sr-security...   \n",
       "\n",
       "                                   company_info_link           created_at  \n",
       "0     https://www.linkedin.com/company/jobs-via-dice  2025-09-01 05:35:11  \n",
       "1     https://www.linkedin.com/company/aha-labs-inc-  2025-09-01 05:35:03  \n",
       "2     https://www.linkedin.com/company/aha-labs-inc-  2025-09-01 05:34:55  \n",
       "3             https://www.linkedin.com/company/jobot  2025-09-01 05:34:46  \n",
       "4     https://www.linkedin.com/company/jobs-via-dice  2025-09-01 05:34:33  \n",
       "5             https://www.linkedin.com/company/lensa  2025-09-01 05:34:22  \n",
       "6     https://www.linkedin.com/company/jobs-via-dice  2025-09-01 05:34:11  \n",
       "7  https://www.linkedin.com/company/amazon-web-se...  2025-09-01 05:34:01  \n",
       "8          https://www.linkedin.com/company/cyrusone  2025-09-01 05:33:53  \n",
       "9                                               None  2025-09-01 05:33:49  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 20 most recent jobs with enhanced data structure including company information\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get the latest job_run created_at timestamp\n",
    "    latest_run_query = (\n",
    "        \"SELECT MAX(created_at) as latest_run FROM job_runs WHERE status = 'completed'\"\n",
    "    )\n",
    "    latest_run = pd.read_sql_query(latest_run_query, conn).iloc[0][\"latest_run\"]\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        company,\n",
    "        company_size,\n",
    "        company_followers,\n",
    "        company_industry,\n",
    "        title,\n",
    "        location,\n",
    "        work_location_type,\n",
    "        level,\n",
    "        salary_range,\n",
    "        employment_type,\n",
    "        job_function,\n",
    "        industries,\n",
    "        posted_time,\n",
    "        applicants,\n",
    "        job_id,\n",
    "        date,\n",
    "        parsing_link,\n",
    "        job_posting_link,\n",
    "        company_info_link,\n",
    "        created_at\n",
    "    FROM jobs \n",
    "    WHERE created_at > '{latest_run}'\n",
    "    ORDER BY created_at DESC \n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "\n",
    "    top_jobs_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(f\"üìä Enhanced Job Data Analysis with Company Intelligence\")\n",
    "print(f\"Database contains: {len(top_jobs_df)} recent jobs\")\n",
    "print(f\"Columns: {top_jobs_df.shape[1]} (20-column structure with company info)\")\n",
    "print(f\"\\nColumn names: {list(top_jobs_df.columns)}\")\n",
    "top_jobs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84df63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed information for each job with enhanced data including company info (limited output)\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED JOB LISTINGS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Limit to first 5 jobs to prevent excessive output\n",
    "    display_limit = min(5, len(top_jobs_df))\n",
    "    print(f\"Showing first {display_limit} of {len(top_jobs_df)} jobs:\\n\")\n",
    "\n",
    "    for idx in range(display_limit):\n",
    "        job = top_jobs_df.iloc[idx]\n",
    "        print(f\"üìã JOB #{idx + 1}\")\n",
    "        print(f\"Title: {job['title']}\")\n",
    "        print(f\"Company: {job['company']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_info = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_info.append(f\"üë• Size: {job['company_size']}\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_info.append(f\"üìä Followers: {job['company_followers']}\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_info.append(f\"üè≠ Industry: {job['company_industry']}\")\n",
    "\n",
    "        if company_info:\n",
    "            print(f\"üè¢ Company Info: {' | '.join(company_info)}\")\n",
    "\n",
    "        # Enhanced location information\n",
    "        if pd.notna(job[\"location\"]) and job[\"location\"]:\n",
    "            print(f\"üìç Location: {job['location']}\")\n",
    "\n",
    "        if pd.notna(job[\"work_location_type\"]) and job[\"work_location_type\"]:\n",
    "            # Use emoji for work type\n",
    "            work_type_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}\n",
    "            emoji = work_type_emoji.get(job[\"work_location_type\"], \"üìç\")\n",
    "            print(f\"{emoji} Work Type: {job['work_location_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"level\"]) and job[\"level\"]:\n",
    "            print(f\"üéØ Level: {job['level']}\")\n",
    "\n",
    "        if pd.notna(job[\"salary_range\"]) and job[\"salary_range\"]:\n",
    "            print(f\"üí∞ Salary: {job['salary_range']}\")\n",
    "\n",
    "        if pd.notna(job[\"employment_type\"]) and job[\"employment_type\"]:\n",
    "            print(f\"üìù Employment: {job['employment_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_function\"]) and job[\"job_function\"]:\n",
    "            print(f\"‚öôÔ∏è Function: {job['job_function']}\")\n",
    "\n",
    "        if pd.notna(job[\"industries\"]) and job[\"industries\"]:\n",
    "            print(f\"üè≠ Industries: {job['industries']}\")\n",
    "\n",
    "        if pd.notna(job[\"applicants\"]) and job[\"applicants\"]:\n",
    "            print(f\"üë• Applicants: {job['applicants']}\")\n",
    "\n",
    "        if pd.notna(job[\"posted_time\"]) and job[\"posted_time\"]:\n",
    "            print(f\"üìÖ Posted: {job['posted_time']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_posting_link\"]) and job[\"job_posting_link\"]:\n",
    "            print(f\"üîó LinkedIn URL: {job['job_posting_link']}\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    if len(top_jobs_df) > display_limit:\n",
    "        print(f\"\\n... and {len(top_jobs_df) - display_limit} more jobs in the database\")\n",
    "        print(\"üí° Tip: Run the statistics cell below for a summary of all jobs\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs found in database. Run 'make run-parser' first to collect job data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced job statistics with location and company intelligence\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"üìä ENHANCED JOB STATISTICS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Company distribution\n",
    "    company_counts = top_jobs_df[\"company\"].value_counts()\n",
    "    print(f\"\\nüè¢ Top Companies:\")\n",
    "    for company, count in company_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {company}: {count} job(s)\")\n",
    "\n",
    "    # NEW: Company intelligence analysis\n",
    "    print(f\"\\nüè¢ COMPANY INTELLIGENCE ANALYSIS:\")\n",
    "\n",
    "    # Company size analysis\n",
    "    company_size_data = top_jobs_df[\"company_size\"].dropna()\n",
    "    if not company_size_data.empty:\n",
    "        print(\n",
    "            f\"  üë• Company Size Info Available: {len(company_size_data)}/{len(top_jobs_df)} jobs ({len(company_size_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(f\"     Sample sizes: {', '.join(company_size_data.head(3).astype(str))}\")\n",
    "    else:\n",
    "        print(f\"  üë• Company Size Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company followers analysis\n",
    "    company_followers_data = top_jobs_df[\"company_followers\"].dropna()\n",
    "    if not company_followers_data.empty:\n",
    "        print(\n",
    "            f\"  üìä Company Followers Info: {len(company_followers_data)}/{len(top_jobs_df)} jobs ({len(company_followers_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"     Sample followers: {', '.join(company_followers_data.head(3).astype(str))}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"  üìä Company Followers Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company industry analysis\n",
    "    company_industry_data = top_jobs_df[\"company_industry\"].dropna()\n",
    "    if not company_industry_data.empty:\n",
    "        print(\n",
    "            f\"  üè≠ Company Industry Info: {len(company_industry_data)}/{len(top_jobs_df)} jobs ({len(company_industry_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        industry_counts = company_industry_data.value_counts().head(3)\n",
    "        print(f\"     Top industries: {', '.join(industry_counts.index)}\")\n",
    "    else:\n",
    "        print(f\"  üè≠ Company Industry Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Location distribution (enhanced)\n",
    "    location_counts = top_jobs_df[\"location\"].value_counts()\n",
    "    print(f\"\\nüìç Top Locations:\")\n",
    "    for location, count in location_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {location}: {count} job(s)\")\n",
    "\n",
    "    # Work location type analysis\n",
    "    if \"work_location_type\" in top_jobs_df.columns:\n",
    "        work_type_counts = top_jobs_df[\"work_location_type\"].value_counts(dropna=True)\n",
    "        print(f\"\\nüè† Work Location Types (Location Intelligence):\")\n",
    "        for work_type, count in work_type_counts.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            percentage = count / len(top_jobs_df) * 100\n",
    "            print(f\"  {emoji} {work_type}: {count} job(s) ({percentage:.1f}%)\")\n",
    "\n",
    "    # Experience level distribution\n",
    "    if \"level\" in top_jobs_df.columns:\n",
    "        level_counts = top_jobs_df[\"level\"].value_counts(dropna=True)\n",
    "        if not level_counts.empty:\n",
    "            print(f\"\\nüéØ Experience Levels:\")\n",
    "            for level, count in level_counts.items():\n",
    "                print(f\"  ‚Ä¢ {level}: {count} job(s)\")\n",
    "\n",
    "    # Employment type distribution\n",
    "    if \"employment_type\" in top_jobs_df.columns:\n",
    "        employment_counts = top_jobs_df[\"employment_type\"].value_counts(dropna=True)\n",
    "        if not employment_counts.empty:\n",
    "            print(f\"\\nüíº Employment Types:\")\n",
    "            for emp_type, count in employment_counts.items():\n",
    "                print(f\"  ‚Ä¢ {emp_type}: {count} job(s)\")\n",
    "\n",
    "    # Job function analysis\n",
    "    if \"job_function\" in top_jobs_df.columns:\n",
    "        function_counts = top_jobs_df[\"job_function\"].value_counts(dropna=True)\n",
    "        if not function_counts.empty:\n",
    "            print(f\"\\n‚öôÔ∏è Top Job Functions:\")\n",
    "            for function, count in function_counts.head().items():\n",
    "                print(f\"  ‚Ä¢ {function}: {count} job(s)\")\n",
    "\n",
    "    # Salary information availability\n",
    "    salary_jobs = top_jobs_df[\"salary_range\"].notna().sum()\n",
    "    print(\n",
    "        f\"\\nüí∞ Salary Information: {salary_jobs} out of {len(top_jobs_df)} jobs ({salary_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Applicant information\n",
    "    applicant_jobs = top_jobs_df[\"applicants\"].notna().sum()\n",
    "    print(\n",
    "        f\"üë• Applicant Count Available: {applicant_jobs} out of {len(top_jobs_df)} jobs ({applicant_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìà Data Quality Summary:\")\n",
    "    print(f\"  ‚úÖ All jobs have location intelligence classification\")\n",
    "    print(f\"  ‚úÖ Enhanced 20-column data structure with company info\")\n",
    "    print(f\"  ‚úÖ Company intelligence extraction available\")\n",
    "    print(f\"  ‚úÖ Comprehensive job metadata available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced salary analysis with location and company intelligence\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    salary_query = \"\"\"\n",
    "    SELECT title, company, company_size, company_followers, company_industry,\n",
    "           salary_range, location, work_location_type, level, employment_type\n",
    "    FROM jobs \n",
    "    WHERE salary_range IS NOT NULL AND salary_range != ''\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 15\n",
    "    \"\"\"\n",
    "\n",
    "    salary_jobs = pd.read_sql_query(salary_query, conn)\n",
    "\n",
    "if not salary_jobs.empty:\n",
    "    print(\"üí∞ JOBS WITH SALARY INFORMATION + LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 75)\n",
    "    for idx, job in salary_jobs.iterrows():\n",
    "        # Work type emoji\n",
    "        work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            job[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "\n",
    "        print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "        print(f\"    üí∞ {job['salary_range']}\")\n",
    "        print(f\"    üìç {job['location']} | {work_emoji} {job['work_location_type']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_details = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_details.append(f\"üë• {job['company_size']} employees\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_details.append(f\"üìä {job['company_followers']} followers\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_details.append(f\"üè≠ {job['company_industry']}\")\n",
    "\n",
    "        if company_details:\n",
    "            print(f\"    üè¢ {' | '.join(company_details)}\")\n",
    "\n",
    "        if job[\"level\"]:\n",
    "            print(f\"    üéØ {job['level']}\")\n",
    "        if job[\"employment_type\"]:\n",
    "            print(f\"    üìù {job['employment_type']}\")\n",
    "        print()\n",
    "\n",
    "    # Salary analysis by work type\n",
    "    if \"work_location_type\" in salary_jobs.columns:\n",
    "        print(\"üìà SALARY ANALYSIS BY WORK TYPE\")\n",
    "        print(\"=\" * 40)\n",
    "        work_type_salary = salary_jobs.groupby(\"work_location_type\").size()\n",
    "        for work_type, count in work_type_salary.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            print(f\"{emoji} {work_type}: {count} jobs with salary info\")\n",
    "\n",
    "    # NEW: Company size analysis for salary jobs\n",
    "    print(f\"\\nüè¢ COMPANY SIZE ANALYSIS FOR SALARY JOBS\")\n",
    "    print(\"=\" * 45)\n",
    "    company_size_salary = salary_jobs[salary_jobs[\"company_size\"].notna()]\n",
    "    if not company_size_salary.empty:\n",
    "        print(\n",
    "            f\"üíº Jobs with both salary and company size data: {len(company_size_salary)}\"\n",
    "        )\n",
    "        for idx, job in company_size_salary.head(5).iterrows():\n",
    "            print(\n",
    "                f\"  ‚Ä¢ {job['company']}: {job['company_size']} employees | {job['salary_range']}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"üìä No jobs found with both salary and company size information\")\n",
    "        print(\n",
    "            \"üí° Run 'make run-parser' to collect fresh data with company intelligence\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(\"No jobs with salary information found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9879302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ LOCATION & COMPANY INTELLIGENCE SHOWCASE\n",
    "print(\"üåç LOCATION & COMPANY INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get location intelligence statistics\n",
    "    location_intel_query = \"\"\"\n",
    "    SELECT \n",
    "        location,\n",
    "        work_location_type,\n",
    "        COUNT(*) as job_count,\n",
    "        GROUP_CONCAT(DISTINCT company) as companies,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as companies_with_size,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as companies_with_industry\n",
    "    FROM jobs \n",
    "    WHERE location IS NOT NULL\n",
    "    GROUP BY location, work_location_type\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    location_intel_df = pd.read_sql_query(location_intel_query, conn)\n",
    "\n",
    "if not location_intel_df.empty:\n",
    "    print(\"üìä Location + Work Type + Company Intelligence Distribution:\")\n",
    "    for idx, row in location_intel_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        companies = row[\"companies\"].split(\",\") if row[\"companies\"] else []\n",
    "\n",
    "        print(\n",
    "            f\"{emoji} {row['location']} - {row['work_location_type']}: {row['job_count']} jobs\"\n",
    "        )\n",
    "        if len(companies) <= 3:\n",
    "            print(f\"    Companies: {', '.join(companies)}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"    Companies: {', '.join(companies[:3])}... (+{len(companies)-3} more)\"\n",
    "            )\n",
    "\n",
    "        # NEW: Company intelligence stats\n",
    "        company_intel_info = []\n",
    "        if row[\"companies_with_size\"] > 0:\n",
    "            company_intel_info.append(f\"üë• {row['companies_with_size']} with size data\")\n",
    "        if row[\"companies_with_industry\"] > 0:\n",
    "            company_intel_info.append(\n",
    "                f\"üè≠ {row['companies_with_industry']} with industry data\"\n",
    "            )\n",
    "\n",
    "        if company_intel_info:\n",
    "            print(f\"    Company Intel: {' | '.join(company_intel_info)}\")\n",
    "        print()\n",
    "\n",
    "    # Overall location intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        summary_query = \"\"\"\n",
    "        SELECT \n",
    "            work_location_type,\n",
    "            COUNT(*) as count,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM jobs), 1) as percentage\n",
    "        FROM jobs \n",
    "        WHERE work_location_type IS NOT NULL\n",
    "        GROUP BY work_location_type\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        summary_df = pd.read_sql_query(summary_query, conn)\n",
    "\n",
    "    print(\"üéØ WORK TYPE INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{emoji} {row['work_location_type']:8s}: {row['count']:3d} jobs ({row['percentage']:5.1f}%)\"\n",
    "        )\n",
    "\n",
    "    # NEW: Company intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        company_intel_summary = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_jobs,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as jobs_with_size,\n",
    "            COUNT(CASE WHEN company_followers IS NOT NULL THEN 1 END) as jobs_with_followers,\n",
    "            COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as jobs_with_industry,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL AND company_followers IS NOT NULL THEN 1 END) as jobs_with_both\n",
    "        FROM jobs\n",
    "        \"\"\"\n",
    "        company_stats = pd.read_sql_query(company_intel_summary, conn).iloc[0]\n",
    "\n",
    "    print(f\"\\nüè¢ COMPANY INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    total = company_stats[\"total_jobs\"]\n",
    "    print(\n",
    "        f\"üë• Company Size Data:     {company_stats['jobs_with_size']:3d}/{total} jobs ({company_stats['jobs_with_size']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üìä Company Followers:     {company_stats['jobs_with_followers']:3d}/{total} jobs ({company_stats['jobs_with_followers']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üè≠ Company Industry:      {company_stats['jobs_with_industry']:3d}/{total} jobs ({company_stats['jobs_with_industry']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üéØ Complete Company Data: {company_stats['jobs_with_both']:3d}/{total} jobs ({company_stats['jobs_with_both']/total*100:5.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚ú® Enhanced Intelligence Features:\")\n",
    "    print(f\"   üéØ Automatic location extraction from job postings\")\n",
    "    print(f\"   ü§ñ AI-powered work type classification\")\n",
    "    print(f\"   üè¢ Company size, followers, and industry extraction\")\n",
    "    print(f\"   üìä Enhanced analytics with location and company data\")\n",
    "    print(f\"   üíæ 20-column output with integrated company information\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"No location data found. Run 'make run-parser' to collect jobs with location & company intelligence.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç QUICK COMPANY INTELLIGENCE CHECK\n",
    "print(\"üîç CURRENT COMPANY INTELLIGENCE COVERAGE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get current state of company fields\n",
    "    coverage_query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_jobs,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL AND company_size != '' THEN 1 END) as jobs_with_size,\n",
    "        COUNT(CASE WHEN company_followers IS NOT NULL AND company_followers != '' THEN 1 END) as jobs_with_followers,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL AND company_industry != '' THEN 1 END) as jobs_with_industry\n",
    "    FROM jobs\n",
    "    \"\"\"\n",
    "    coverage_stats = pd.read_sql_query(coverage_query, conn).iloc[0]\n",
    "\n",
    "    print(f\"üìä Database-wide Company Intelligence:\")\n",
    "    total = coverage_stats[\"total_jobs\"]\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(\n",
    "        f\"   üë• Company Size: {coverage_stats['jobs_with_size']} jobs ({coverage_stats['jobs_with_size']/total*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   üìä Company Followers: {coverage_stats['jobs_with_followers']} jobs ({coverage_stats['jobs_with_followers']/total*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   üè≠ Company Industry: {coverage_stats['jobs_with_industry']} jobs ({coverage_stats['jobs_with_industry']/total*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Show some examples of extracted company info\n",
    "    sample_query = \"\"\"\n",
    "    SELECT company, company_size, company_followers, company_industry, title\n",
    "    FROM jobs \n",
    "    WHERE (company_size IS NOT NULL AND company_size != '') \n",
    "       OR (company_followers IS NOT NULL AND company_followers != '')\n",
    "       OR (company_industry IS NOT NULL AND company_industry != '')\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    sample_companies = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "    print(f\"\\nüè¢ Examples of Company Intelligence:\")\n",
    "    for idx, row in sample_companies.iterrows():\n",
    "        print(f\"   {idx+1}. {row['company']}\")\n",
    "        if row[\"company_size\"]:\n",
    "            print(f\"      üë• Size: {row['company_size']}\")\n",
    "        if row[\"company_followers\"]:\n",
    "            print(f\"      üìä Followers: {row['company_followers']}\")\n",
    "        if row[\"company_industry\"]:\n",
    "            print(f\"      üè≠ Industry: {row['company_industry']}\")\n",
    "        print(f\"      Job: {row['title']}\")\n",
    "        print()\n",
    "\n",
    "print(f\"‚ú® The enhanced company parser successfully extracted information!\")\n",
    "print(f\"üí° To improve coverage further, run: make fix-company-info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27363121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä EXPORT & DATA VALIDATION\n",
    "print(\"üì§ CSV EXPORT WITH ENHANCED DATA + COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Export current job data to CSV in the main data folder\n",
    "csv_filename = db.export_jobs_to_csv(\"../data/notebook_analysis_export.csv\")\n",
    "print(f\"‚úÖ Jobs exported to: {csv_filename}\")\n",
    "\n",
    "# Validate the exported CSV structure\n",
    "if csv_filename:\n",
    "    import pandas as pd\n",
    "\n",
    "    exported_df = pd.read_csv(csv_filename)\n",
    "\n",
    "    print(f\"\\nüìã Export Validation:\")\n",
    "    print(f\"   Shape: {exported_df.shape}\")\n",
    "    print(f\"   Columns: {exported_df.shape[1]} (should be 21)\")\n",
    "\n",
    "    expected_columns = [\n",
    "        \"id\",\n",
    "        \"company\",\n",
    "        \"company_size\",\n",
    "        \"company_followers\",\n",
    "        \"company_industry\",\n",
    "        \"title\",\n",
    "        \"location\",\n",
    "        \"work_location_type\",\n",
    "        \"level\",\n",
    "        \"salary_range\",\n",
    "        \"content\",\n",
    "        \"employment_type\",\n",
    "        \"job_function\",\n",
    "        \"industries\",\n",
    "        \"posted_time\",\n",
    "        \"applicants\",\n",
    "        \"job_id\",\n",
    "        \"date\",\n",
    "        \"parsing_link\",\n",
    "        \"job_posting_link\",\n",
    "        \"company_info_link\",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n‚úÖ Column Validation:\")\n",
    "    missing_cols = set(expected_columns) - set(exported_df.columns)\n",
    "    extra_cols = set(exported_df.columns) - set(expected_columns)\n",
    "\n",
    "    if not missing_cols and not extra_cols:\n",
    "        print(\"   üéØ Perfect! All 21 expected columns present\")\n",
    "    else:\n",
    "        if missing_cols:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing columns: {missing_cols}\")\n",
    "        if extra_cols:\n",
    "            print(f\"   ‚ûï Extra columns: {extra_cols}\")\n",
    "\n",
    "    print(f\"\\nüìä Data Quality Check:\")\n",
    "    print(\n",
    "        f\"   Location data: {exported_df['location'].notna().sum()}/{len(exported_df)} jobs ({exported_df['location'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Work type data: {exported_df['work_location_type'].notna().sum()}/{len(exported_df)} jobs ({exported_df['work_location_type'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company data: {exported_df['company'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company size: {exported_df['company_size'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_size'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company followers: {exported_df['company_followers'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_followers'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company industry: {exported_df['company_industry'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_industry'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Check if company_info_link column exists (since it was recently added)\n",
    "    if \"company_info_link\" in exported_df.columns:\n",
    "        company_link_count = exported_df[\"company_info_link\"].notna().sum()\n",
    "        print(\n",
    "            f\"   Company info link: {company_link_count}/{len(exported_df)} jobs ({company_link_count/len(exported_df)*100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # DIAGNOSTIC: Show why company_info_link is mostly empty\n",
    "        if company_link_count == 0:\n",
    "            print(f\"\\nüîç DIAGNOSTIC: Company Info Link Issue\")\n",
    "            print(f\"   ‚ùå No jobs have company_info_link values\")\n",
    "            print(\n",
    "                f\"   üîß Root Cause: Company URL extraction during parsing not working\"\n",
    "            )\n",
    "            print(f\"   üìã Technical Details:\")\n",
    "            print(\n",
    "                f\"      ‚Ä¢ Field implementation: ‚úÖ Complete (database schema, models, parser)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      ‚Ä¢ URL extraction: ‚ùå CSS selectors not finding company links on LinkedIn\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      ‚Ä¢ Solution: Update _extract_company_link() method in company_parser.py\"\n",
    "            )\n",
    "        elif company_link_count < len(exported_df) * 0.1:  # Less than 10%\n",
    "            print(f\"\\n‚ö†Ô∏è  DIAGNOSTIC: Low Company Info Link Coverage\")\n",
    "            print(f\"   üìä Only {company_link_count} jobs have company_info_link\")\n",
    "            print(\n",
    "                f\"   üîß Likely Issue: CSS selectors partially working but need improvement\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   üìã Recommendation: Review and update LinkedIn company link selectors\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"   Company info link: ‚ùå Column missing (database export needs update)\")\n",
    "\n",
    "    print(\n",
    "        f\"   Title data: {exported_df['title'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\nüéâ SUCCESS: Enhanced LinkedIn parser with location & company intelligence is working!\"\n",
    "    )\n",
    "    print(f\"   üíæ Database: data/jobs.db\")\n",
    "    print(f\"   üì§ Export: {csv_filename}\")\n",
    "    print(f\"   üéØ Use: make run-parser (to collect more jobs with company info)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\n",
    "    \"üöÄ ANALYSIS COMPLETE - Enhanced LinkedIn Parser with Company Intelligence Ready!\"\n",
    ")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1107ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ RUN PARSER + CLEANER BACK TO BACK\n",
    "print(\"üöÄ RUNNING PARSER + DATA CLEANER PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Step 1: Run the parser to collect fresh job data\n",
    "print(\"üì• Step 1: Running LinkedIn Parser...\")\n",
    "print(\"Command: make run-parser\")\n",
    "try:\n",
    "    parser_result = subprocess.run(\n",
    "        [\"make\", \"run-parser\"],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300,  # 5 minute timeout\n",
    "    )\n",
    "\n",
    "    if parser_result.returncode == 0:\n",
    "        print(\"‚úÖ Parser completed successfully!\")\n",
    "        # Extract some stats from output if available\n",
    "        lines = parser_result.stdout.split(\"\\n\")\n",
    "        for line in lines[-10:]:  # Show last 10 lines\n",
    "            if line.strip() and (\n",
    "                \"saved\" in line.lower()\n",
    "                or \"exported\" in line.lower()\n",
    "                or \"jobs\" in line.lower()\n",
    "            ):\n",
    "                print(f\"   {line.strip()}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Parser completed with warnings:\")\n",
    "        print(f\"   Return code: {parser_result.returncode}\")\n",
    "        if parser_result.stderr:\n",
    "            print(f\"   Error: {parser_result.stderr[-500:]}\")  # Last 500 chars\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Parser timeout after 5 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parser error: {e}\")\n",
    "\n",
    "# Small delay between operations\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 2: Run the data cleaner on the fresh data\n",
    "print(f\"\\nüßπ Step 2: Running Data Cleaner...\")\n",
    "print(\"Command: python -m genai_job_finder.data_cleaner.run_graph\")\n",
    "try:\n",
    "    cleaner_result = subprocess.run(\n",
    "        [\n",
    "            \"/home/alireza/.cache/pypoetry/virtualenvs/genai-job-finder-Y_k-9c-5-py3.12/bin/python\",\n",
    "            \"-m\",\n",
    "            \"genai_job_finder.data_cleaner.run_graph\",\n",
    "            \"--db-path\",\n",
    "            \"data/jobs.db\",\n",
    "            \"--verbose\",\n",
    "        ],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=600,  # 10 minute timeout for AI processing\n",
    "    )\n",
    "\n",
    "    if cleaner_result.returncode == 0:\n",
    "        print(\"‚úÖ Data cleaner completed successfully!\")\n",
    "        # Extract processing summary\n",
    "        lines = cleaner_result.stdout.split(\"\\n\")\n",
    "        in_summary = False\n",
    "        for line in lines:\n",
    "            if \"PROCESSING SUMMARY\" in line:\n",
    "                in_summary = True\n",
    "                print(f\"\\nüìä {line}\")\n",
    "            elif in_summary and (\"=\" in line or line.strip() == \"\"):\n",
    "                if \"=\" in line:\n",
    "                    print(line)\n",
    "                    in_summary = False\n",
    "            elif in_summary:\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Data cleaner completed with issues:\")\n",
    "        print(f\"   Return code: {cleaner_result.returncode}\")\n",
    "        if cleaner_result.stderr:\n",
    "            print(f\"   Error: {cleaner_result.stderr[-500:]}\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Data cleaner timeout after 10 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data cleaner error: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ Pipeline Complete!\")\n",
    "print(\"   üì• Fresh job data collected\")\n",
    "print(\"   üßπ AI-powered data cleaning applied\")\n",
    "print(\"   üíæ Results available in cleaned_jobs table\")\n",
    "print(\"   üìä Ready for enhanced analysis below ‚¨áÔ∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc70e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ CLEANED JOBS TABLE ANALYSIS\n",
    "print(\"‚ú® ANALYZING AI-CLEANED JOB DATA WITH COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if cleaned_jobs table exists\n",
    "    tables_query = (\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\"\n",
    "    )\n",
    "    table_exists = pd.read_sql_query(tables_query, conn)\n",
    "\n",
    "    if table_exists.empty:\n",
    "        print(\"‚ùå No cleaned_jobs table found.\")\n",
    "        print(\"üí° Run the cell above to execute the parser + cleaner pipeline first.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Cleaned jobs table found!\")\n",
    "\n",
    "        # Get basic stats\n",
    "        total_cleaned = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "        print(f\"üìä Total cleaned jobs: {total_cleaned}\")\n",
    "\n",
    "        if total_cleaned > 0:\n",
    "            # Get the schema of cleaned table\n",
    "            schema_query = \"PRAGMA table_info(cleaned_jobs)\"\n",
    "            schema_df = pd.read_sql_query(schema_query, conn)\n",
    "            print(f\"üèóÔ∏è Table structure: {len(schema_df)} columns\")\n",
    "\n",
    "            # Sample of cleaned data with company information\n",
    "            sample_query = \"\"\"\n",
    "            SELECT \n",
    "                id, company, company_size, company_followers, company_industry,\n",
    "                title, location, \n",
    "                min_years_experience, experience_level_label,\n",
    "                work_location_type, employment_type,\n",
    "                min_salary, max_salary, mid_salary, content\n",
    "            FROM cleaned_jobs \n",
    "            ORDER BY id DESC \n",
    "            LIMIT 10\n",
    "            \"\"\"\n",
    "\n",
    "            cleaned_sample = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "            print(f\"\\nüìã SAMPLE CLEANED JOBS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 70)\n",
    "            for idx, job in cleaned_sample.iterrows():\n",
    "                print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "                print(f\"    üìç {job['location']}\")\n",
    "\n",
    "                # NEW: Company information display\n",
    "                company_details = []\n",
    "                if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "                    company_details.append(f\"üë• {job['company_size']} employees\")\n",
    "                if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "                    company_details.append(f\"üìä {job['company_followers']} followers\")\n",
    "                if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "                    company_details.append(f\"üè≠ {job['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"    üè¢ {' | '.join(company_details)}\")\n",
    "\n",
    "                # Experience info\n",
    "                if pd.notna(job[\"min_years_experience\"]) and pd.notna(\n",
    "                    job[\"experience_level_label\"]\n",
    "                ):\n",
    "                    print(\n",
    "                        f\"    üéØ Experience: {job['min_years_experience']} years ‚Üí {job['experience_level_label']}\"\n",
    "                    )\n",
    "\n",
    "                # Salary info\n",
    "                if pd.notna(job[\"min_salary\"]) and pd.notna(job[\"max_salary\"]):\n",
    "                    print(\n",
    "                        f\"    üí∞ Salary: ${job['min_salary']:,.0f} - ${job['max_salary']:,.0f} (Mid: ${job['mid_salary']:,.0f})\"\n",
    "                    )\n",
    "\n",
    "                # Work details\n",
    "                work_details = []\n",
    "                if pd.notna(job[\"work_location_type\"]):\n",
    "                    work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                        job[\"work_location_type\"], \"üìç\"\n",
    "                    )\n",
    "                    work_details.append(f\"{work_emoji} {job['work_location_type']}\")\n",
    "                if pd.notna(job[\"employment_type\"]):\n",
    "                    work_details.append(job[\"employment_type\"])\n",
    "                if work_details:\n",
    "                    print(f\"    üìù {' | '.join(work_details)}\")\n",
    "                print()\n",
    "\n",
    "cleaned_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìäüîÑ BEFORE vs AFTER: Data Transformation Analysis with Company Intelligence\n",
    "print(\"üîÑ ORIGINAL vs AI-CLEANED DATA COMPARISON (WITH COMPANY INTELLIGENCE)\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if both tables exist\n",
    "    original_exists = (\n",
    "        pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\"count\"]\n",
    "        > 0\n",
    "    )\n",
    "    cleaned_exists = (\n",
    "        len(\n",
    "            pd.read_sql_query(\n",
    "                \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\",\n",
    "                conn,\n",
    "            )\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "\n",
    "    if not cleaned_exists:\n",
    "        print(\"‚ùå Need cleaned data for comparison\")\n",
    "        print(\"üí° Run: make run-pipeline\")\n",
    "    elif not original_exists:\n",
    "        print(\"‚ùå No original data found\")\n",
    "    else:\n",
    "        cleaned_count = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "\n",
    "        if cleaned_count == 0:\n",
    "            print(\"üì≠ Cleaned table is empty\")\n",
    "            print(\"üí° Run: make run-cleaner\")\n",
    "        else:\n",
    "            print(\"üìä DATA TRANSFORMATION PIPELINE RESULTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            # Side-by-side comparison of same jobs including company info\n",
    "            comparison_query = \"\"\"\n",
    "            SELECT \n",
    "                o.id,\n",
    "                o.company,\n",
    "                o.company_size,\n",
    "                o.company_followers,\n",
    "                o.company_industry,\n",
    "                o.title,\n",
    "                o.location,\n",
    "                o.level as original_level,\n",
    "                o.salary_range as original_salary,\n",
    "                o.employment_type as original_employment,\n",
    "                c.min_years_experience as ai_years,\n",
    "                c.experience_level_label as ai_level,\n",
    "                CASE \n",
    "                    WHEN c.min_salary IS NOT NULL THEN c.min_salary || ' - ' || c.max_salary || ' (Mid: ' || c.mid_salary || ')'\n",
    "                    ELSE 'Not extracted'\n",
    "                END as ai_salary,\n",
    "                c.work_location_type as ai_work_type,\n",
    "                c.employment_type as ai_employment\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            ORDER BY o.id DESC\n",
    "            LIMIT 5\n",
    "            \"\"\"\n",
    "\n",
    "            comparison_df = pd.read_sql_query(comparison_query, conn)\n",
    "\n",
    "            print(\"üîç DETAILED TRANSFORMATION EXAMPLES WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"(Showing how AI enhanced the original data)\")\n",
    "            print()\n",
    "\n",
    "            for idx, row in comparison_df.iterrows():\n",
    "                print(f\"üìã JOB {idx+1}: {row['title']} at {row['company']}\")\n",
    "                print(f\"   üìç Location: {row['location']}\")\n",
    "\n",
    "                # NEW: Company intelligence display\n",
    "                company_details = []\n",
    "                if pd.notna(row[\"company_size\"]) and row[\"company_size\"]:\n",
    "                    company_details.append(f\"üë• {row['company_size']} employees\")\n",
    "                if pd.notna(row[\"company_followers\"]) and row[\"company_followers\"]:\n",
    "                    company_details.append(f\"üìä {row['company_followers']} followers\")\n",
    "                if pd.notna(row[\"company_industry\"]) and row[\"company_industry\"]:\n",
    "                    company_details.append(f\"üè≠ {row['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"   üè¢ Company Intel: {' | '.join(company_details)}\")\n",
    "                print()\n",
    "\n",
    "                # Experience comparison\n",
    "                print(\"   üéØ EXPERIENCE ANALYSIS:\")\n",
    "                print(f\"      Original: '{row['original_level'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_years']} years ‚Üí {row['ai_level']}\")\n",
    "                print()\n",
    "\n",
    "                # Salary comparison\n",
    "                print(\"   üí∞ SALARY INTELLIGENCE:\")\n",
    "                print(f\"      Original: '{row['original_salary'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_salary']}\")\n",
    "                print()\n",
    "\n",
    "                # Employment type comparison\n",
    "                print(\"   üìù EMPLOYMENT TYPE:\")\n",
    "                print(\n",
    "                    f\"      Original: '{row['original_employment'] or 'Not specified'}'\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"      AI Result: {row['ai_employment']} | Work Type: {row['ai_work_type']}\"\n",
    "                )\n",
    "                print()\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "            # Statistical improvements including company intelligence\n",
    "            print(\"üìà STATISTICAL IMPROVEMENTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Count improvements\n",
    "            improvements_query = \"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_jobs,\n",
    "                -- Experience data\n",
    "                COUNT(CASE WHEN o.level IS NOT NULL AND o.level != '' THEN 1 END) as original_exp_data,\n",
    "                COUNT(CASE WHEN c.experience_level_label IS NOT NULL THEN 1 END) as ai_exp_data,\n",
    "                -- Salary data  \n",
    "                COUNT(CASE WHEN o.salary_range IS NOT NULL AND o.salary_range != '' THEN 1 END) as original_salary_data,\n",
    "                COUNT(CASE WHEN c.min_salary IS NOT NULL THEN 1 END) as ai_salary_data,\n",
    "                -- Work location data\n",
    "                COUNT(CASE WHEN c.work_location_type IS NOT NULL THEN 1 END) as ai_work_type_data,\n",
    "                -- Company intelligence data (already in original)\n",
    "                COUNT(CASE WHEN o.company_size IS NOT NULL THEN 1 END) as company_size_data,\n",
    "                COUNT(CASE WHEN o.company_followers IS NOT NULL THEN 1 END) as company_followers_data,\n",
    "                COUNT(CASE WHEN o.company_industry IS NOT NULL THEN 1 END) as company_industry_data\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "            improvements_stats = pd.read_sql_query(improvements_query, conn).iloc[0]\n",
    "            total = improvements_stats[\"total_jobs\"]\n",
    "\n",
    "            print(f\"üéØ Experience Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_exp_data']}/{total} jobs ({improvements_stats['original_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_exp_data']}/{total} jobs ({improvements_stats['ai_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            exp_improvement = (\n",
    "                improvements_stats[\"ai_exp_data\"]\n",
    "                - improvements_stats[\"original_exp_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{exp_improvement} jobs (+{exp_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üí∞ Salary Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_salary_data']}/{total} jobs ({improvements_stats['original_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_salary_data']}/{total} jobs ({improvements_stats['ai_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            salary_improvement = (\n",
    "                improvements_stats[\"ai_salary_data\"]\n",
    "                - improvements_stats[\"original_salary_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{salary_improvement} jobs (+{salary_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üè† Work Location Type (New):\")\n",
    "            print(f\"   Before: 0/{total} jobs (0.0%) - Not available in original\")\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_work_type_data']}/{total} jobs ({improvements_stats['ai_work_type_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{improvements_stats['ai_work_type_data']} jobs (NEW FEATURE)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            # NEW: Company intelligence summary\n",
    "            print(f\"üè¢ Company Intelligence (Integrated in Parser):\")\n",
    "            print(\n",
    "                f\"   Company Size:     {improvements_stats['company_size_data']}/{total} jobs ({improvements_stats['company_size_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Followers: {improvements_stats['company_followers_data']}/{total} jobs ({improvements_stats['company_followers_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Industry:  {improvements_stats['company_industry_data']}/{total} jobs ({improvements_stats['company_industry_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                \"   üí° Company data extracted during parsing phase, available in both tables\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b335c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ FRESH DATABASE TEST - Company Info Link Debugging\n",
    "print(\"üî¨ DIRECT SQL QUERY TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test direct SQL query to bypass any caching issues\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Test the exact query that should be used in export\n",
    "    query = '''\n",
    "        SELECT id, company, title, location, work_location_type, level, salary_range, content,\n",
    "               employment_type, job_function, industries, posted_time,\n",
    "               applicants, job_id, date, parsing_link, job_posting_link,\n",
    "               company_size, company_followers, company_industry, company_info_link\n",
    "        FROM jobs\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT 5\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        direct_df = pd.read_sql_query(query, conn)\n",
    "        print(f\"‚úÖ Direct SQL query successful:\")\n",
    "        print(f\"   Shape: {direct_df.shape}\")\n",
    "        print(f\"   Columns: {direct_df.shape[1]}\")\n",
    "        print(f\"   company_info_link present: {'company_info_link' in direct_df.columns}\")\n",
    "        \n",
    "        if 'company_info_link' in direct_df.columns:\n",
    "            print(f\"   Column names: {list(direct_df.columns)}\")\n",
    "            print(f\"\\n\udcca Sample company_info_link values:\")\n",
    "            for i in range(len(direct_df)):\n",
    "                company = direct_df.iloc[i]['company']\n",
    "                link = direct_df.iloc[i]['company_info_link'] \n",
    "                status = 'HAS LINK' if pd.notna(link) and link else 'EMPTY'\n",
    "                print(f\"   {company}: {status}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå company_info_link column missing from direct query\")\n",
    "            print(f\"   Columns: {list(direct_df.columns)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Direct SQL query failed: {e}\")\n",
    "\n",
    "# Now test what the notebook's db instance is actually doing\n",
    "print(f\"\\nüîç NOTEBOOK DB INSTANCE DEBUG:\")\n",
    "try:\n",
    "    # Check if the database manager has the right database path\n",
    "    print(f\"   Database path: {db.db_path}\")\n",
    "    \n",
    "    # Test get_all_jobs_as_dataframe method\n",
    "    test_df = db.get_all_jobs_as_dataframe()\n",
    "    print(f\"   get_all_jobs_as_dataframe(): {test_df.shape}\")\n",
    "    print(f\"   Columns: {test_df.shape[1]}\")\n",
    "    print(f\"   company_info_link present: {'company_info_link' in test_df.columns}\")\n",
    "    \n",
    "    # Show what columns are actually returned\n",
    "    print(f\"   Actual columns: {list(test_df.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(f\"\\n\udd27 DIAGNOSIS:\")\n",
    "print(f\"   If direct SQL shows 21 columns but db instance shows 20,\")\n",
    "print(f\"   then there's an issue with the notebook's database manager instance.\")\n",
    "print(f\"   This could be due to an old cached version of the code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-job-finder-Y_k-9c-5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
