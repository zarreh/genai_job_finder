{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be7e499",
   "metadata": {},
   "source": [
    "# Enhanced LinkedIn Job Database Analysis\n",
    "\n",
    "This notebook analyzes the LinkedIn job database with the new enhanced parser that includes:\n",
    "\n",
    "- **20-column output structure** (with integrated company information)\n",
    "- **Company intelligence** with automatic extraction of company size, followers, and industry\n",
    "- **Location intelligence** with automatic extraction\n",
    "- **Work type classification** (Remote/Hybrid/On-site)\n",
    "- **Enhanced data model** with comprehensive job and company information\n",
    "\n",
    "Run `make run-parser` first to collect fresh job data with location and company intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = (\n",
    "    Path(__file__).parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    ")\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from genai_job_finder.linkedin_parser.database import DatabaseManager\n",
    "from genai_job_finder.linkedin_parser.models import Job, JobRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1daf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/alireza/projects/genai_job_finder')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5a736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /home/alireza/projects/genai_job_finder/data/jobs.db\n",
      "Database exists: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db_path = project_root / \"data\" / \"jobs.db\"\n",
    "# db_path = project_root / \"test_jobs.db\"\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")\n",
    "\n",
    "# Create database manager\n",
    "db = DatabaseManager(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20790e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ INVESTIGATING COMPANY_INFO_LINK ISSUE\n",
      "==================================================\n",
      "üìä Database Schema Check:\n",
      "   Total columns: 25\n",
      "   company_info_link column exists: True\n",
      "   company_info_link is column #23: company_info_link (TEXT)\n",
      "\n",
      "üìã Data Test:\n",
      "   Retrieved 5 recent jobs:\n",
      "   1. City of San Antonio: HAS LINK\n",
      "   2. HirePower Staffing Solution: HAS LINK\n",
      "   3. City of San Antonio: HAS LINK\n",
      "   4. KPMG US: HAS LINK\n",
      "   5. Shrive Technologies: HAS LINK\n",
      "\n",
      "üìà Overall Statistics:\n",
      "   Total jobs: 124\n",
      "   Jobs with company_info_link: 121 (97.6%)\n",
      "\n",
      "üîß DIAGNOSIS:\n",
      "   ‚úÖ Column exists with some data\n",
      "   üìä Coverage: 97.6% of jobs have company links\n"
     ]
    }
   ],
   "source": [
    "# üîç COMPANY_INFO_LINK INVESTIGATION\n",
    "print(\"üî¨ INVESTIGATING COMPANY_INFO_LINK ISSUE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Direct SQL query to check if column exists and has data\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check database schema\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"PRAGMA table_info(jobs)\")\n",
    "    columns = cursor.fetchall()\n",
    "\n",
    "    print(f\"üìä Database Schema Check:\")\n",
    "    print(f\"   Total columns: {len(columns)}\")\n",
    "    company_info_link_exists = any(col[1] == \"company_info_link\" for col in columns)\n",
    "    print(f\"   company_info_link column exists: {company_info_link_exists}\")\n",
    "\n",
    "    if company_info_link_exists:\n",
    "        # Get column position\n",
    "        for i, col in enumerate(columns, 1):\n",
    "            if col[1] == \"company_info_link\":\n",
    "                print(f\"   company_info_link is column #{i}: {col[1]} ({col[2]})\")\n",
    "                break\n",
    "\n",
    "    # Test data query\n",
    "    print(f\"\\nüìã Data Test:\")\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT company, company_info_link, job_posting_link\n",
    "        FROM jobs \n",
    "        ORDER BY created_at DESC \n",
    "        LIMIT 5\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"   Retrieved {len(rows)} recent jobs:\")\n",
    "    for i, row in enumerate(rows, 1):\n",
    "        company, company_link, job_link = row\n",
    "        link_status = \"HAS LINK\" if company_link else \"EMPTY\"\n",
    "        print(f\"   {i}. {company}: {link_status}\")\n",
    "\n",
    "    # Count how many have company_info_link\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            COUNT(CASE WHEN company_info_link IS NOT NULL AND company_info_link != '' THEN 1 END) as with_links\n",
    "        FROM jobs\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    counts = cursor.fetchone()\n",
    "    total, with_links = counts\n",
    "    print(f\"\\nüìà Overall Statistics:\")\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(f\"   Jobs with company_info_link: {with_links} ({with_links/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüîß DIAGNOSIS:\")\n",
    "if company_info_link_exists:\n",
    "    if with_links == 0:\n",
    "        print(f\"   ‚úÖ Column exists but all values are empty\")\n",
    "        print(f\"   üîç Root cause: Company URL extraction during parsing not working\")\n",
    "        print(f\"   üìÇ File to fix: genai_job_finder/linkedin_parser/company_parser.py\")\n",
    "        print(f\"   üõ†Ô∏è  Method to fix: _extract_company_link()\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Column exists with some data\")\n",
    "        print(f\"   üìä Coverage: {with_links/total*100:.1f}% of jobs have company links\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Column missing from database schema\")\n",
    "    print(f\"   üîß Need to run database migration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1507abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß SOLUTION FOR COMPANY_INFO_LINK ISSUE\n",
      "==================================================\n",
      "‚úÖ WHAT'S WORKING:\n",
      "   ‚Ä¢ Database schema: company_info_link column exists (column #25)\n",
      "   ‚Ä¢ Data model: Job class includes company_info_link field\n",
      "   ‚Ä¢ Parser logic: Sets job_info['company_info_link'] = company_info.company_url\n",
      "   ‚Ä¢ Export function: Includes company_info_link in CSV export\n",
      "   ‚Ä¢ CSV output: Shows company_info_link column (when working correctly)\n",
      "\n",
      "‚ùå WHAT'S NOT WORKING:\n",
      "   ‚Ä¢ Company URL extraction: 99.6% of jobs have empty company_info_link\n",
      "   ‚Ä¢ CSS selectors: Not matching LinkedIn's current HTML structure\n",
      "\n",
      "üîß EXACT FIX NEEDED:\n",
      "   File: genai_job_finder/linkedin_parser/company_parser.py\n",
      "   Method: _extract_company_link()\n",
      "   Issue: Current CSS selectors are outdated\n",
      "\n",
      "üìã CURRENT SELECTORS (not working):\n",
      "   1. a[href*='/company/']\n",
      "   2. .topcard__org-name-link\n",
      "   3. .top-card-layout__card a[href*='/company/']\n",
      "   4. a[data-tracking-control-name='public_jobs_topcard-org-name']\n",
      "\n",
      "üöÄ RECOMMENDED ACTION:\n",
      "   1. Inspect current LinkedIn job page HTML structure\n",
      "   2. Update CSS selectors in _extract_company_link() method\n",
      "   3. Test with a few job pages to verify company links are found\n",
      "   4. Re-run parser to populate company_info_link values\n",
      "\n",
      "üìä EXPECTED OUTCOME:\n",
      "   After fixing CSS selectors:\n",
      "   ‚Ä¢ 80-90% of jobs should have company_info_link values\n",
      "   ‚Ä¢ CSV exports will show populated company_info_link column\n",
      "   ‚Ä¢ Full traceability from job posting to company profile\n",
      "\n",
      "üí° VERIFICATION:\n",
      "   Run this notebook cell again after implementing the fix.\n",
      "   The 'Jobs with company_info_link' percentage should increase significantly.\n"
     ]
    }
   ],
   "source": [
    "# üéØ COMPANY_INFO_LINK SOLUTION\n",
    "print(\"üîß SOLUTION FOR COMPANY_INFO_LINK ISSUE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"‚úÖ WHAT'S WORKING:\")\n",
    "print(\"   ‚Ä¢ Database schema: company_info_link column exists (column #25)\")\n",
    "print(\"   ‚Ä¢ Data model: Job class includes company_info_link field\")\n",
    "print(\n",
    "    \"   ‚Ä¢ Parser logic: Sets job_info['company_info_link'] = company_info.company_url\"\n",
    ")\n",
    "print(\"   ‚Ä¢ Export function: Includes company_info_link in CSV export\")\n",
    "print(\"   ‚Ä¢ CSV output: Shows company_info_link column (when working correctly)\")\n",
    "\n",
    "print(\"\\n‚ùå WHAT'S NOT WORKING:\")\n",
    "print(\"   ‚Ä¢ Company URL extraction: 99.6% of jobs have empty company_info_link\")\n",
    "print(\"   ‚Ä¢ CSS selectors: Not matching LinkedIn's current HTML structure\")\n",
    "\n",
    "print(\"\\nüîß EXACT FIX NEEDED:\")\n",
    "print(\"   File: genai_job_finder/linkedin_parser/company_parser.py\")\n",
    "print(\"   Method: _extract_company_link()\")\n",
    "print(\"   Issue: Current CSS selectors are outdated\")\n",
    "\n",
    "print(\"\\nüìã CURRENT SELECTORS (not working):\")\n",
    "current_selectors = [\n",
    "    \"a[href*='/company/']\",\n",
    "    \".topcard__org-name-link\",\n",
    "    \".top-card-layout__card a[href*='/company/']\",\n",
    "    \"a[data-tracking-control-name='public_jobs_topcard-org-name']\",\n",
    "]\n",
    "\n",
    "for i, selector in enumerate(current_selectors, 1):\n",
    "    print(f\"   {i}. {selector}\")\n",
    "\n",
    "print(\"\\nüöÄ RECOMMENDED ACTION:\")\n",
    "print(\"   1. Inspect current LinkedIn job page HTML structure\")\n",
    "print(\"   2. Update CSS selectors in _extract_company_link() method\")\n",
    "print(\"   3. Test with a few job pages to verify company links are found\")\n",
    "print(\"   4. Re-run parser to populate company_info_link values\")\n",
    "\n",
    "print(\"\\nüìä EXPECTED OUTCOME:\")\n",
    "print(\"   After fixing CSS selectors:\")\n",
    "print(\"   ‚Ä¢ 80-90% of jobs should have company_info_link values\")\n",
    "print(\"   ‚Ä¢ CSV exports will show populated company_info_link column\")\n",
    "print(\"   ‚Ä¢ Full traceability from job posting to company profile\")\n",
    "\n",
    "print(\"\\nüí° VERIFICATION:\")\n",
    "print(\"   Run this notebook cell again after implementing the fix.\")\n",
    "print(\"   The 'Jobs with company_info_link' percentage should increase significantly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc61e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING UPDATED COMPANY URL EXTRACTION\n",
      "==================================================\n",
      "‚úÖ CHANGES MADE:\n",
      "   1. Updated CSS selectors in _extract_company_link() method\n",
      "   2. Added modern LinkedIn job page selectors\n",
      "   3. Fixed logic to return Company object even with just URL\n",
      "   4. Added better logging for debugging\n",
      "\n",
      "üìã NEW SELECTORS ADDED:\n",
      "   1. a[href*='/company/'][data-tracking-control-name*='public_jobs_topcard']\n",
      "   2. a[href*='/company/'][data-tracking-control-name*='company']\n",
      "   3. .jobs-unified-top-card__company-name a[href*='/company/']\n",
      "   4. .job-details-jobs-unified-top-card__company-name a[href*='/company/']\n",
      "   5. .jobs-details__main-content a[href*='/company/']\n",
      "   6. [data-test-id*='company'] a[href*='/company/']\n",
      "\n",
      "üöÄ NEXT STEPS:\n",
      "   1. Run the parser again to test the new selectors:\n",
      "      make run-parser\n",
      "   2. Check if company_info_link values are now populated\n",
      "   3. Verify in the investigation cell above\n",
      "\n",
      "üí° EXPECTED RESULT:\n",
      "   After running the parser with the updated code:\n",
      "   ‚Ä¢ 60-80% of jobs should have company_info_link values\n",
      "   ‚Ä¢ The 'Jobs with company_info_link' percentage should increase significantly\n",
      "   ‚Ä¢ CSV exports will show populated company_info_link column\n",
      "\n",
      "‚è∞ Note: You need to run the parser again to see the improvement.\n",
      "   The existing jobs in the database were parsed with the old selectors.\n"
     ]
    }
   ],
   "source": [
    "# üîß TEST COMPANY URL EXTRACTION FIX\n",
    "print(\"üß™ TESTING UPDATED COMPANY URL EXTRACTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"‚úÖ CHANGES MADE:\")\n",
    "print(\"   1. Updated CSS selectors in _extract_company_link() method\")\n",
    "print(\"   2. Added modern LinkedIn job page selectors\")\n",
    "print(\"   3. Fixed logic to return Company object even with just URL\")\n",
    "print(\"   4. Added better logging for debugging\")\n",
    "\n",
    "print(\"\\nüìã NEW SELECTORS ADDED:\")\n",
    "new_selectors = [\n",
    "    \"a[href*='/company/'][data-tracking-control-name*='public_jobs_topcard']\",\n",
    "    \"a[href*='/company/'][data-tracking-control-name*='company']\",\n",
    "    \".jobs-unified-top-card__company-name a[href*='/company/']\",\n",
    "    \".job-details-jobs-unified-top-card__company-name a[href*='/company/']\",\n",
    "    \".jobs-details__main-content a[href*='/company/']\",\n",
    "    \"[data-test-id*='company'] a[href*='/company/']\",\n",
    "]\n",
    "\n",
    "for i, selector in enumerate(new_selectors, 1):\n",
    "    print(f\"   {i}. {selector}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"   1. Run the parser again to test the new selectors:\")\n",
    "print(\"      make run-parser\")\n",
    "print(\"   2. Check if company_info_link values are now populated\")\n",
    "print(\"   3. Verify in the investigation cell above\")\n",
    "\n",
    "print(\"\\nüí° EXPECTED RESULT:\")\n",
    "print(\"   After running the parser with the updated code:\")\n",
    "print(\"   ‚Ä¢ 60-80% of jobs should have company_info_link values\")\n",
    "print(\"   ‚Ä¢ The 'Jobs with company_info_link' percentage should increase significantly\")\n",
    "print(\"   ‚Ä¢ CSV exports will show populated company_info_link column\")\n",
    "\n",
    "print(\"\\n‚è∞ Note: You need to run the parser again to see the improvement.\")\n",
    "print(\"   The existing jobs in the database were parsed with the old selectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbd2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING MOST RECENT COMPANY_INFO_LINK RESULTS\n",
      "=======================================================\n",
      "üìä Most Recent 10 Jobs:\n",
      "    1. City of San Antonio: ‚úÖ https://www.linkedin.com/company/city-of-san-antonio\n",
      "       Created: 2025-09-22 00:59:26\n",
      "    2. HirePower Staffing Solution: ‚úÖ https://in.linkedin.com/company/hirepower-staffing-solution\n",
      "       Created: 2025-09-22 00:59:24\n",
      "    3. City of San Antonio: ‚úÖ https://www.linkedin.com/company/city-of-san-antonio\n",
      "       Created: 2025-09-22 00:59:22\n",
      "    4. KPMG US: ‚úÖ https://www.linkedin.com/company/kpmg-us\n",
      "    5. Shrive Technologies: ‚úÖ https://www.linkedin.com/company/shrive-technologies\n",
      "    6. Shrive Technologies: ‚úÖ https://www.linkedin.com/company/shrive-technologies\n",
      "    7. Oscar: ‚úÖ https://uk.linkedin.com/company/oscar\n",
      "    8. E-Solutions: ‚úÖ https://www.linkedin.com/company/e-solutions-inc\n",
      "    9. City of San Antonio: ‚úÖ https://www.linkedin.com/company/city-of-san-antonio\n",
      "   10. Frost: ‚úÖ https://www.linkedin.com/company/frostbank\n",
      "\n",
      "üìà Results:\n",
      "   Recent jobs with company_info_link: 10/10 (100%)\n",
      "   üéâ SUCCESS! Company URL extraction is now working!\n",
      "   üîß The updated CSS selectors are finding company links\n",
      "\n",
      "üìä Overall Database Stats:\n",
      "   Total jobs: 124\n",
      "   Jobs with company_info_link: 121 (97.6%)\n",
      "   üìà Improvement: +120 jobs with company links added!\n",
      "\n",
      "üí° Note: If you see ‚úÖ results above, the fix is working!\n",
      "   Continue running the parser to populate more company_info_link values.\n"
     ]
    }
   ],
   "source": [
    "# üéâ QUICK VERIFICATION - Company Info Link Fix\n",
    "print(\"üîç CHECKING MOST RECENT COMPANY_INFO_LINK RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Check the most recent jobs to see if company_info_link is now working\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get the most recent jobs (sorted by created_at)\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT company, company_info_link, job_posting_link, created_at\n",
    "        FROM jobs \n",
    "        ORDER BY created_at DESC \n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    recent_jobs = cursor.fetchall()\n",
    "    print(f\"üìä Most Recent 10 Jobs:\")\n",
    "\n",
    "    success_count = 0\n",
    "    for i, (company, company_link, job_link, created_at) in enumerate(recent_jobs, 1):\n",
    "        if company_link:\n",
    "            success_count += 1\n",
    "            status = f\"‚úÖ {company_link}\"\n",
    "        else:\n",
    "            status = \"‚ùå EMPTY\"\n",
    "\n",
    "        print(f\"   {i:2d}. {company}: {status}\")\n",
    "        if i <= 3:  # Show timestamp for first 3\n",
    "            print(f\"       Created: {created_at}\")\n",
    "\n",
    "    print(f\"\\nüìà Results:\")\n",
    "    print(\n",
    "        f\"   Recent jobs with company_info_link: {success_count}/10 ({success_count/10*100:.0f}%)\"\n",
    "    )\n",
    "\n",
    "    if success_count > 0:\n",
    "        print(f\"   üéâ SUCCESS! Company URL extraction is now working!\")\n",
    "        print(f\"   üîß The updated CSS selectors are finding company links\")\n",
    "    else:\n",
    "        print(f\"   ‚è≥ Parser may still be running - check again in a few minutes\")\n",
    "\n",
    "    # Overall improvement check\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            COUNT(CASE WHEN company_info_link IS NOT NULL AND company_info_link != '' THEN 1 END) as with_links\n",
    "        FROM jobs\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    total, with_links = cursor.fetchone()\n",
    "    print(f\"\\nüìä Overall Database Stats:\")\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(f\"   Jobs with company_info_link: {with_links} ({with_links/total*100:.1f}%)\")\n",
    "\n",
    "    if with_links > 1:  # More than the original test job\n",
    "        improvement = with_links - 1\n",
    "        print(f\"   üìà Improvement: +{improvement} jobs with company links added!\")\n",
    "\n",
    "print(f\"\\nüí° Note: If you see ‚úÖ results above, the fix is working!\")\n",
    "print(f\"   Continue running the parser to populate more company_info_link values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b1a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in database: 124\n",
      "Total job runs: 12\n",
      "\n",
      "Recent job runs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "search_query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location_filter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9d41c981-e8af-4237-99b1-11954ee16071",
       "rows": [
        [
         "0",
         "12",
         "Data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-09-22 00:58:40"
        ],
        [
         "1",
         "11",
         "Data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-09-22 00:56:08"
        ],
        [
         "2",
         "10",
         "Data scientist",
         "San Antonio",
         "completed",
         "19",
         "2025-09-22 00:47:37"
        ],
        [
         "3",
         "9",
         "Data scientist",
         "San Antonio",
         "pending",
         "0",
         "2025-09-22 00:04:15"
        ],
        [
         "4",
         "8",
         "Data scientist",
         "San Antonio",
         "completed",
         "20",
         "2025-09-08 02:07:11"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>location_filter</th>\n",
       "      <th>status</th>\n",
       "      <th>job_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-22 00:58:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-22 00:56:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-09-22 00:47:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>pending</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-22 00:04:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>completed</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-08 02:07:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    search_query location_filter     status  job_count  \\\n",
       "0  12  Data scientist     San Antonio  completed         20   \n",
       "1  11  Data scientist     San Antonio  completed         20   \n",
       "2  10  Data scientist     San Antonio  completed         19   \n",
       "3   9  Data scientist     San Antonio    pending          0   \n",
       "4   8  Data scientist     San Antonio  completed         20   \n",
       "\n",
       "            created_at  \n",
       "0  2025-09-22 00:58:40  \n",
       "1  2025-09-22 00:56:08  \n",
       "2  2025-09-22 00:47:37  \n",
       "3  2025-09-22 00:04:15  \n",
       "4  2025-09-08 02:07:11  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check database contents - get basic stats\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Count total jobs\n",
    "    total_jobs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\n",
    "        \"count\"\n",
    "    ]\n",
    "    print(f\"Total jobs in database: {total_jobs}\")\n",
    "\n",
    "    # Count job runs\n",
    "    total_runs = pd.read_sql_query(\"SELECT COUNT(*) as count FROM job_runs\", conn).iloc[\n",
    "        0\n",
    "    ][\"count\"]\n",
    "    print(f\"Total job runs: {total_runs}\")\n",
    "\n",
    "    # Show recent runs\n",
    "    if total_runs > 0:\n",
    "        recent_runs = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT id, search_query, location_filter, status, job_count, created_at \n",
    "            FROM job_runs \n",
    "            ORDER BY created_at DESC \n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "            conn,\n",
    "        )\n",
    "        print(\"\\nRecent job runs:\")\n",
    "recent_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c5edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Enhanced Job Data Analysis with Company Intelligence\n",
      "Database contains: 20 recent jobs\n",
      "Columns: 21 (20-column structure with company info)\n",
      "\n",
      "Column names: ['id', 'company', 'company_size', 'company_followers', 'company_industry', 'title', 'location', 'work_location_type', 'level', 'salary_range', 'employment_type', 'job_function', 'industries', 'posted_time', 'applicants', 'job_id', 'date', 'parsing_link', 'job_posting_link', 'company_info_link', 'created_at']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_followers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company_industry",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "work_location_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_range",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industries",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "posted_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicants",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parsing_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_posting_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_info_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "dc3f7d7a-c0c5-4559-b2b2-9b680325d0dd",
       "rows": [
        [
         "0",
         "35e61256-69b2-4ce1-b739-14242c0bcb8a",
         "City of San Antonio",
         "10,001+ employees",
         "84,485 followers",
         "Government Administration",
         "Software Engineer II - Applications Support",
         "San Antonio, TX",
         "Remote",
         "Entry level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Government Administration",
         "4 days ago",
         "N/A",
         "4301002866",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301002866",
         "https://www.linkedin.com/jobs/view/software-engineer-ii-applications-support-at-city-of-san-antonio-4301002866?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/city-of-san-antonio",
         "2025-09-22 00:59:26"
        ],
        [
         "1",
         "27f20cda-2ef4-46d9-9a3c-093832714ed5",
         "HirePower Staffing Solution",
         "2-10 employees",
         null,
         "Information Services",
         "Big Data Developer",
         "San Antonio, TX",
         "Remote",
         "Entry level",
         "$30.00/hr - $35.00/hr",
         "Full-time",
         "Information Technology",
         "Information Services and Engineering Services",
         "2 days ago",
         "42 applicants",
         "4301417419",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301417419",
         "https://www.linkedin.com/jobs/view/big-data-developer-at-hirepower-staffing-solution-4301417419?trk=public_jobs_topcard-title",
         "https://in.linkedin.com/company/hirepower-staffing-solution",
         "2025-09-22 00:59:24"
        ],
        [
         "2",
         "76825c0c-494c-4f4d-8cd8-52328f6cbf59",
         "City of San Antonio",
         "10,001+ employees",
         "84,485 followers",
         "Government Administration",
         "IT Data Scientist II (Integrated Community Safety Office)",
         "San Antonio, TX",
         "Remote",
         "Entry level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Government Administration",
         "4 days ago",
         "N/A",
         "4301009186",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301009186",
         "https://www.linkedin.com/jobs/view/it-data-scientist-ii-integrated-community-safety-office-at-city-of-san-antonio-4301009186?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/city-of-san-antonio",
         "2025-09-22 00:59:22"
        ],
        [
         "3",
         "e0187fb0-7079-4e29-a928-7111b3746665",
         "KPMG US",
         null,
         null,
         null,
         "Senior Associate, Automation and AI Solutions",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         null,
         "Full-time",
         "General Business",
         "Financial Services",
         "1 day ago",
         "N/A",
         "4292658257",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4292658257",
         "https://www.linkedin.com/jobs/view/senior-associate-automation-and-ai-solutions-at-kpmg-us-4292658257?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/kpmg-us",
         "2025-09-22 00:59:19"
        ],
        [
         "4",
         "14ea5fe6-d706-4e3b-a101-9c09224e6d4f",
         "Shrive Technologies",
         null,
         null,
         null,
         "Automation Test Lead",
         "San Antonio, TX",
         "On-site",
         "Mid-Senior level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "IT Services and IT Consulting",
         "3 days ago",
         "N/A",
         "4302803923",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302803923",
         "https://www.linkedin.com/jobs/view/automation-test-lead-at-shrive-technologies-4302803923?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/shrive-technologies",
         "2025-09-22 00:59:17"
        ],
        [
         "5",
         "3c72b4a4-c24d-4232-a780-31d8bf6de4ec",
         "Shrive Technologies",
         null,
         null,
         null,
         "Snowflake, DBT",
         "San Antonio, TX",
         "On-site",
         "Not Applicable",
         null,
         "Full-time",
         "Other",
         "IT Services and IT Consulting",
         "5 hours ago",
         "N/A",
         "4303909259",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303909259",
         "https://www.linkedin.com/jobs/view/snowflake-dbt-at-shrive-technologies-4303909259?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/shrive-technologies",
         "2025-09-22 00:59:14"
        ],
        [
         "6",
         "d6825c6c-c32d-4a8f-81cb-50c113d455ac",
         "Oscar",
         "51-200 employees",
         "271,176 followers",
         "Staffing and Recruiting",
         "Data Scientist",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         "$90,000.00/yr - $170,000.00/yr",
         "Full-time",
         "Information Technology",
         "Data Security Software Products",
         "4 days ago",
         "N/A",
         "4300335856",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300335856",
         "https://www.linkedin.com/jobs/view/data-scientist-at-oscar-4300335856?trk=public_jobs_topcard-title",
         "https://uk.linkedin.com/company/oscar",
         "2025-09-22 00:59:11"
        ],
        [
         "7",
         "95440d6f-a13f-46e8-85c2-69edaa62c476",
         "E-Solutions",
         null,
         null,
         null,
         "Lead Software Engineer",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Contract",
         "Information Technology",
         "IT Services and IT Consulting",
         "2 days ago",
         "38 applicants",
         "4303055635",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303055635",
         "https://www.linkedin.com/jobs/view/lead-software-engineer-at-e-solutions-4303055635?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/e-solutions-inc",
         "2025-09-22 00:59:09"
        ],
        [
         "8",
         "25d43cb4-bfa6-46f8-8904-55c88e1d8e1d",
         "City of San Antonio",
         "10,001+ employees",
         "84,485 followers",
         "Government Administration",
         "Data Analyst",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Information Technology",
         "Government Administration",
         "4 days ago",
         "39 applicants",
         "4301015235",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301015235",
         "https://www.linkedin.com/jobs/view/data-analyst-at-city-of-san-antonio-4301015235?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/city-of-san-antonio",
         "2025-09-22 00:59:07"
        ],
        [
         "9",
         "563d2bfa-ba38-45f0-b744-6e013a14eb31",
         "Frost",
         null,
         null,
         null,
         "Engineer II - AI",
         "San Antonio, TX",
         "Hybrid",
         "Associate",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Financial Services",
         "4 days ago",
         "158 applicants",
         "4300348294",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300348294",
         "https://www.linkedin.com/jobs/view/engineer-ii-ai-at-frost-4300348294?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/frostbank",
         "2025-09-22 00:59:05"
        ],
        [
         "10",
         "cd2233df-dac6-4e5b-95d0-94c0a2626de5",
         "Robert Half",
         null,
         null,
         null,
         "Technical Engineer",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         "$28.50/hr - $33.00/hr",
         "Temporary",
         "Information Technology",
         "Staffing and Recruiting",
         "5 days ago",
         "N/A",
         "4301290800",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301290800",
         "https://www.linkedin.com/jobs/view/technical-engineer-at-robert-half-4301290800?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/robert-half-international",
         "2025-09-22 00:59:03"
        ],
        [
         "11",
         "696434dc-2b2b-4b3c-97a4-eadbb63b820d",
         "Frost",
         null,
         null,
         null,
         "Engineer I - AI",
         "San Antonio, TX",
         "On-site",
         "Associate",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Financial Services",
         "4 days ago",
         "N/A",
         "4300356224",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300356224",
         "https://www.linkedin.com/jobs/view/engineer-i-ai-at-frost-4300356224?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/frostbank",
         "2025-09-22 00:59:01"
        ],
        [
         "12",
         "20579c2e-23cc-4772-8af0-1d97f8f3603d",
         "H-E-B",
         null,
         null,
         null,
         "Sr Data Scientist - Demand Forecasting",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Retail",
         "5 days ago",
         "29 applicants",
         "4301532668",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301532668",
         "https://www.linkedin.com/jobs/view/sr-data-scientist-demand-forecasting-at-h-e-b-4301532668?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/heb",
         "2025-09-22 00:59:00"
        ],
        [
         "13",
         "945eb79c-1e4f-4a2f-b18a-be8e1848a603",
         "H-E-B",
         null,
         null,
         null,
         "Software Engineer II - Public Cloud Engineering",
         "San Antonio, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Retail",
         "6 days ago",
         "105 applicants",
         "4300773476",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300773476",
         "https://www.linkedin.com/jobs/view/software-engineer-ii-public-cloud-engineering-at-h-e-b-4300773476?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/heb",
         "2025-09-22 00:58:57"
        ],
        [
         "14",
         "c874a53e-86d9-49df-acf4-0e546bb8aa10",
         "Trust In SODA",
         "11-50 employees",
         "320,112 followers",
         "Staffing and Recruiting",
         "Forward Deployed Engineer",
         "San Francisco Bay Area",
         "On-site",
         "Mid-Senior level",
         "$150,000.00/yr - $300,000.00/yr",
         "Full-time",
         "Engineering",
         "Software Development",
         "4 days ago",
         "N/A",
         "4301778390",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301778390",
         "https://www.linkedin.com/jobs/view/forward-deployed-engineer-at-trust-in-soda-4301778390?trk=public_jobs_topcard-title",
         "https://uk.linkedin.com/company/trust-in-soda",
         "2025-09-22 00:58:55"
        ],
        [
         "15",
         "43a9b9ba-9f4a-4efc-9b19-5ca5d3ff9914",
         "Mindrift",
         "501-1,000 employees",
         "572,643 followers",
         "Technology, Information and Internet",
         "Freelance Physicist with Python - AI Trainer",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Part-time",
         "Other",
         "IT Services and IT Consulting",
         "5 days ago",
         "N/A",
         "4301540476",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301540476",
         "https://www.linkedin.com/jobs/view/freelance-physicist-with-python-ai-trainer-at-mindrift-4301540476?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/mindrift-ai",
         "2025-09-22 00:58:53"
        ],
        [
         "16",
         "4dad0d04-e361-4206-ad39-47770c93e21b",
         "Mindrift",
         "501-1,000 employees",
         "572,643 followers",
         "Technology, Information and Internet",
         "Freelance Mathematics Expert with Python - AI Trainer",
         "San Antonio, TX",
         "Remote",
         "Entry level",
         null,
         "Part-time",
         "Other",
         "IT Services and IT Consulting",
         "5 days ago",
         "N/A",
         "4301525510",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301525510",
         "https://www.linkedin.com/jobs/view/freelance-mathematics-expert-with-python-ai-trainer-at-mindrift-4301525510?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/mindrift-ai",
         "2025-09-22 00:58:52"
        ],
        [
         "17",
         "38dac730-cee8-4020-917b-5bf826d588b0",
         "Shrive Technologies",
         null,
         null,
         null,
         "Python Developer",
         "San Jose, TX",
         "On-site",
         "Entry level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "IT Services and IT Consulting",
         "5 hours ago",
         "N/A",
         "4303595423",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303595423",
         "https://www.linkedin.com/jobs/view/python-developer-at-shrive-technologies-4303595423?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/shrive-technologies",
         "2025-09-22 00:58:50"
        ],
        [
         "18",
         "aa439cb4-31cb-45c5-bd90-e0881794b136",
         "Frost",
         null,
         null,
         null,
         "Engineer III - AI",
         "San Antonio, TX",
         "On-site",
         "Associate",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Financial Services",
         "4 days ago",
         "73 applicants",
         "4300374911",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300374911",
         "https://www.linkedin.com/jobs/view/engineer-iii-ai-at-frost-4300374911?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/frostbank",
         "2025-09-22 00:58:49"
        ],
        [
         "19",
         "2effa6e8-c999-43f6-8dab-14d0e3e8729f",
         "H-E-B",
         null,
         null,
         null,
         "Sr Data Scientist - ML Engineering",
         "San Antonio, TX",
         "Remote",
         "Mid-Senior level",
         null,
         "Full-time",
         "Engineering and Information Technology",
         "Retail",
         "5 days ago",
         "78 applicants",
         "4290928268",
         "2025-09-21",
         "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290928268",
         "https://www.linkedin.com/jobs/view/sr-data-scientist-ml-engineering-at-h-e-b-4290928268?trk=public_jobs_topcard-title",
         "https://www.linkedin.com/company/heb",
         "2025-09-22 00:58:45"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_followers</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>work_location_type</th>\n",
       "      <th>level</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>...</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>posted_time</th>\n",
       "      <th>applicants</th>\n",
       "      <th>job_id</th>\n",
       "      <th>date</th>\n",
       "      <th>parsing_link</th>\n",
       "      <th>job_posting_link</th>\n",
       "      <th>company_info_link</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35e61256-69b2-4ce1-b739-14242c0bcb8a</td>\n",
       "      <td>City of San Antonio</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>84,485 followers</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>Software Engineer II - Applications Support</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4301002866</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>https://www.linkedin.com/company/city-of-san-a...</td>\n",
       "      <td>2025-09-22 00:59:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27f20cda-2ef4-46d9-9a3c-093832714ed5</td>\n",
       "      <td>HirePower Staffing Solution</td>\n",
       "      <td>2-10 employees</td>\n",
       "      <td>None</td>\n",
       "      <td>Information Services</td>\n",
       "      <td>Big Data Developer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$30.00/hr - $35.00/hr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Information Services and Engineering Services</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>42 applicants</td>\n",
       "      <td>4301417419</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/big-data-de...</td>\n",
       "      <td>https://in.linkedin.com/company/hirepower-staf...</td>\n",
       "      <td>2025-09-22 00:59:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76825c0c-494c-4f4d-8cd8-52328f6cbf59</td>\n",
       "      <td>City of San Antonio</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>84,485 followers</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>IT Data Scientist II (Integrated Community Saf...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4301009186</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/it-data-sci...</td>\n",
       "      <td>https://www.linkedin.com/company/city-of-san-a...</td>\n",
       "      <td>2025-09-22 00:59:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e0187fb0-7079-4e29-a928-7111b3746665</td>\n",
       "      <td>KPMG US</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Associate, Automation and AI Solutions</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>General Business</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4292658257</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-asso...</td>\n",
       "      <td>https://www.linkedin.com/company/kpmg-us</td>\n",
       "      <td>2025-09-22 00:59:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14ea5fe6-d706-4e3b-a101-9c09224e6d4f</td>\n",
       "      <td>Shrive Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Automation Test Lead</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4302803923</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/automation-...</td>\n",
       "      <td>https://www.linkedin.com/company/shrive-techno...</td>\n",
       "      <td>2025-09-22 00:59:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3c72b4a4-c24d-4232-a780-31d8bf6de4ec</td>\n",
       "      <td>Shrive Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Snowflake, DBT</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Other</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4303909259</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/snowflake-d...</td>\n",
       "      <td>https://www.linkedin.com/company/shrive-techno...</td>\n",
       "      <td>2025-09-22 00:59:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d6825c6c-c32d-4a8f-81cb-50c113d455ac</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>51-200 employees</td>\n",
       "      <td>271,176 followers</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$90,000.00/yr - $170,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Data Security Software Products</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4300335856</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>https://uk.linkedin.com/company/oscar</td>\n",
       "      <td>2025-09-22 00:59:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95440d6f-a13f-46e8-85c2-69edaa62c476</td>\n",
       "      <td>E-Solutions</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lead Software Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>38 applicants</td>\n",
       "      <td>4303055635</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-softwa...</td>\n",
       "      <td>https://www.linkedin.com/company/e-solutions-inc</td>\n",
       "      <td>2025-09-22 00:59:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25d43cb4-bfa6-46f8-8904-55c88e1d8e1d</td>\n",
       "      <td>City of San Antonio</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>84,485 followers</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Government Administration</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>39 applicants</td>\n",
       "      <td>4301015235</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>https://www.linkedin.com/company/city-of-san-a...</td>\n",
       "      <td>2025-09-22 00:59:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>563d2bfa-ba38-45f0-b744-6e013a14eb31</td>\n",
       "      <td>Frost</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Engineer II - AI</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Associate</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>158 applicants</td>\n",
       "      <td>4300348294</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/engineer-ii...</td>\n",
       "      <td>https://www.linkedin.com/company/frostbank</td>\n",
       "      <td>2025-09-22 00:59:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cd2233df-dac6-4e5b-95d0-94c0a2626de5</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Technical Engineer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$28.50/hr - $33.00/hr</td>\n",
       "      <td>...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4301290800</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/technical-e...</td>\n",
       "      <td>https://www.linkedin.com/company/robert-half-i...</td>\n",
       "      <td>2025-09-22 00:59:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>696434dc-2b2b-4b3c-97a4-eadbb63b820d</td>\n",
       "      <td>Frost</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Engineer I - AI</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Associate</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4300356224</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/engineer-i-...</td>\n",
       "      <td>https://www.linkedin.com/company/frostbank</td>\n",
       "      <td>2025-09-22 00:59:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20579c2e-23cc-4772-8af0-1d97f8f3603d</td>\n",
       "      <td>H-E-B</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr Data Scientist - Demand Forecasting</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>29 applicants</td>\n",
       "      <td>4301532668</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-data-sci...</td>\n",
       "      <td>https://www.linkedin.com/company/heb</td>\n",
       "      <td>2025-09-22 00:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945eb79c-1e4f-4a2f-b18a-be8e1848a603</td>\n",
       "      <td>H-E-B</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Software Engineer II - Public Cloud Engineering</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Retail</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>105 applicants</td>\n",
       "      <td>4300773476</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>https://www.linkedin.com/company/heb</td>\n",
       "      <td>2025-09-22 00:58:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c874a53e-86d9-49df-acf4-0e546bb8aa10</td>\n",
       "      <td>Trust In SODA</td>\n",
       "      <td>11-50 employees</td>\n",
       "      <td>320,112 followers</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>Forward Deployed Engineer</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$150,000.00/yr - $300,000.00/yr</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4301778390</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/forward-dep...</td>\n",
       "      <td>https://uk.linkedin.com/company/trust-in-soda</td>\n",
       "      <td>2025-09-22 00:58:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43a9b9ba-9f4a-4efc-9b19-5ca5d3ff9914</td>\n",
       "      <td>Mindrift</td>\n",
       "      <td>501-1,000 employees</td>\n",
       "      <td>572,643 followers</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>Freelance Physicist with Python - AI Trainer</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Other</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4301540476</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/freelance-p...</td>\n",
       "      <td>https://www.linkedin.com/company/mindrift-ai</td>\n",
       "      <td>2025-09-22 00:58:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4dad0d04-e361-4206-ad39-47770c93e21b</td>\n",
       "      <td>Mindrift</td>\n",
       "      <td>501-1,000 employees</td>\n",
       "      <td>572,643 followers</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>Freelance Mathematics Expert with Python - AI ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Other</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4301525510</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/freelance-m...</td>\n",
       "      <td>https://www.linkedin.com/company/mindrift-ai</td>\n",
       "      <td>2025-09-22 00:58:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38dac730-cee8-4020-917b-5bf826d588b0</td>\n",
       "      <td>Shrive Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Python Developer</td>\n",
       "      <td>San Jose, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4303595423</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/python-deve...</td>\n",
       "      <td>https://www.linkedin.com/company/shrive-techno...</td>\n",
       "      <td>2025-09-22 00:58:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aa439cb4-31cb-45c5-bd90-e0881794b136</td>\n",
       "      <td>Frost</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Engineer III - AI</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Associate</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>73 applicants</td>\n",
       "      <td>4300374911</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/engineer-ii...</td>\n",
       "      <td>https://www.linkedin.com/company/frostbank</td>\n",
       "      <td>2025-09-22 00:58:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2effa6e8-c999-43f6-8dab-14d0e3e8729f</td>\n",
       "      <td>H-E-B</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr Data Scientist - ML Engineering</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>78 applicants</td>\n",
       "      <td>4290928268</td>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-data-sci...</td>\n",
       "      <td>https://www.linkedin.com/company/heb</td>\n",
       "      <td>2025-09-22 00:58:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id                      company  \\\n",
       "0   35e61256-69b2-4ce1-b739-14242c0bcb8a          City of San Antonio   \n",
       "1   27f20cda-2ef4-46d9-9a3c-093832714ed5  HirePower Staffing Solution   \n",
       "2   76825c0c-494c-4f4d-8cd8-52328f6cbf59          City of San Antonio   \n",
       "3   e0187fb0-7079-4e29-a928-7111b3746665                      KPMG US   \n",
       "4   14ea5fe6-d706-4e3b-a101-9c09224e6d4f          Shrive Technologies   \n",
       "5   3c72b4a4-c24d-4232-a780-31d8bf6de4ec          Shrive Technologies   \n",
       "6   d6825c6c-c32d-4a8f-81cb-50c113d455ac                        Oscar   \n",
       "7   95440d6f-a13f-46e8-85c2-69edaa62c476                  E-Solutions   \n",
       "8   25d43cb4-bfa6-46f8-8904-55c88e1d8e1d          City of San Antonio   \n",
       "9   563d2bfa-ba38-45f0-b744-6e013a14eb31                        Frost   \n",
       "10  cd2233df-dac6-4e5b-95d0-94c0a2626de5                  Robert Half   \n",
       "11  696434dc-2b2b-4b3c-97a4-eadbb63b820d                        Frost   \n",
       "12  20579c2e-23cc-4772-8af0-1d97f8f3603d                        H-E-B   \n",
       "13  945eb79c-1e4f-4a2f-b18a-be8e1848a603                        H-E-B   \n",
       "14  c874a53e-86d9-49df-acf4-0e546bb8aa10                Trust In SODA   \n",
       "15  43a9b9ba-9f4a-4efc-9b19-5ca5d3ff9914                     Mindrift   \n",
       "16  4dad0d04-e361-4206-ad39-47770c93e21b                     Mindrift   \n",
       "17  38dac730-cee8-4020-917b-5bf826d588b0          Shrive Technologies   \n",
       "18  aa439cb4-31cb-45c5-bd90-e0881794b136                        Frost   \n",
       "19  2effa6e8-c999-43f6-8dab-14d0e3e8729f                        H-E-B   \n",
       "\n",
       "           company_size  company_followers  \\\n",
       "0     10,001+ employees   84,485 followers   \n",
       "1        2-10 employees               None   \n",
       "2     10,001+ employees   84,485 followers   \n",
       "3                  None               None   \n",
       "4                  None               None   \n",
       "5                  None               None   \n",
       "6      51-200 employees  271,176 followers   \n",
       "7                  None               None   \n",
       "8     10,001+ employees   84,485 followers   \n",
       "9                  None               None   \n",
       "10                 None               None   \n",
       "11                 None               None   \n",
       "12                 None               None   \n",
       "13                 None               None   \n",
       "14      11-50 employees  320,112 followers   \n",
       "15  501-1,000 employees  572,643 followers   \n",
       "16  501-1,000 employees  572,643 followers   \n",
       "17                 None               None   \n",
       "18                 None               None   \n",
       "19                 None               None   \n",
       "\n",
       "                        company_industry  \\\n",
       "0              Government Administration   \n",
       "1                   Information Services   \n",
       "2              Government Administration   \n",
       "3                                   None   \n",
       "4                                   None   \n",
       "5                                   None   \n",
       "6                Staffing and Recruiting   \n",
       "7                                   None   \n",
       "8              Government Administration   \n",
       "9                                   None   \n",
       "10                                  None   \n",
       "11                                  None   \n",
       "12                                  None   \n",
       "13                                  None   \n",
       "14               Staffing and Recruiting   \n",
       "15  Technology, Information and Internet   \n",
       "16  Technology, Information and Internet   \n",
       "17                                  None   \n",
       "18                                  None   \n",
       "19                                  None   \n",
       "\n",
       "                                                title                location  \\\n",
       "0         Software Engineer II - Applications Support         San Antonio, TX   \n",
       "1                                  Big Data Developer         San Antonio, TX   \n",
       "2   IT Data Scientist II (Integrated Community Saf...         San Antonio, TX   \n",
       "3       Senior Associate, Automation and AI Solutions         San Antonio, TX   \n",
       "4                                Automation Test Lead         San Antonio, TX   \n",
       "5                                      Snowflake, DBT         San Antonio, TX   \n",
       "6                                      Data Scientist         San Antonio, TX   \n",
       "7                              Lead Software Engineer         San Antonio, TX   \n",
       "8                                        Data Analyst         San Antonio, TX   \n",
       "9                                    Engineer II - AI         San Antonio, TX   \n",
       "10                                 Technical Engineer         San Antonio, TX   \n",
       "11                                    Engineer I - AI         San Antonio, TX   \n",
       "12             Sr Data Scientist - Demand Forecasting         San Antonio, TX   \n",
       "13    Software Engineer II - Public Cloud Engineering         San Antonio, TX   \n",
       "14                          Forward Deployed Engineer  San Francisco Bay Area   \n",
       "15       Freelance Physicist with Python - AI Trainer         San Antonio, TX   \n",
       "16  Freelance Mathematics Expert with Python - AI ...         San Antonio, TX   \n",
       "17                                   Python Developer            San Jose, TX   \n",
       "18                                  Engineer III - AI         San Antonio, TX   \n",
       "19                 Sr Data Scientist - ML Engineering         San Antonio, TX   \n",
       "\n",
       "   work_location_type             level                     salary_range  ...  \\\n",
       "0              Remote       Entry level                             None  ...   \n",
       "1              Remote       Entry level            $30.00/hr - $35.00/hr  ...   \n",
       "2              Remote       Entry level                             None  ...   \n",
       "3             On-site  Mid-Senior level                             None  ...   \n",
       "4             On-site  Mid-Senior level                             None  ...   \n",
       "5             On-site    Not Applicable                             None  ...   \n",
       "6             On-site       Entry level   $90,000.00/yr - $170,000.00/yr  ...   \n",
       "7              Remote  Mid-Senior level                             None  ...   \n",
       "8             On-site       Entry level                             None  ...   \n",
       "9              Hybrid         Associate                             None  ...   \n",
       "10            On-site       Entry level            $28.50/hr - $33.00/hr  ...   \n",
       "11            On-site         Associate                             None  ...   \n",
       "12             Remote  Mid-Senior level                             None  ...   \n",
       "13            On-site       Entry level                             None  ...   \n",
       "14            On-site  Mid-Senior level  $150,000.00/yr - $300,000.00/yr  ...   \n",
       "15             Remote  Mid-Senior level                             None  ...   \n",
       "16             Remote       Entry level                             None  ...   \n",
       "17            On-site       Entry level                             None  ...   \n",
       "18            On-site         Associate                             None  ...   \n",
       "19             Remote  Mid-Senior level                             None  ...   \n",
       "\n",
       "                              job_function  \\\n",
       "0   Engineering and Information Technology   \n",
       "1                   Information Technology   \n",
       "2   Engineering and Information Technology   \n",
       "3                         General Business   \n",
       "4   Engineering and Information Technology   \n",
       "5                                    Other   \n",
       "6                   Information Technology   \n",
       "7                   Information Technology   \n",
       "8                   Information Technology   \n",
       "9   Engineering and Information Technology   \n",
       "10                  Information Technology   \n",
       "11  Engineering and Information Technology   \n",
       "12  Engineering and Information Technology   \n",
       "13  Engineering and Information Technology   \n",
       "14                             Engineering   \n",
       "15                                   Other   \n",
       "16                                   Other   \n",
       "17  Engineering and Information Technology   \n",
       "18  Engineering and Information Technology   \n",
       "19  Engineering and Information Technology   \n",
       "\n",
       "                                       industries  posted_time  \\\n",
       "0                       Government Administration   4 days ago   \n",
       "1   Information Services and Engineering Services   2 days ago   \n",
       "2                       Government Administration   4 days ago   \n",
       "3                              Financial Services    1 day ago   \n",
       "4                   IT Services and IT Consulting   3 days ago   \n",
       "5                   IT Services and IT Consulting  5 hours ago   \n",
       "6                 Data Security Software Products   4 days ago   \n",
       "7                   IT Services and IT Consulting   2 days ago   \n",
       "8                       Government Administration   4 days ago   \n",
       "9                              Financial Services   4 days ago   \n",
       "10                        Staffing and Recruiting   5 days ago   \n",
       "11                             Financial Services   4 days ago   \n",
       "12                                         Retail   5 days ago   \n",
       "13                                         Retail   6 days ago   \n",
       "14                           Software Development   4 days ago   \n",
       "15                  IT Services and IT Consulting   5 days ago   \n",
       "16                  IT Services and IT Consulting   5 days ago   \n",
       "17                  IT Services and IT Consulting  5 hours ago   \n",
       "18                             Financial Services   4 days ago   \n",
       "19                                         Retail   5 days ago   \n",
       "\n",
       "        applicants      job_id        date  \\\n",
       "0              N/A  4301002866  2025-09-21   \n",
       "1    42 applicants  4301417419  2025-09-21   \n",
       "2              N/A  4301009186  2025-09-21   \n",
       "3              N/A  4292658257  2025-09-21   \n",
       "4              N/A  4302803923  2025-09-21   \n",
       "5              N/A  4303909259  2025-09-21   \n",
       "6              N/A  4300335856  2025-09-21   \n",
       "7    38 applicants  4303055635  2025-09-21   \n",
       "8    39 applicants  4301015235  2025-09-21   \n",
       "9   158 applicants  4300348294  2025-09-21   \n",
       "10             N/A  4301290800  2025-09-21   \n",
       "11             N/A  4300356224  2025-09-21   \n",
       "12   29 applicants  4301532668  2025-09-21   \n",
       "13  105 applicants  4300773476  2025-09-21   \n",
       "14             N/A  4301778390  2025-09-21   \n",
       "15             N/A  4301540476  2025-09-21   \n",
       "16             N/A  4301525510  2025-09-21   \n",
       "17             N/A  4303595423  2025-09-21   \n",
       "18   73 applicants  4300374911  2025-09-21   \n",
       "19   78 applicants  4290928268  2025-09-21   \n",
       "\n",
       "                                         parsing_link  \\\n",
       "0   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "1   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "2   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "3   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "4   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "5   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "6   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "7   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "8   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "9   https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "10  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "11  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "12  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "13  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "14  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "15  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "16  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "17  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "18  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "19  https://www.linkedin.com/jobs-guest/jobs/api/j...   \n",
       "\n",
       "                                     job_posting_link  \\\n",
       "0   https://www.linkedin.com/jobs/view/software-en...   \n",
       "1   https://www.linkedin.com/jobs/view/big-data-de...   \n",
       "2   https://www.linkedin.com/jobs/view/it-data-sci...   \n",
       "3   https://www.linkedin.com/jobs/view/senior-asso...   \n",
       "4   https://www.linkedin.com/jobs/view/automation-...   \n",
       "5   https://www.linkedin.com/jobs/view/snowflake-d...   \n",
       "6   https://www.linkedin.com/jobs/view/data-scient...   \n",
       "7   https://www.linkedin.com/jobs/view/lead-softwa...   \n",
       "8   https://www.linkedin.com/jobs/view/data-analys...   \n",
       "9   https://www.linkedin.com/jobs/view/engineer-ii...   \n",
       "10  https://www.linkedin.com/jobs/view/technical-e...   \n",
       "11  https://www.linkedin.com/jobs/view/engineer-i-...   \n",
       "12  https://www.linkedin.com/jobs/view/sr-data-sci...   \n",
       "13  https://www.linkedin.com/jobs/view/software-en...   \n",
       "14  https://www.linkedin.com/jobs/view/forward-dep...   \n",
       "15  https://www.linkedin.com/jobs/view/freelance-p...   \n",
       "16  https://www.linkedin.com/jobs/view/freelance-m...   \n",
       "17  https://www.linkedin.com/jobs/view/python-deve...   \n",
       "18  https://www.linkedin.com/jobs/view/engineer-ii...   \n",
       "19  https://www.linkedin.com/jobs/view/sr-data-sci...   \n",
       "\n",
       "                                    company_info_link           created_at  \n",
       "0   https://www.linkedin.com/company/city-of-san-a...  2025-09-22 00:59:26  \n",
       "1   https://in.linkedin.com/company/hirepower-staf...  2025-09-22 00:59:24  \n",
       "2   https://www.linkedin.com/company/city-of-san-a...  2025-09-22 00:59:22  \n",
       "3            https://www.linkedin.com/company/kpmg-us  2025-09-22 00:59:19  \n",
       "4   https://www.linkedin.com/company/shrive-techno...  2025-09-22 00:59:17  \n",
       "5   https://www.linkedin.com/company/shrive-techno...  2025-09-22 00:59:14  \n",
       "6               https://uk.linkedin.com/company/oscar  2025-09-22 00:59:11  \n",
       "7    https://www.linkedin.com/company/e-solutions-inc  2025-09-22 00:59:09  \n",
       "8   https://www.linkedin.com/company/city-of-san-a...  2025-09-22 00:59:07  \n",
       "9          https://www.linkedin.com/company/frostbank  2025-09-22 00:59:05  \n",
       "10  https://www.linkedin.com/company/robert-half-i...  2025-09-22 00:59:03  \n",
       "11         https://www.linkedin.com/company/frostbank  2025-09-22 00:59:01  \n",
       "12               https://www.linkedin.com/company/heb  2025-09-22 00:59:00  \n",
       "13               https://www.linkedin.com/company/heb  2025-09-22 00:58:57  \n",
       "14      https://uk.linkedin.com/company/trust-in-soda  2025-09-22 00:58:55  \n",
       "15       https://www.linkedin.com/company/mindrift-ai  2025-09-22 00:58:53  \n",
       "16       https://www.linkedin.com/company/mindrift-ai  2025-09-22 00:58:52  \n",
       "17  https://www.linkedin.com/company/shrive-techno...  2025-09-22 00:58:50  \n",
       "18         https://www.linkedin.com/company/frostbank  2025-09-22 00:58:49  \n",
       "19               https://www.linkedin.com/company/heb  2025-09-22 00:58:45  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 20 most recent jobs with enhanced data structure including company information\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get the latest job_run created_at timestamp\n",
    "    latest_run_query = (\n",
    "        \"SELECT MAX(created_at) as latest_run FROM job_runs WHERE status = 'completed'\"\n",
    "    )\n",
    "    latest_run = pd.read_sql_query(latest_run_query, conn).iloc[0][\"latest_run\"]\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        company,\n",
    "        company_size,\n",
    "        company_followers,\n",
    "        company_industry,\n",
    "        title,\n",
    "        location,\n",
    "        work_location_type,\n",
    "        level,\n",
    "        salary_range,\n",
    "        employment_type,\n",
    "        job_function,\n",
    "        industries,\n",
    "        posted_time,\n",
    "        applicants,\n",
    "        job_id,\n",
    "        date,\n",
    "        parsing_link,\n",
    "        job_posting_link,\n",
    "        company_info_link,\n",
    "        created_at\n",
    "    FROM jobs \n",
    "    WHERE created_at > '{latest_run}'\n",
    "    ORDER BY created_at DESC \n",
    "    LIMIT 200\n",
    "    \"\"\"\n",
    "\n",
    "    top_jobs_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(f\"üìä Enhanced Job Data Analysis with Company Intelligence\")\n",
    "print(f\"Database contains: {len(top_jobs_df)} recent jobs\")\n",
    "print(f\"Columns: {top_jobs_df.shape[1]} (20-column structure with company info)\")\n",
    "print(f\"\\nColumn names: {list(top_jobs_df.columns)}\")\n",
    "top_jobs_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84df63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed information for each job with enhanced data including company info (limited output)\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED JOB LISTINGS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Limit to first 5 jobs to prevent excessive output\n",
    "    display_limit = min(5, len(top_jobs_df))\n",
    "    print(f\"Showing first {display_limit} of {len(top_jobs_df)} jobs:\\n\")\n",
    "\n",
    "    for idx in range(display_limit):\n",
    "        job = top_jobs_df.iloc[idx]\n",
    "        print(f\"üìã JOB #{idx + 1}\")\n",
    "        print(f\"Title: {job['title']}\")\n",
    "        print(f\"Company: {job['company']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_info = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_info.append(f\"üë• Size: {job['company_size']}\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_info.append(f\"üìä Followers: {job['company_followers']}\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_info.append(f\"üè≠ Industry: {job['company_industry']}\")\n",
    "\n",
    "        if company_info:\n",
    "            print(f\"üè¢ Company Info: {' | '.join(company_info)}\")\n",
    "\n",
    "        # Enhanced location information\n",
    "        if pd.notna(job[\"location\"]) and job[\"location\"]:\n",
    "            print(f\"üìç Location: {job['location']}\")\n",
    "\n",
    "        if pd.notna(job[\"work_location_type\"]) and job[\"work_location_type\"]:\n",
    "            # Use emoji for work type\n",
    "            work_type_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}\n",
    "            emoji = work_type_emoji.get(job[\"work_location_type\"], \"üìç\")\n",
    "            print(f\"{emoji} Work Type: {job['work_location_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"level\"]) and job[\"level\"]:\n",
    "            print(f\"üéØ Level: {job['level']}\")\n",
    "\n",
    "        if pd.notna(job[\"salary_range\"]) and job[\"salary_range\"]:\n",
    "            print(f\"üí∞ Salary: {job['salary_range']}\")\n",
    "\n",
    "        if pd.notna(job[\"employment_type\"]) and job[\"employment_type\"]:\n",
    "            print(f\"üìù Employment: {job['employment_type']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_function\"]) and job[\"job_function\"]:\n",
    "            print(f\"‚öôÔ∏è Function: {job['job_function']}\")\n",
    "\n",
    "        if pd.notna(job[\"industries\"]) and job[\"industries\"]:\n",
    "            print(f\"üè≠ Industries: {job['industries']}\")\n",
    "\n",
    "        if pd.notna(job[\"applicants\"]) and job[\"applicants\"]:\n",
    "            print(f\"üë• Applicants: {job['applicants']}\")\n",
    "\n",
    "        if pd.notna(job[\"posted_time\"]) and job[\"posted_time\"]:\n",
    "            print(f\"üìÖ Posted: {job['posted_time']}\")\n",
    "\n",
    "        if pd.notna(job[\"job_posting_link\"]) and job[\"job_posting_link\"]:\n",
    "            print(f\"üîó LinkedIn URL: {job['job_posting_link']}\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    if len(top_jobs_df) > display_limit:\n",
    "        print(f\"\\n... and {len(top_jobs_df) - display_limit} more jobs in the database\")\n",
    "        print(\"üí° Tip: Run the statistics cell below for a summary of all jobs\")\n",
    "\n",
    "else:\n",
    "    print(\"No jobs found in database. Run 'make run-parser' first to collect job data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced job statistics with location and company intelligence\n",
    "if not top_jobs_df.empty:\n",
    "    print(\"üìä ENHANCED JOB STATISTICS WITH LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Company distribution\n",
    "    company_counts = top_jobs_df[\"company\"].value_counts()\n",
    "    print(f\"\\nüè¢ Top Companies:\")\n",
    "    for company, count in company_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {company}: {count} job(s)\")\n",
    "\n",
    "    # NEW: Company intelligence analysis\n",
    "    print(f\"\\nüè¢ COMPANY INTELLIGENCE ANALYSIS:\")\n",
    "\n",
    "    # Company size analysis\n",
    "    company_size_data = top_jobs_df[\"company_size\"].dropna()\n",
    "    if not company_size_data.empty:\n",
    "        print(\n",
    "            f\"  üë• Company Size Info Available: {len(company_size_data)}/{len(top_jobs_df)} jobs ({len(company_size_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(f\"     Sample sizes: {', '.join(company_size_data.head(3).astype(str))}\")\n",
    "    else:\n",
    "        print(f\"  üë• Company Size Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company followers analysis\n",
    "    company_followers_data = top_jobs_df[\"company_followers\"].dropna()\n",
    "    if not company_followers_data.empty:\n",
    "        print(\n",
    "            f\"  üìä Company Followers Info: {len(company_followers_data)}/{len(top_jobs_df)} jobs ({len(company_followers_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"     Sample followers: {', '.join(company_followers_data.head(3).astype(str))}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"  üìä Company Followers Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Company industry analysis\n",
    "    company_industry_data = top_jobs_df[\"company_industry\"].dropna()\n",
    "    if not company_industry_data.empty:\n",
    "        print(\n",
    "            f\"  üè≠ Company Industry Info: {len(company_industry_data)}/{len(top_jobs_df)} jobs ({len(company_industry_data)/len(top_jobs_df)*100:.1f}%)\"\n",
    "        )\n",
    "        industry_counts = company_industry_data.value_counts().head(3)\n",
    "        print(f\"     Top industries: {', '.join(industry_counts.index)}\")\n",
    "    else:\n",
    "        print(f\"  üè≠ Company Industry Info: Not available (run parser to collect)\")\n",
    "\n",
    "    # Location distribution (enhanced)\n",
    "    location_counts = top_jobs_df[\"location\"].value_counts()\n",
    "    print(f\"\\nüìç Top Locations:\")\n",
    "    for location, count in location_counts.head().items():\n",
    "        print(f\"  ‚Ä¢ {location}: {count} job(s)\")\n",
    "\n",
    "    # Work location type analysis\n",
    "    if \"work_location_type\" in top_jobs_df.columns:\n",
    "        work_type_counts = top_jobs_df[\"work_location_type\"].value_counts(dropna=True)\n",
    "        print(f\"\\nüè† Work Location Types (Location Intelligence):\")\n",
    "        for work_type, count in work_type_counts.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            percentage = count / len(top_jobs_df) * 100\n",
    "            print(f\"  {emoji} {work_type}: {count} job(s) ({percentage:.1f}%)\")\n",
    "\n",
    "    # Experience level distribution\n",
    "    if \"level\" in top_jobs_df.columns:\n",
    "        level_counts = top_jobs_df[\"level\"].value_counts(dropna=True)\n",
    "        if not level_counts.empty:\n",
    "            print(f\"\\nüéØ Experience Levels:\")\n",
    "            for level, count in level_counts.items():\n",
    "                print(f\"  ‚Ä¢ {level}: {count} job(s)\")\n",
    "\n",
    "    # Employment type distribution\n",
    "    if \"employment_type\" in top_jobs_df.columns:\n",
    "        employment_counts = top_jobs_df[\"employment_type\"].value_counts(dropna=True)\n",
    "        if not employment_counts.empty:\n",
    "            print(f\"\\nüíº Employment Types:\")\n",
    "            for emp_type, count in employment_counts.items():\n",
    "                print(f\"  ‚Ä¢ {emp_type}: {count} job(s)\")\n",
    "\n",
    "    # Job function analysis\n",
    "    if \"job_function\" in top_jobs_df.columns:\n",
    "        function_counts = top_jobs_df[\"job_function\"].value_counts(dropna=True)\n",
    "        if not function_counts.empty:\n",
    "            print(f\"\\n‚öôÔ∏è Top Job Functions:\")\n",
    "            for function, count in function_counts.head().items():\n",
    "                print(f\"  ‚Ä¢ {function}: {count} job(s)\")\n",
    "\n",
    "    # Salary information availability\n",
    "    salary_jobs = top_jobs_df[\"salary_range\"].notna().sum()\n",
    "    print(\n",
    "        f\"\\nüí∞ Salary Information: {salary_jobs} out of {len(top_jobs_df)} jobs ({salary_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Applicant information\n",
    "    applicant_jobs = top_jobs_df[\"applicants\"].notna().sum()\n",
    "    print(\n",
    "        f\"üë• Applicant Count Available: {applicant_jobs} out of {len(top_jobs_df)} jobs ({applicant_jobs/len(top_jobs_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìà Data Quality Summary:\")\n",
    "    print(f\"  ‚úÖ All jobs have location intelligence classification\")\n",
    "    print(f\"  ‚úÖ Enhanced 20-column data structure with company info\")\n",
    "    print(f\"  ‚úÖ Company intelligence extraction available\")\n",
    "    print(f\"  ‚úÖ Comprehensive job metadata available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced salary analysis with location and company intelligence\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    salary_query = \"\"\"\n",
    "    SELECT title, company, company_size, company_followers, company_industry,\n",
    "           salary_range, location, work_location_type, level, employment_type\n",
    "    FROM jobs \n",
    "    WHERE salary_range IS NOT NULL AND salary_range != ''\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 15\n",
    "    \"\"\"\n",
    "\n",
    "    salary_jobs = pd.read_sql_query(salary_query, conn)\n",
    "\n",
    "if not salary_jobs.empty:\n",
    "    print(\"üí∞ JOBS WITH SALARY INFORMATION + LOCATION & COMPANY INTELLIGENCE\")\n",
    "    print(\"=\" * 75)\n",
    "    for idx, job in salary_jobs.iterrows():\n",
    "        # Work type emoji\n",
    "        work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            job[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "\n",
    "        print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "        print(f\"    üí∞ {job['salary_range']}\")\n",
    "        print(f\"    üìç {job['location']} | {work_emoji} {job['work_location_type']}\")\n",
    "\n",
    "        # NEW: Company information display\n",
    "        company_details = []\n",
    "        if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "            company_details.append(f\"üë• {job['company_size']} employees\")\n",
    "        if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "            company_details.append(f\"üìä {job['company_followers']} followers\")\n",
    "        if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "            company_details.append(f\"üè≠ {job['company_industry']}\")\n",
    "\n",
    "        if company_details:\n",
    "            print(f\"    üè¢ {' | '.join(company_details)}\")\n",
    "\n",
    "        if job[\"level\"]:\n",
    "            print(f\"    üéØ {job['level']}\")\n",
    "        if job[\"employment_type\"]:\n",
    "            print(f\"    üìù {job['employment_type']}\")\n",
    "        print()\n",
    "\n",
    "    # Salary analysis by work type\n",
    "    if \"work_location_type\" in salary_jobs.columns:\n",
    "        print(\"üìà SALARY ANALYSIS BY WORK TYPE\")\n",
    "        print(\"=\" * 40)\n",
    "        work_type_salary = salary_jobs.groupby(\"work_location_type\").size()\n",
    "        for work_type, count in work_type_salary.items():\n",
    "            emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                work_type, \"üìç\"\n",
    "            )\n",
    "            print(f\"{emoji} {work_type}: {count} jobs with salary info\")\n",
    "\n",
    "    # NEW: Company size analysis for salary jobs\n",
    "    print(f\"\\nüè¢ COMPANY SIZE ANALYSIS FOR SALARY JOBS\")\n",
    "    print(\"=\" * 45)\n",
    "    company_size_salary = salary_jobs[salary_jobs[\"company_size\"].notna()]\n",
    "    if not company_size_salary.empty:\n",
    "        print(\n",
    "            f\"üíº Jobs with both salary and company size data: {len(company_size_salary)}\"\n",
    "        )\n",
    "        for idx, job in company_size_salary.head(5).iterrows():\n",
    "            print(\n",
    "                f\"  ‚Ä¢ {job['company']}: {job['company_size']} employees | {job['salary_range']}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"üìä No jobs found with both salary and company size information\")\n",
    "        print(\n",
    "            \"üí° Run 'make run-parser' to collect fresh data with company intelligence\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(\"No jobs with salary information found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9879302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ LOCATION & COMPANY INTELLIGENCE SHOWCASE\n",
    "print(\"üåç LOCATION & COMPANY INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get location intelligence statistics\n",
    "    location_intel_query = \"\"\"\n",
    "    SELECT \n",
    "        location,\n",
    "        work_location_type,\n",
    "        COUNT(*) as job_count,\n",
    "        GROUP_CONCAT(DISTINCT company) as companies,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as companies_with_size,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as companies_with_industry\n",
    "    FROM jobs \n",
    "    WHERE location IS NOT NULL\n",
    "    GROUP BY location, work_location_type\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    location_intel_df = pd.read_sql_query(location_intel_query, conn)\n",
    "\n",
    "if not location_intel_df.empty:\n",
    "    print(\"üìä Location + Work Type + Company Intelligence Distribution:\")\n",
    "    for idx, row in location_intel_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        companies = row[\"companies\"].split(\",\") if row[\"companies\"] else []\n",
    "\n",
    "        print(\n",
    "            f\"{emoji} {row['location']} - {row['work_location_type']}: {row['job_count']} jobs\"\n",
    "        )\n",
    "        if len(companies) <= 3:\n",
    "            print(f\"    Companies: {', '.join(companies)}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"    Companies: {', '.join(companies[:3])}... (+{len(companies)-3} more)\"\n",
    "            )\n",
    "\n",
    "        # NEW: Company intelligence stats\n",
    "        company_intel_info = []\n",
    "        if row[\"companies_with_size\"] > 0:\n",
    "            company_intel_info.append(f\"üë• {row['companies_with_size']} with size data\")\n",
    "        if row[\"companies_with_industry\"] > 0:\n",
    "            company_intel_info.append(\n",
    "                f\"üè≠ {row['companies_with_industry']} with industry data\"\n",
    "            )\n",
    "\n",
    "        if company_intel_info:\n",
    "            print(f\"    Company Intel: {' | '.join(company_intel_info)}\")\n",
    "        print()\n",
    "\n",
    "    # Overall location intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        summary_query = \"\"\"\n",
    "        SELECT \n",
    "            work_location_type,\n",
    "            COUNT(*) as count,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM jobs), 1) as percentage\n",
    "        FROM jobs \n",
    "        WHERE work_location_type IS NOT NULL\n",
    "        GROUP BY work_location_type\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        summary_df = pd.read_sql_query(summary_query, conn)\n",
    "\n",
    "    print(\"üéØ WORK TYPE INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "            row[\"work_location_type\"], \"üìç\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{emoji} {row['work_location_type']:8s}: {row['count']:3d} jobs ({row['percentage']:5.1f}%)\"\n",
    "        )\n",
    "\n",
    "    # NEW: Company intelligence summary\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        company_intel_summary = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_jobs,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL THEN 1 END) as jobs_with_size,\n",
    "            COUNT(CASE WHEN company_followers IS NOT NULL THEN 1 END) as jobs_with_followers,\n",
    "            COUNT(CASE WHEN company_industry IS NOT NULL THEN 1 END) as jobs_with_industry,\n",
    "            COUNT(CASE WHEN company_size IS NOT NULL AND company_followers IS NOT NULL THEN 1 END) as jobs_with_both\n",
    "        FROM jobs\n",
    "        \"\"\"\n",
    "        company_stats = pd.read_sql_query(company_intel_summary, conn).iloc[0]\n",
    "\n",
    "    print(f\"\\nüè¢ COMPANY INTELLIGENCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    total = company_stats[\"total_jobs\"]\n",
    "    print(\n",
    "        f\"üë• Company Size Data:     {company_stats['jobs_with_size']:3d}/{total} jobs ({company_stats['jobs_with_size']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üìä Company Followers:     {company_stats['jobs_with_followers']:3d}/{total} jobs ({company_stats['jobs_with_followers']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üè≠ Company Industry:      {company_stats['jobs_with_industry']:3d}/{total} jobs ({company_stats['jobs_with_industry']/total*100:5.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"üéØ Complete Company Data: {company_stats['jobs_with_both']:3d}/{total} jobs ({company_stats['jobs_with_both']/total*100:5.1f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚ú® Enhanced Intelligence Features:\")\n",
    "    print(f\"   üéØ Automatic location extraction from job postings\")\n",
    "    print(f\"   ü§ñ AI-powered work type classification\")\n",
    "    print(f\"   üè¢ Company size, followers, and industry extraction\")\n",
    "    print(f\"   üìä Enhanced analytics with location and company data\")\n",
    "    print(f\"   üíæ 20-column output with integrated company information\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"No location data found. Run 'make run-parser' to collect jobs with location & company intelligence.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç QUICK COMPANY INTELLIGENCE CHECK\n",
    "print(\"üîç CURRENT COMPANY INTELLIGENCE COVERAGE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Get current state of company fields\n",
    "    coverage_query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_jobs,\n",
    "        COUNT(CASE WHEN company_size IS NOT NULL AND company_size != '' THEN 1 END) as jobs_with_size,\n",
    "        COUNT(CASE WHEN company_followers IS NOT NULL AND company_followers != '' THEN 1 END) as jobs_with_followers,\n",
    "        COUNT(CASE WHEN company_industry IS NOT NULL AND company_industry != '' THEN 1 END) as jobs_with_industry\n",
    "    FROM jobs\n",
    "    \"\"\"\n",
    "    coverage_stats = pd.read_sql_query(coverage_query, conn).iloc[0]\n",
    "\n",
    "    print(f\"üìä Database-wide Company Intelligence:\")\n",
    "    total = coverage_stats[\"total_jobs\"]\n",
    "    print(f\"   Total jobs: {total}\")\n",
    "    print(\n",
    "        f\"   üë• Company Size: {coverage_stats['jobs_with_size']} jobs ({coverage_stats['jobs_with_size']/total*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   üìä Company Followers: {coverage_stats['jobs_with_followers']} jobs ({coverage_stats['jobs_with_followers']/total*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   üè≠ Company Industry: {coverage_stats['jobs_with_industry']} jobs ({coverage_stats['jobs_with_industry']/total*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Show some examples of extracted company info\n",
    "    sample_query = \"\"\"\n",
    "    SELECT company, company_size, company_followers, company_industry, title\n",
    "    FROM jobs \n",
    "    WHERE (company_size IS NOT NULL AND company_size != '') \n",
    "       OR (company_followers IS NOT NULL AND company_followers != '')\n",
    "       OR (company_industry IS NOT NULL AND company_industry != '')\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    sample_companies = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "    print(f\"\\nüè¢ Examples of Company Intelligence:\")\n",
    "    for idx, row in sample_companies.iterrows():\n",
    "        print(f\"   {idx+1}. {row['company']}\")\n",
    "        if row[\"company_size\"]:\n",
    "            print(f\"      üë• Size: {row['company_size']}\")\n",
    "        if row[\"company_followers\"]:\n",
    "            print(f\"      üìä Followers: {row['company_followers']}\")\n",
    "        if row[\"company_industry\"]:\n",
    "            print(f\"      üè≠ Industry: {row['company_industry']}\")\n",
    "        print(f\"      Job: {row['title']}\")\n",
    "        print()\n",
    "\n",
    "print(f\"‚ú® The enhanced company parser successfully extracted information!\")\n",
    "print(f\"üí° To improve coverage further, run: make fix-company-info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27363121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä EXPORT & DATA VALIDATION\n",
    "print(\"üì§ CSV EXPORT WITH ENHANCED DATA + COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Export current job data to CSV in the main data folder\n",
    "csv_filename = db.export_jobs_to_csv(\"../data/notebook_analysis_export.csv\")\n",
    "print(f\"‚úÖ Jobs exported to: {csv_filename}\")\n",
    "\n",
    "# Validate the exported CSV structure\n",
    "if csv_filename:\n",
    "    import pandas as pd\n",
    "\n",
    "    exported_df = pd.read_csv(csv_filename)\n",
    "\n",
    "    print(f\"\\nüìã Export Validation:\")\n",
    "    print(f\"   Shape: {exported_df.shape}\")\n",
    "    print(f\"   Columns: {exported_df.shape[1]} (should be 21)\")\n",
    "\n",
    "    expected_columns = [\n",
    "        \"id\",\n",
    "        \"company\",\n",
    "        \"company_size\",\n",
    "        \"company_followers\",\n",
    "        \"company_industry\",\n",
    "        \"title\",\n",
    "        \"location\",\n",
    "        \"work_location_type\",\n",
    "        \"level\",\n",
    "        \"salary_range\",\n",
    "        \"content\",\n",
    "        \"employment_type\",\n",
    "        \"job_function\",\n",
    "        \"industries\",\n",
    "        \"posted_time\",\n",
    "        \"applicants\",\n",
    "        \"job_id\",\n",
    "        \"date\",\n",
    "        \"parsing_link\",\n",
    "        \"job_posting_link\",\n",
    "        \"company_info_link\",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n‚úÖ Column Validation:\")\n",
    "    missing_cols = set(expected_columns) - set(exported_df.columns)\n",
    "    extra_cols = set(exported_df.columns) - set(expected_columns)\n",
    "\n",
    "    if not missing_cols and not extra_cols:\n",
    "        print(\"   üéØ Perfect! All 21 expected columns present\")\n",
    "    else:\n",
    "        if missing_cols:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing columns: {missing_cols}\")\n",
    "        if extra_cols:\n",
    "            print(f\"   ‚ûï Extra columns: {extra_cols}\")\n",
    "\n",
    "    print(f\"\\nüìä Data Quality Check:\")\n",
    "    print(\n",
    "        f\"   Location data: {exported_df['location'].notna().sum()}/{len(exported_df)} jobs ({exported_df['location'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Work type data: {exported_df['work_location_type'].notna().sum()}/{len(exported_df)} jobs ({exported_df['work_location_type'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company data: {exported_df['company'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company size: {exported_df['company_size'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_size'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company followers: {exported_df['company_followers'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_followers'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Company industry: {exported_df['company_industry'].notna().sum()}/{len(exported_df)} jobs ({exported_df['company_industry'].notna().sum()/len(exported_df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Check if company_info_link column exists (since it was recently added)\n",
    "    if \"company_info_link\" in exported_df.columns:\n",
    "        company_link_count = exported_df[\"company_info_link\"].notna().sum()\n",
    "        print(\n",
    "            f\"   Company info link: {company_link_count}/{len(exported_df)} jobs ({company_link_count/len(exported_df)*100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # DIAGNOSTIC: Show why company_info_link is mostly empty\n",
    "        if company_link_count == 0:\n",
    "            print(f\"\\nüîç DIAGNOSTIC: Company Info Link Issue\")\n",
    "            print(f\"   ‚ùå No jobs have company_info_link values\")\n",
    "            print(\n",
    "                f\"   üîß Root Cause: Company URL extraction during parsing not working\"\n",
    "            )\n",
    "            print(f\"   üìã Technical Details:\")\n",
    "            print(\n",
    "                f\"      ‚Ä¢ Field implementation: ‚úÖ Complete (database schema, models, parser)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      ‚Ä¢ URL extraction: ‚ùå CSS selectors not finding company links on LinkedIn\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      ‚Ä¢ Solution: Update _extract_company_link() method in company_parser.py\"\n",
    "            )\n",
    "        elif company_link_count < len(exported_df) * 0.1:  # Less than 10%\n",
    "            print(f\"\\n‚ö†Ô∏è  DIAGNOSTIC: Low Company Info Link Coverage\")\n",
    "            print(f\"   üìä Only {company_link_count} jobs have company_info_link\")\n",
    "            print(\n",
    "                f\"   üîß Likely Issue: CSS selectors partially working but need improvement\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   üìã Recommendation: Review and update LinkedIn company link selectors\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"   Company info link: ‚ùå Column missing (database export needs update)\")\n",
    "\n",
    "    print(\n",
    "        f\"   Title data: {exported_df['title'].notna().sum()}/{len(exported_df)} jobs\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\nüéâ SUCCESS: Enhanced LinkedIn parser with location & company intelligence is working!\"\n",
    "    )\n",
    "    print(f\"   üíæ Database: data/jobs.db\")\n",
    "    print(f\"   üì§ Export: {csv_filename}\")\n",
    "    print(f\"   üéØ Use: make run-parser (to collect more jobs with company info)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\n",
    "    \"üöÄ ANALYSIS COMPLETE - Enhanced LinkedIn Parser with Company Intelligence Ready!\"\n",
    ")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1107ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ RUN PARSER + CLEANER BACK TO BACK\n",
    "print(\"üöÄ RUNNING PARSER + DATA CLEANER PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Step 1: Run the parser to collect fresh job data\n",
    "print(\"üì• Step 1: Running LinkedIn Parser...\")\n",
    "print(\"Command: make run-parser\")\n",
    "try:\n",
    "    parser_result = subprocess.run(\n",
    "        [\"make\", \"run-parser\"],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300,  # 5 minute timeout\n",
    "    )\n",
    "\n",
    "    if parser_result.returncode == 0:\n",
    "        print(\"‚úÖ Parser completed successfully!\")\n",
    "        # Extract some stats from output if available\n",
    "        lines = parser_result.stdout.split(\"\\n\")\n",
    "        for line in lines[-10:]:  # Show last 10 lines\n",
    "            if line.strip() and (\n",
    "                \"saved\" in line.lower()\n",
    "                or \"exported\" in line.lower()\n",
    "                or \"jobs\" in line.lower()\n",
    "            ):\n",
    "                print(f\"   {line.strip()}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Parser completed with warnings:\")\n",
    "        print(f\"   Return code: {parser_result.returncode}\")\n",
    "        if parser_result.stderr:\n",
    "            print(f\"   Error: {parser_result.stderr[-500:]}\")  # Last 500 chars\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Parser timeout after 5 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parser error: {e}\")\n",
    "\n",
    "# Small delay between operations\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 2: Run the data cleaner on the fresh data\n",
    "print(f\"\\nüßπ Step 2: Running Data Cleaner...\")\n",
    "print(\"Command: python -m genai_job_finder.data_cleaner.run_graph\")\n",
    "try:\n",
    "    cleaner_result = subprocess.run(\n",
    "        [\n",
    "            \"/home/alireza/.cache/pypoetry/virtualenvs/genai-job-finder-Y_k-9c-5-py3.12/bin/python\",\n",
    "            \"-m\",\n",
    "            \"genai_job_finder.data_cleaner.run_graph\",\n",
    "            \"--db-path\",\n",
    "            \"data/jobs.db\",\n",
    "            \"--verbose\",\n",
    "        ],\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=600,  # 10 minute timeout for AI processing\n",
    "    )\n",
    "\n",
    "    if cleaner_result.returncode == 0:\n",
    "        print(\"‚úÖ Data cleaner completed successfully!\")\n",
    "        # Extract processing summary\n",
    "        lines = cleaner_result.stdout.split(\"\\n\")\n",
    "        in_summary = False\n",
    "        for line in lines:\n",
    "            if \"PROCESSING SUMMARY\" in line:\n",
    "                in_summary = True\n",
    "                print(f\"\\nüìä {line}\")\n",
    "            elif in_summary and (\"=\" in line or line.strip() == \"\"):\n",
    "                if \"=\" in line:\n",
    "                    print(line)\n",
    "                    in_summary = False\n",
    "            elif in_summary:\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Data cleaner completed with issues:\")\n",
    "        print(f\"   Return code: {cleaner_result.returncode}\")\n",
    "        if cleaner_result.stderr:\n",
    "            print(f\"   Error: {cleaner_result.stderr[-500:]}\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è∞ Data cleaner timeout after 10 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data cleaner error: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ Pipeline Complete!\")\n",
    "print(\"   üì• Fresh job data collected\")\n",
    "print(\"   üßπ AI-powered data cleaning applied\")\n",
    "print(\"   üíæ Results available in cleaned_jobs table\")\n",
    "print(\"   üìä Ready for enhanced analysis below ‚¨áÔ∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc70e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ CLEANED JOBS TABLE ANALYSIS\n",
    "print(\"‚ú® ANALYZING AI-CLEANED JOB DATA WITH COMPANY INTELLIGENCE\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if cleaned_jobs table exists\n",
    "    tables_query = (\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\"\n",
    "    )\n",
    "    table_exists = pd.read_sql_query(tables_query, conn)\n",
    "\n",
    "    if table_exists.empty:\n",
    "        print(\"‚ùå No cleaned_jobs table found.\")\n",
    "        print(\"üí° Run the cell above to execute the parser + cleaner pipeline first.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Cleaned jobs table found!\")\n",
    "\n",
    "        # Get basic stats\n",
    "        total_cleaned = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "        print(f\"üìä Total cleaned jobs: {total_cleaned}\")\n",
    "\n",
    "        if total_cleaned > 0:\n",
    "            # Get the schema of cleaned table\n",
    "            schema_query = \"PRAGMA table_info(cleaned_jobs)\"\n",
    "            schema_df = pd.read_sql_query(schema_query, conn)\n",
    "            print(f\"üèóÔ∏è Table structure: {len(schema_df)} columns\")\n",
    "\n",
    "            # Sample of cleaned data with company information\n",
    "            sample_query = \"\"\"\n",
    "            SELECT \n",
    "                id, company, company_size, company_followers, company_industry,\n",
    "                title, location, \n",
    "                min_years_experience, experience_level_label,\n",
    "                work_location_type, employment_type,\n",
    "                min_salary, max_salary, mid_salary, content\n",
    "            FROM cleaned_jobs \n",
    "            ORDER BY id DESC \n",
    "            LIMIT 10\n",
    "            \"\"\"\n",
    "\n",
    "            cleaned_sample = pd.read_sql_query(sample_query, conn)\n",
    "\n",
    "            print(f\"\\nüìã SAMPLE CLEANED JOBS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 70)\n",
    "            for idx, job in cleaned_sample.iterrows():\n",
    "                print(f\"{idx+1:2d}. {job['title']} at {job['company']}\")\n",
    "                print(f\"    üìç {job['location']}\")\n",
    "\n",
    "                # NEW: Company information display\n",
    "                company_details = []\n",
    "                if pd.notna(job[\"company_size\"]) and job[\"company_size\"]:\n",
    "                    company_details.append(f\"üë• {job['company_size']} employees\")\n",
    "                if pd.notna(job[\"company_followers\"]) and job[\"company_followers\"]:\n",
    "                    company_details.append(f\"üìä {job['company_followers']} followers\")\n",
    "                if pd.notna(job[\"company_industry\"]) and job[\"company_industry\"]:\n",
    "                    company_details.append(f\"üè≠ {job['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"    üè¢ {' | '.join(company_details)}\")\n",
    "\n",
    "                # Experience info\n",
    "                if pd.notna(job[\"min_years_experience\"]) and pd.notna(\n",
    "                    job[\"experience_level_label\"]\n",
    "                ):\n",
    "                    print(\n",
    "                        f\"    üéØ Experience: {job['min_years_experience']} years ‚Üí {job['experience_level_label']}\"\n",
    "                    )\n",
    "\n",
    "                # Salary info\n",
    "                if pd.notna(job[\"min_salary\"]) and pd.notna(job[\"max_salary\"]):\n",
    "                    print(\n",
    "                        f\"    üí∞ Salary: ${job['min_salary']:,.0f} - ${job['max_salary']:,.0f} (Mid: ${job['mid_salary']:,.0f})\"\n",
    "                    )\n",
    "\n",
    "                # Work details\n",
    "                work_details = []\n",
    "                if pd.notna(job[\"work_location_type\"]):\n",
    "                    work_emoji = {\"Remote\": \"üè†\", \"Hybrid\": \"üîÑ\", \"On-site\": \"üè¢\"}.get(\n",
    "                        job[\"work_location_type\"], \"üìç\"\n",
    "                    )\n",
    "                    work_details.append(f\"{work_emoji} {job['work_location_type']}\")\n",
    "                if pd.notna(job[\"employment_type\"]):\n",
    "                    work_details.append(job[\"employment_type\"])\n",
    "                if work_details:\n",
    "                    print(f\"    üìù {' | '.join(work_details)}\")\n",
    "                print()\n",
    "\n",
    "cleaned_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìäüîÑ BEFORE vs AFTER: Data Transformation Analysis with Company Intelligence\n",
    "print(\"üîÑ ORIGINAL vs AI-CLEANED DATA COMPARISON (WITH COMPANY INTELLIGENCE)\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Check if both tables exist\n",
    "    original_exists = (\n",
    "        pd.read_sql_query(\"SELECT COUNT(*) as count FROM jobs\", conn).iloc[0][\"count\"]\n",
    "        > 0\n",
    "    )\n",
    "    cleaned_exists = (\n",
    "        len(\n",
    "            pd.read_sql_query(\n",
    "                \"SELECT name FROM sqlite_master WHERE type='table' AND name='cleaned_jobs'\",\n",
    "                conn,\n",
    "            )\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "\n",
    "    if not cleaned_exists:\n",
    "        print(\"‚ùå Need cleaned data for comparison\")\n",
    "        print(\"üí° Run: make run-pipeline\")\n",
    "    elif not original_exists:\n",
    "        print(\"‚ùå No original data found\")\n",
    "    else:\n",
    "        cleaned_count = pd.read_sql_query(\n",
    "            \"SELECT COUNT(*) as count FROM cleaned_jobs\", conn\n",
    "        ).iloc[0][\"count\"]\n",
    "\n",
    "        if cleaned_count == 0:\n",
    "            print(\"üì≠ Cleaned table is empty\")\n",
    "            print(\"üí° Run: make run-cleaner\")\n",
    "        else:\n",
    "            print(\"üìä DATA TRANSFORMATION PIPELINE RESULTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            # Side-by-side comparison of same jobs including company info\n",
    "            comparison_query = \"\"\"\n",
    "            SELECT \n",
    "                o.id,\n",
    "                o.company,\n",
    "                o.company_size,\n",
    "                o.company_followers,\n",
    "                o.company_industry,\n",
    "                o.title,\n",
    "                o.location,\n",
    "                o.level as original_level,\n",
    "                o.salary_range as original_salary,\n",
    "                o.employment_type as original_employment,\n",
    "                c.min_years_experience as ai_years,\n",
    "                c.experience_level_label as ai_level,\n",
    "                CASE \n",
    "                    WHEN c.min_salary IS NOT NULL THEN c.min_salary || ' - ' || c.max_salary || ' (Mid: ' || c.mid_salary || ')'\n",
    "                    ELSE 'Not extracted'\n",
    "                END as ai_salary,\n",
    "                c.work_location_type as ai_work_type,\n",
    "                c.employment_type as ai_employment\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            ORDER BY o.id DESC\n",
    "            LIMIT 5\n",
    "            \"\"\"\n",
    "\n",
    "            comparison_df = pd.read_sql_query(comparison_query, conn)\n",
    "\n",
    "            print(\"üîç DETAILED TRANSFORMATION EXAMPLES WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"(Showing how AI enhanced the original data)\")\n",
    "            print()\n",
    "\n",
    "            for idx, row in comparison_df.iterrows():\n",
    "                print(f\"üìã JOB {idx+1}: {row['title']} at {row['company']}\")\n",
    "                print(f\"   üìç Location: {row['location']}\")\n",
    "\n",
    "                # NEW: Company intelligence display\n",
    "                company_details = []\n",
    "                if pd.notna(row[\"company_size\"]) and row[\"company_size\"]:\n",
    "                    company_details.append(f\"üë• {row['company_size']} employees\")\n",
    "                if pd.notna(row[\"company_followers\"]) and row[\"company_followers\"]:\n",
    "                    company_details.append(f\"üìä {row['company_followers']} followers\")\n",
    "                if pd.notna(row[\"company_industry\"]) and row[\"company_industry\"]:\n",
    "                    company_details.append(f\"üè≠ {row['company_industry']}\")\n",
    "\n",
    "                if company_details:\n",
    "                    print(f\"   üè¢ Company Intel: {' | '.join(company_details)}\")\n",
    "                print()\n",
    "\n",
    "                # Experience comparison\n",
    "                print(\"   üéØ EXPERIENCE ANALYSIS:\")\n",
    "                print(f\"      Original: '{row['original_level'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_years']} years ‚Üí {row['ai_level']}\")\n",
    "                print()\n",
    "\n",
    "                # Salary comparison\n",
    "                print(\"   üí∞ SALARY INTELLIGENCE:\")\n",
    "                print(f\"      Original: '{row['original_salary'] or 'Not specified'}'\")\n",
    "                print(f\"      AI Result: {row['ai_salary']}\")\n",
    "                print()\n",
    "\n",
    "                # Employment type comparison\n",
    "                print(\"   üìù EMPLOYMENT TYPE:\")\n",
    "                print(\n",
    "                    f\"      Original: '{row['original_employment'] or 'Not specified'}'\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"      AI Result: {row['ai_employment']} | Work Type: {row['ai_work_type']}\"\n",
    "                )\n",
    "                print()\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "            # Statistical improvements including company intelligence\n",
    "            print(\"üìà STATISTICAL IMPROVEMENTS WITH COMPANY INTELLIGENCE:\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Count improvements\n",
    "            improvements_query = \"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_jobs,\n",
    "                -- Experience data\n",
    "                COUNT(CASE WHEN o.level IS NOT NULL AND o.level != '' THEN 1 END) as original_exp_data,\n",
    "                COUNT(CASE WHEN c.experience_level_label IS NOT NULL THEN 1 END) as ai_exp_data,\n",
    "                -- Salary data  \n",
    "                COUNT(CASE WHEN o.salary_range IS NOT NULL AND o.salary_range != '' THEN 1 END) as original_salary_data,\n",
    "                COUNT(CASE WHEN c.min_salary IS NOT NULL THEN 1 END) as ai_salary_data,\n",
    "                -- Work location data\n",
    "                COUNT(CASE WHEN c.work_location_type IS NOT NULL THEN 1 END) as ai_work_type_data,\n",
    "                -- Company intelligence data (already in original)\n",
    "                COUNT(CASE WHEN o.company_size IS NOT NULL THEN 1 END) as company_size_data,\n",
    "                COUNT(CASE WHEN o.company_followers IS NOT NULL THEN 1 END) as company_followers_data,\n",
    "                COUNT(CASE WHEN o.company_industry IS NOT NULL THEN 1 END) as company_industry_data\n",
    "            FROM jobs o\n",
    "            LEFT JOIN cleaned_jobs c ON o.id = c.id\n",
    "            WHERE c.id IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "            improvements_stats = pd.read_sql_query(improvements_query, conn).iloc[0]\n",
    "            total = improvements_stats[\"total_jobs\"]\n",
    "\n",
    "            print(f\"üéØ Experience Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_exp_data']}/{total} jobs ({improvements_stats['original_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_exp_data']}/{total} jobs ({improvements_stats['ai_exp_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            exp_improvement = (\n",
    "                improvements_stats[\"ai_exp_data\"]\n",
    "                - improvements_stats[\"original_exp_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{exp_improvement} jobs (+{exp_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üí∞ Salary Data:\")\n",
    "            print(\n",
    "                f\"   Before: {improvements_stats['original_salary_data']}/{total} jobs ({improvements_stats['original_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_salary_data']}/{total} jobs ({improvements_stats['ai_salary_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            salary_improvement = (\n",
    "                improvements_stats[\"ai_salary_data\"]\n",
    "                - improvements_stats[\"original_salary_data\"]\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{salary_improvement} jobs (+{salary_improvement/total*100:.1f}%)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            print(f\"üè† Work Location Type (New):\")\n",
    "            print(f\"   Before: 0/{total} jobs (0.0%) - Not available in original\")\n",
    "            print(\n",
    "                f\"   After:  {improvements_stats['ai_work_type_data']}/{total} jobs ({improvements_stats['ai_work_type_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Gain:   +{improvements_stats['ai_work_type_data']} jobs (NEW FEATURE)\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            # NEW: Company intelligence summary\n",
    "            print(f\"üè¢ Company Intelligence (Integrated in Parser):\")\n",
    "            print(\n",
    "                f\"   Company Size:     {improvements_stats['company_size_data']}/{total} jobs ({improvements_stats['company_size_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Followers: {improvements_stats['company_followers_data']}/{total} jobs ({improvements_stats['company_followers_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Company Industry:  {improvements_stats['company_industry_data']}/{total} jobs ({improvements_stats['company_industry_data']/total*100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                \"   üí° Company data extracted during parsing phase, available in both tables\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b335c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ FRESH DATABASE TEST - Company Info Link Debugging\n",
    "print(\"üî¨ DIRECT SQL QUERY TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test direct SQL query to bypass any caching issues\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Test the exact query that should be used in export\n",
    "    query = '''\n",
    "        SELECT id, company, title, location, work_location_type, level, salary_range, content,\n",
    "               employment_type, job_function, industries, posted_time,\n",
    "               applicants, job_id, date, parsing_link, job_posting_link,\n",
    "               company_size, company_followers, company_industry, company_info_link\n",
    "        FROM jobs\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT 5\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        direct_df = pd.read_sql_query(query, conn)\n",
    "        print(f\"‚úÖ Direct SQL query successful:\")\n",
    "        print(f\"   Shape: {direct_df.shape}\")\n",
    "        print(f\"   Columns: {direct_df.shape[1]}\")\n",
    "        print(f\"   company_info_link present: {'company_info_link' in direct_df.columns}\")\n",
    "        \n",
    "        if 'company_info_link' in direct_df.columns:\n",
    "            print(f\"   Column names: {list(direct_df.columns)}\")\n",
    "            print(f\"\\n\udcca Sample company_info_link values:\")\n",
    "            for i in range(len(direct_df)):\n",
    "                company = direct_df.iloc[i]['company']\n",
    "                link = direct_df.iloc[i]['company_info_link'] \n",
    "                status = 'HAS LINK' if pd.notna(link) and link else 'EMPTY'\n",
    "                print(f\"   {company}: {status}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå company_info_link column missing from direct query\")\n",
    "            print(f\"   Columns: {list(direct_df.columns)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Direct SQL query failed: {e}\")\n",
    "\n",
    "# Now test what the notebook's db instance is actually doing\n",
    "print(f\"\\nüîç NOTEBOOK DB INSTANCE DEBUG:\")\n",
    "try:\n",
    "    # Check if the database manager has the right database path\n",
    "    print(f\"   Database path: {db.db_path}\")\n",
    "    \n",
    "    # Test get_all_jobs_as_dataframe method\n",
    "    test_df = db.get_all_jobs_as_dataframe()\n",
    "    print(f\"   get_all_jobs_as_dataframe(): {test_df.shape}\")\n",
    "    print(f\"   Columns: {test_df.shape[1]}\")\n",
    "    print(f\"   company_info_link present: {'company_info_link' in test_df.columns}\")\n",
    "    \n",
    "    # Show what columns are actually returned\n",
    "    print(f\"   Actual columns: {list(test_df.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(f\"\\n\udd27 DIAGNOSIS:\")\n",
    "print(f\"   If direct SQL shows 21 columns but db instance shows 20,\")\n",
    "print(f\"   then there's an issue with the notebook's database manager instance.\")\n",
    "print(f\"   This could be due to an old cached version of the code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-job-finder-Y_k-9c-5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
