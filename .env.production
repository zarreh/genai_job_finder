# Production Environment Configuration for Docker

# Application Settings
APP_ENV=production
DEBUG=false
LOG_LEVEL=INFO

# Streamlit Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
STREAMLIT_SERVER_HEADLESS=true
STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
STREAMLIT_THEME_BASE=light

# Chat Configuration
CHAT_CONFIG_MODE=openai
# Options: default, mixed, openai, env

# LLM Provider Configuration (for env mode)
CHAT_LLM_PROVIDER=openai
CHAT_LLM_MODEL=gpt-3.5-turbo
CHAT_LLM_TEMPERATURE=0.7
CHAT_LLM_API_KEY=
CHAT_LLM_BASE_URL=https://api.openai.com/v1

RESUME_LLM_PROVIDER=openai
RESUME_LLM_MODEL=gpt-3.5-turbo
RESUME_LLM_TEMPERATURE=0.3
RESUME_LLM_API_KEY=
RESUME_LLM_BASE_URL=https://api.openai.com/v1

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Database Configuration
DATABASE_URL=sqlite:///data/jobs.db

# Security
SECRET_KEY=your_secret_key_here_change_in_production

# File Upload Limits
MAX_UPLOAD_SIZE_MB=10
ALLOWED_EXTENSIONS=pdf,doc,docx

# Performance
WORKERS=1
THREADS=4
TIMEOUT=300

# Monitoring
HEALTH_CHECK_ENABLED=true
METRICS_ENABLED=false

# Data Persistence
DATA_BACKUP_ENABLED=true
BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM

# External Services
OLLAMA_URL=http://ollama:11434
OLLAMA_TIMEOUT=30

# Rate Limiting
RATE_LIMIT_ENABLED=false
RATE_LIMIT_PER_MINUTE=60